# 统计学学习

***统计学不研究统计，它研究的是不确定性***


统计的基本思想: ***从随机性中寻找规律性***

统计思想的基本方法：***从样本性质推断总体性质***

推断的两大支柱就是：***概率和误差***，并贯穿于整个统计学的几乎所有关键点。

统计学最终归结到两个核心理念:***允许误差下的概率保证;允许误差下的统计推断***。

统计思维模式主要包括：  
均值模式  
变异模式  
估计模式  
相关模式  
拟合模式  
检验模式  
归纳模式  
比较模式  

均值模式：均值是对所要研究对象的简明而重要的代表。均值模式要求从总体上看问题，观察事物一般的发展趋势，避免个别偶然现象的干扰，体现了总体观、数量观和推断观。

变异模式：均值也代表了某种变异，否则无从谈起。统计研究对象中的个体必须存在差异。统计方法就是要认识事物数量方面的差异。在统计学中，用来反映变异的概念是方差，表示离散程度。平均与变异都是对具有同类个体的总体特征的抽象和宏观度量。

估计模式：估计模式是应用某种合理的方法，通过对有限量的样本的分析，对未知事物或者未发生事物进行估计推测的思想，由一个事物的特点和规律来推测其他事物，对其进行认识。使用估计方法有一个前提条件，那就是获取的样本应与总体具有类似的性质。在某种条件下，样本才能代表总体。在估计过程中，要保持逻辑的严谨性。

相关模式：并不是所有的事物之间都存在着严格的因果关系。在某些统计样本的变化过程中，经常会出现一些其它事物相随共变或相随共现的情况。我们把这种非确定性关系的相随共变叫做统计相关性。它们之间不存在确定的函数关系，也会有奇异值出现。

拟合模式：在统计世界中，个体显随机性，群体显规律性。拟合是对群体规律性的抽象，即公式化或模型化。一旦事物的变化被模型化，我们就找到了解决问题的方法，知道了变化趋势。

归纳模式：由某类事物中部分对象的特征,推断出该类事物的全部对象的特征,或者由个别事实概括出一般结论的推理叫做归纳推理。归纳推理是由部分到整体,由个别到一般的推理。推断性统计的由随机抽样样本性质推断总体性质的方法就是归纳的方法。有时归纳法得出的结论未必真实，因此还需要用实际样本资料对结论进行检验。

检验模式：推断性统计的依据就是归纳法。归纳法得出的结论永远是概率性质的。为了保证基于局部特征和规律所推断出来的对整体的判断的可信度，我们需要增加一道检验过程，就是利用实际样本资料来检验事先对总体某些数量特征的假设是否正确。

比较模式：统计的比较模式是依照比较的思维逻辑将比较对象与比较标准进行比较对照，计算出现象数量上的差别和变化，进而对比较对象做出评价和判断的一种统计思维方式。它包含比较的标准、比较的方式和比较的原则等具体内容。统计的比较模式在相对指标、变异指标、时间数列分析、指数、抽样推断和相关分析中都得到了有效的运用。


## 1. 统计学实验设计，及背后的知识

***设计实验的原则，是尽可能的控制实验中出现的变量，如果需要，则可以使用分组的方式处理那些无法通过主观行动影响的实验***

### 1) 对照实验

对照实验，即通过控制实验中的变量，对实验过程和结果进行**比较**。 对照实验是常用的实验方式，可以用于检验药物的有效性等。  
对照实验的关键在于分组：比如检验药品的有效性当中，可以通过认为的设置**处理组（提供药品）** 和 **对照组（提供安慰剂）**  

为了保证实验结果，实验过程需要保证随机：实验分组随机，过程双盲（实验者和实验者在均不知情的情况进行实验于统计）

同时，统计学上，为了避免**偏性**,需要进一步的控制对照组和处理组间的变量，防止出现因其他变量对实验结果进行**混淆**，这需要使得除了处理/实验这点之外，两组尽可能的相似  
以药物实验为例，为了避免因家庭条件（富裕家庭比贫穷家庭营养更好导致抵抗力更强）引起的偏性，则需要在对照组和处理组内部再增加一个家庭环境的分组，以进行对比。

在分组开始前，需要对参与实验的对象进行检查，保证他们均符合条件，例如：参与新冠疫苗实验的实验对象，不能患有新冠

整体实验中，两个分组的绝对数量不是关键，只要保证在同一数量级即可，因为最终判断结果数据时，可以使用比率而非绝对数据进行判断。

### 2) 历史对照实验

历史对照组，即将使用新方法的实验对象作为实验组，将之前使用老方法的实验对象设置未对照组，通过比较实验组和对照组确定结果。

例如：确定新药的有效性：将使用新药和老药的实验对象进行比较。

对于历史对照实验来说，需要控制历史对照组和实验组之间的差异，以避免可能出现的偏性。

## 总结

1. 统计学家使用比较的办法，试图搞清处理(接种疫苗)对反应(感染新冠)的效应。为了找到这两者的关系，他们把处理组和对照组中同分组的反应/结果之间进行对比
2. 在保证处理组和对照组仅仅在实验上出现区别，其他点上没有区别的情况下(避免混淆)，这两个组对比的结果就应该是实验的效果
3. 在使用随机对照实验的情况下，为了保证处理组和对照组条件相同，应尽量使用随机抽取的方式从实验对象中选择处理组和对照组
4. 对照组使用的安慰剂，应是中性的但是近似处理组使用的试剂
5. 随机实验应遵循双盲实验原则，即实验对象不清楚自身是在处理组还是在对照组，而研究人员也同样不知道这点，以免人事行为及之后评估过程中产生偏性

### 2) 观察研究

观察研究和对照实验不同，对照实验中，研究者决定对照组，而观察实验当中的分组是自然形成的，研究人员仅仅是客观的观察整体结果

***相对对照实验，观察研究中分组流程中，很有可能存在一定的偏性（例如吸烟的人群和不吸烟的人群进行比较，吸烟的人群的收入可能更低，因此影响了两个组的寿命）。为此，观察实验中，首先应该理清对照组和处理组之间的关系，以避免混淆***

针对对照组和处理组之间的混淆问题，最好的解决办法是通过创建子分组的方式控制变量。

控制变量的方法，可以用于针对较小且较均匀的分组进行偏性处理。例如：比较吸烟者和不吸烟者健康情况，以判断吸烟是否真正影响健康的实验中，因为吸烟者客观下以男性居多，且年龄偏大，故从整体上看会收到性别影响

为了排除这些影响，则应该针对**不同年龄层**的**男性吸烟者和男性非吸烟者/女性吸烟者和女性非吸烟者**进行观察实验。通过这种控制行为，可以事实上的避免性别和年龄分布不均的原则，对对照组和处理组返回的结果产生的影响。

***相关性并不等同于因果关系***

糙皮病案例：  
糙皮病（一种皮肤病）在18世纪被欧洲贫困地区的医生首次观察到，因为和某种吸血苍蝇的地理活动区域相同，一直被认为是由此类苍蝇传染的。但在20世纪，糙皮病被发现是因为缺乏烟酸(P-P因子)造成的，烟酸天然存在肉/蛋/奶/部分蔬菜和谷物当中，但是不存在于玉米(穷人的主要食物)当中。饮食上的限制才是糙皮病的主要病因，而苍蝇只是贫穷的标志，不是病的起因。

***针对通过观察研究中存在的混淆问题，可以通过设置更多较小的/均匀的子组进行调整这被称为：控制混杂因素***

例: 加州大学入学性别分析：  
从宏观角度上，加州大学以性别划分的入学率当中，男性占比44%，相比女性占比35%来说，确实存在一定入学歧视，得出这种判断潜在的假设是:  
1. 男女申请资质相同
2. 每个专业对招收男/女的倾向大体相同
通过对100个系中，占据30%比例的6个系的男/女录取率进行分析，可以发现：
1. 从录取率上来看：6个系中男/女的录取率相近，没有显著区别
2. 从绝对值上看，男/女在6个系的总数上没有太大差距，但是在分布上出现了较大差异：女性申请人更多集中在6个系中的4个系当中，而男性申请人则更多的集中在6个系当中的前两个系当中
根据之后调查的结果发现：6个系的申请难度并不相同，前两个系相对易于申请，而前两个系恰恰是男性集中申请的系，而其他四个系相对难以申请，但是集中了大部分的女性申请人

故，可以得出结论：表面上的申请差异是由男/女申请人申请系的分布引起的，底层原因则是因为每个系的申请难度不同，即：男性申请容易录取的专业，而女性则多申请录取难度高的专业

|专业|申请人数（男）|录取百分比（男）|申请人数（女）|录取百分比（女）|申请总数|
|:--|:--|:--|:---|:---|:---|
|A|825|62|108|82|933|
|B|560|63|25|68|585|
|C|325|37|593|34|918|
|D|417|33|375|35|792|
|E|191|28|393|24|584|
|F|373|6|341|7|714|

为了便于进行混淆控制，可以引入加权平均数的方式对申请率进行计算，此处的加权数即为申请总数：

男性加权平均入学率：  

    (62%x933 + 63%x585 + 37%x918 + 33%x792 + 28%x584 + 6%x714) / sum(933,585,918,792,584,714) 

39%

女性加权平均入学率：  

    (82%x933 + 68%x585 + 34%x918 + 35%x792 + 24%x584 + 7%x714) / sum(933,585,918,792,584,714)  

43%

最终得到结论：男/女申请人加权平均录取率相同，无性别歧视


# 描述性统计

针对于大部分统计数据，因为样本量较多，均需要使用描述性统计的方法对全部数据进行概括

## 1. 变量

变量，指的是研究中*因调查对象不同*而*产生差异*的*特性*。  
变量可以分为定性变量（婚姻情况，就业情况）与定量变量（年龄，收入）。  
变量可以是连续的或离散的：离散变量中，不同对象提供的变量间的差距应是固定且仅在一定范围内的（家庭规模）。而连续变量间的差距则是不固定的（年龄，一年、一个月、一天）  
在研究中，定性数据是由定性变量收集的

### 变量控制

在一般的实验当中，不会仅仅针对一项变量进行试验。  
例如：针对药物的实验中，会有血压，效果等多项变量。针对每个变量都要做好变量的控制工作：针对**血压**这个变量的测量工作中，也需要考虑到年龄的分组控制
这种情况下，可以使用交叉表列出实验组和对照组，所有年龄段下，不同血压的人数的比例

## 2. 平均数与标准差

在统计学中，**平均数**和**中位数**都用于寻找数据的中心（算数中心和实际中心），而**方差/标准差**用于度量平均数的散步程度（散步约大，方差/标准差越大），**四分位数间距**则是数据散步的另一种测度。

### 平均数中位数与方差

***一个数列的平均数，等于他们的和除以他们的个数的总数。***  
***一个数列的中位数，等于数列从小到大排列，此时数组最中间部分的标量数字就是中位数，如果数组为偶数，则为中间两个数的平均值***

平均数是一个用于*概括数据*的强有力的办法，但是这种浓缩仅仅通过*消除数据个体间的差异*而得到。有些差异则会被平均数掩盖掉。  
理想情况下，数据的分布应该是均匀的，所以平均数应该等于中位数。但是实际情况下，两个数据往往存在差异，而此时平均数两端的数据分布并非50%对50%。而中位数的两边数据分布均为50%对50%，即在直方图中，中位数左/右两边面积相等

为了统计平均数(算数中心)和中位数(实际中心)之间的差距，可以使用方差进行度量。  
方差是在概率论和统计方差*衡量随机变量或一组数据时离散程度的度量*，方差用来计算*每一个变量（观察值）与总体均数之间的差异*。  
方差的计算公式：SUM((数组中项目-数组平均值)^2)/len(数组)

### 剖面/纵向调查

剖面调查指的是：不同的研究对象，在*同一时间点*与其他实验对象*相互*进行比较  
纵向调查指的是：实验对象在整个实验中被持续跟踪，且和*自身*在*不同时间点*的记录进行比较

### 均方根与标准差

标准差/Standard Division（SD）用于计算数列中*同时出现了正/负两种数据*的情况下，*数据的分布*，即一个数列关于其平均数的散布。*标准差σ是方差σ2的正平方根；而方差是随机变量期望的二次偏差的期望。*  
方差度量了数组偏离平均数的大小，这是一类平均偏差。标准差表示了数列中的数离散于它们的平均值有多远。大多数情况下，数列中的数项离开平均数一个SD单位，极少数数项偏离了2个及3个以上的SD。  
粗略的说，数组中三分之二的数项（68%）在离平均数+-1SD范围内，其余32%离的较远；20分之19的数项（95%）在距离平均数+-2SD的范围内，而5%则远之；此规则适用于大部分数列。这也是置信区间设置为95%的原因。  

均方根是一种*降低偏性*时常用的计算方法，在数据统计分析中，**将所有值平方求和，求其均值，再开平方，就得到均方根值**。在物理学中，我们常用均方根值来分析噪声。

均方根计算指的是：平方根(SUM(((数组中项目)^2))/len(数组))，均方根计算了去除符号后，数列的项有多大；标准差计算的是偏离平均数（平均数偏差）的均方根。

标准差计算指的是：***σx = 平方根(E(x - mean(x)))
平方根(SUM(((数组中数项目-平均数)^2))/len(数组))  
另一种计算方法：平方根((项数)^2的平均数-(数项平均数)^2)***

**标准差计算，实际是在计算数项偏离平均值的幅度，公式中 x - mean(x)的作用即在于此。  
那为何要对它做平方呢？因为有时候变量值与均值是反向偏离的，x - mean(x)的结果是个负数，  
平方后，就可以把负号消除了。这样在后面求平均时，每一项数值才不会被正负抵消掉，最后求出的平均值才能更好的体现出每次变化偏离均值的情况  
当然，最后求出平均值后并没有结束，因为刚才为了消除负号，把[x - mean(x)]进行了平方，那最后肯定要把求出的均值开方，将这个偏离均值的幅度还原回原来的量级。这就是为什么要求差加总的平方根。**。

#### 两个标准差：标准差与标准差+

在当前的各类计算器及统计软件(包括Excel中)，一般存在两个标准差：  
标准差（针对总体）/ SD：一般意义上的标准差，即Excel表中STDV.P函数；一般**针对总体的全体数据**进行计算时使用，公式即为：***σx = 平方根(E(x - mean(x)))***  
标准差+（针对抽样样本）/ SD+：用**抽样样本**估算的总体的标准差，即标准误差。(Excel表中STDV.V函数)；为一般总体数据的SD(即上述SD)除以一个增强因子，***公式为：平方根(E(x - mean(x))) / 平方根((抽样样本量-1)/抽样样本量) 或可以简写为 平方根((x-mean(x))^2/(抽样样本量-1))；其中抽样样本量即为当前希望求标准差的数据的项数***

如果希望验证当前的标准差是SD还是SD+，则可以针对1,-1两个值求其标准差。如果结果为1，则当前标准差为SD，如果得到1.41，则为SD+

# 正态分布

### 正态曲线

因为相像，直方图可以近似划为一条曲线/正态曲线（正态近似），正态曲线用于代替统计数据常用的直方图，方便进行数据比较工作。

正态曲线公式：100% / 根号(2Π) * e^-(x^2/2)，其中e=2.71812

正态曲线关于0点对称，故数据0点即为平均值点，又为中位数点，且曲线下面积等于100%，标准的正态曲线数据应服从：  
+-1标准差单位间的正态曲线面积为68%，+-2标准差单位间的正态曲线面积为95%，位于曲线首/尾两个部分约占数据的十万分之六。

***标准单位个数是指的一个数值在平均数之上/之下多少个SD***

正态曲线内部表面积的求法：依据已知的+-1SD 面积为68%，和+-2SD为95%（这被称之为正态表），且正态曲线依据0点完全对称来推算面积

***一列数，如果遵循正态分布，落在一个给定区间项的百分数可以通过将区间转换为标准差单位(SD)，然后求正态分布曲线下相应的面积而估值。这个过程被称之为正态近似***

正态近似的求值：首先将区间转化成标准差单位(SD)，其次求正态曲线下相应的面积，最后将两步合在一起，

### 百分位数和四分位数

平均数和标准差单位(SD)仅能用于概括服从正态分布的数据，**但是一般情况下，数据不会完美的服从正态分布，而会从在长尾/左偏/右偏等情况**。  
为了概括这种数据，可以使用*百分位数*，即按照数据大小从小到大排列后，依据相同间隔（百分比）将数据分割成多个区间；当中，**第50百分位应正好是数据的中位数**。  
针对常见的几个由百分位数的取值点，可以推出**四分位数，即将数据从小到大排列后进行四等分，每个数据间隔为25%，并观察位于数据0%，25%，50%，75%和100%的几个点的数据。**  
四分位间距，在当**SD因数据分布不遵循正态分布而导致对曲线尾部面积进行了过多关注时**，用于**测量数据散布**，***所有曲线/直方图,无论是否遵循正态分布，均可以使用百分位数对数据进行概括***。

而当数据分布直方图遵循正态分布时，可以根据曲线的 **平均数** 和 **标准差单位(SD)** 对数据本身进行重构，这种情况下，平均数和SD是好的概括统计量。

例:  
数学SAT考试平均分为535，SD为100，求95百分位数。  
正态表中，以0点为准的占据+-2SD部分占据了全部数据的95%，但是此时说的95百分位数，则是说*数据从最小点，到数组的第95百分位*，即故原来的正态分布表中标定的数据在此时将不能使用。但是可以借用**正态近似**的思想，通过曲线面积求解：根据正态表，在服从正态分布的数据中，可以使用SD来表示数据的离散。第95百分数所在的点以在正态分布直方图中对应的点为5%数据所在的点。现在要求的是，5百分位至95百分位之间的面积，且5百分位至95百分位两点的SD值。5百分位和95百分位点中，占据了整个曲线的90%（100%-5%-5%，100%的面积减去了5百分位左边的5%的面积，和95百分位右边5%的面积），想在的问题是：90%阴影面积下的SD值是多少。通过+-2SD占据95%的情况可知，此位置应在2SD之内，约为1.65个SD，即为100 * 1.65 = 165分。故，95百分位则为535+165 = 700分

# 误差与测量误差

***每次单独测量值 = 精确值 + 机会误差***

误差无处不在，理想状况下，如果数据经过多次测量，每次测量的到的结果应该完全相同。但是实际情况下，因为**机会误差**存在的原因，数据每次测量得到的结果一定存在不同。  
机会误差的来源很难搞清，在一般的称量情况中，可能出现机会误差的原因包括但不限于：砝码/测量仪器的磨损，测量时的气温/气压，测量地点的重力等  
一般情况下，测量/处理机会误差的方法，是**经过多次测量后取所有结果的平均值**，这样的话机会误差将会平分给多个结果，这样就能进一步减小机会误差了，这被称之为**中心极限理论**。

***中心极限理论：设想我们重复称量一枚实际重量为5g的砝码。即使我们没有任何的操作失误，结果仍然会是 5.01g, 4.98g, 5.03g, .... ，不停徘徊，但大都处于真实值附近。这些变化来源于无法避免的随机误差。高斯则实际推导出了，这些随机误差应该服从正态分布。经过拉普拉斯，高尔顿等人的发展，我们最终得到了“中心极限定理”。简要一点可以这么说，当样本量趋于无限大的时候，样本均值减去理论均值渐近服从中心为0的正态分布。***

无论怎么测量，测量值都可能不同于真实值，如果重复一次，将显示一次的不同。为了得到一个值得信赖的值，则需要多次重复实验，通过得到的数据进行判断。  
机会误差使得每次单独测量值偏离精确值，偏离大小随着不同测量而变化，**在标准情况下，重复误差的变化性可以代表机会误差的变化性**。
***一系列重复测量值的标准差(SD)是单次测量中的机会误差可能大小的估计***

## 离群点

在正常的测量过程中，必定存在部分数据大幅偏离/远离大部分的测算数据，这些数据被称为**离群点**。  
在计算描述性统计，和拟合正态曲线的过程中，离群点的存在会成为干扰。当研究者看到一个离群点时，需要决定**是否因为接受此点数据而影响到数据的正态曲线的拟合**，**亦或者决定放弃此点**。

如果决定是否放弃离群点：如果数据量相对有限，且希望**坚持数据的客观性**以**避免任何人为的主观筛选过程**，则应该保留离群点。（离群点客观存在且不是因为流程错误所引起，为使得数据和正态曲线拟合而人为且主观的对数据进行筛选，数据将无法很好的表现当前的客观现实情况）如果修改少量离群点即可使得原始数据拟合正态曲线，则可以酌情去掉离群点。

## 偏性/系统误差

在数据测量当中，**偏性以相同的方式影响每个测量值，将它们推向同一个方向**；而**机会误差则随着不同的测量变化而变化，时上时下。**

例如：在卖菜的菜贩子秤砣上的吸铁石：引起秤砣重力变化使得每次测量得出的数据均偏大/小。

***理想情况下，通过统计多次重复实验，机会误差应会被抵消，重复测量值的平均数将给出测量物体的精确值（理想条件下机会误差也应符合正态分布）***  
但因为偏性存在的原因，测量的平均数将大于/小于精确值；偏性会使得每次测量得到的结果偏离真正的值：***单独测量值 = 精确值 + 偏性 + 误差 ***

通过对测量数据的观察无法客观发现偏性，一般会通过和客观标准比对(1千克秤砣和标准千克比较)或者和理论进行比较发现。

# 点和线

线由无数个点组成，在笛卡尔平面直角坐标系中，一个点的坐标可以写为(x,y)

### 线的斜率和截距

在一条线上，从一点A沿直线移动至点B，那么因为A点和B点移动所产生的x轴上的数据增长/减小（负增长）/变化被称之为**前移**，而Y轴上的数据增长/减小（负增长）/变化则被称之为**上升**。  
在一条直线中，无论取哪两个点，上升一定是前移的一半，**上升和前移的比率被称之为斜率：斜率 = 上升 / 前移；斜率是沿直线随X增加Y的比率/形成的夹角的陡峭程度***。  
***斜率为正则直线是上升的，为负则直线是下降的***。

直线的截距是指：***X = 0时 Y的值/高***

***斜率的实质：y变化一个单位和x变化一个单位的比，即：在同一直线上的两点(x1,y1) 和 (x2,y2)中，y变化一个单位(y2-y1) / x变化一个单位(x2-x1)***

### 由点和斜率确定直线/直线的函数

当直线经过点(2,1) 且斜率为1/2，求直线:

函数计算法:  
由直线经过点(2,1)，斜率为1/2可知：
    x = 2,y = 1，且y / x = 1/2，故可得到如下函数：y = 1/2 * x

画图法：  
画出点(2,1)后，向前前移3，根据斜率公式可得出，此时一点应为 1/2 * 3 = 1.5。由此得到两点(2,1)和(3,1.5)后，通过两点确定/施划直线。

***方程 y = mx + b 为一条直线，且斜率为m,截距为b***

# 相关

相关及相关性是统计学研究的重要组成部分。涉及到相关的知识时，一般情况研究的是**两个及两个以上变量之间的关系**。例如父亲身高和儿子身高之间的关系。  
通过绘制父亲身高与儿子身高之间的散点图（没对实验对象中，父亲身高值为x，儿子身高值为y），可以对父亲身高和儿子身高这两个变量进行分析。  
通过判断绘制出的散点图的倾向：整体向右上则x/y为正相关（随着x的增长y同时进行增长），通过观察可知：儿子身高父亲身高有关且呈正相关。但是通过散点图中点的散步可知：如果散步相对集中在一条线上(y=+-x)则可说明两个变量之间相关性强，反之如果散点图中点相对分散，则相关性若。如果相关性较强，则已知一个变量对预测另一个变量存在帮助，反之则无帮助。

通常情况下，仅在自身产生变化的变量被称之为**自变量**，因为自变量变化影响下变化的量为**因变量**。例中，希望了解儿子的身高是否受到父亲身高的影响，则父亲身高为自变量而儿子身高为因变量。

## 相关系数与协方差

针对普通的单变量数据，一般可以使用平均数/标准差等描述性统计指标对数据进行概括。针对两个变量的数据，因为存在两个变量/二维的原因，无法使用原先的指标。  
针对二维以上的数据，可以以下指标对数据进行描述:

**平均数点**:变量x和变量y各自的平均数组成的点，即散点图散步的中心点  
**水平/垂直散步度**：在理想情况下，x轴和y轴数据也应该符合正态分布，故可以使用x轴数据的标准差值（SD）和y轴数据的标准差值（SD）计算出水平SD和垂直SD。依据正态曲线表可知，大部分的数据都会集中在+-2SD中，故可以使用**x轴数据+-2SD的值**和**y轴数据+-2SD**的值来描述**水平/垂直散步**。  
**协方差**：表示用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。  
**相关系数**：相关系数缩写为r，用于描述x和y两个变量之间的关系。相关系数是线性相关或围绕直线群集程度的一种度量。

### 协方差

协方差表示的是**两个变量的总体的误差**，即可以用于描述协方差作为描述X和Y相关程度。  
这与只表示一个变量误差的方差不同。如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

**协方差用于表示两个变量是否正负相关，也就是数值上变化是否同或反向；也可以用于计算相关性系数**

注：协方差只表示线性相关的方向，取值正无穷到负无穷。  
也就是说，协方差为正值，说明一个变量变大另一个变量也变大；取负值说明一个变量变大另一个变量变小，取0说明两个变量没有相关关系。  
而协方差的绝对值不反映线性相关的程度（其绝对值与变量的取值范围有关系）。

***协方差公式:  
Cov(X,Y) = E[(x-mean(x))x(y-mean(y))]***

公式简单翻译一下是：如果有X,Y两个变量，每个时刻的“X值与其均值之差”乘以“Y值与其均值之差”得到一个乘积，再对这每时刻的乘积求和并求出均值  
故：**如果协方差为正，说明X，Y同向变化，协方差越大说明同向程度越高；如果协方差为负，说明X，Y反向运动，协方差越小说明反向程度越高**

若两个随机变量X和Y相互独立，则E[(X-E(X))(Y-E(Y))]=0，因而若上述数学期望不为零，则X和Y必不是相互独立的，亦即它们之间存在着一定的关系  
故:  
当 cov(X, Y)>0时，表明 X与Y 正相关；  
当 cov(X, Y)<0时，表明X与Y负相关；  
当 cov(X, Y)=0时，表明X与Y不相关。

在概率论和统计学中，协方差用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。

从直观上来看，协方差表示的是两个变量总体误差的期望。  
如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值时另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，即其中一个变量大于自身的期望值时另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。  

如果X与Y是统计独立的，那么二者之间的协方差就是0，因为两个独立的随机变量满足E[XY]=E[X]E[Y]。  
但是，反过来并不成立。即如果X与Y的协方差为0，二者并不一定是统计独立的。  
协方差Cov(X,Y)的度量单位是X的协方差乘以Y的协方差。  
协方差为0的两个随机变量称为是不相关的

### 相关系数的计算

***将每个变量都转化为标准单位(SD)时，乘积的平均数即为相关系数***

相关系数也可以看成协方差：一种剔除了两个变量量纲影响、标准化后的特殊协方差  
既然是一种特殊的协方差，那它：  
1、也可以反映两个变量变化时是同向还是反向，如果同向变化就为正，反向变化就为负。  
2、由于它是标准化后的协方差，因此更重要的特性来了：它消除了两个变量变化幅度的影响，而只是单纯反应两个变量每单位变化时的相似程度。

将自变量记为x，因变量记为y，相关系数记为r，则：  
***r = Cov(X,Y)/(σx x σy)  
即：r = mean[(x-mean(x)) * (y-mean(y))] / σx x σy
r = mean([(使用SD表示X)x(使用SD表示y)])  
mean(x = [(x数项-平均值)/SD] * y = [(y数项-平均值)/SD])***

计算过程：  
1.将x/y值转化为标准单位(SD)
2.求对应x/y值标准单位的乘积
3.求出平均值

**相关系数直接衡量的就是线性相关关系，取值就在+-1之间，体现的含义是X和Y多大程度在一条斜率存在且不为0的直线上**

例:  
x = [1,3,4,5,7]  
y = [5,9,7,1,13]  

求相关性系数  

首先将x/y对应数项转为SD值：  
x = [(1-4)/2 = -1.5, (3-4)/2 = -0.5, (4-4)/2 =0, (5-4)/2 = 0.5. (7-4)/2 = 1.5]  
y = [-0.5,0.5,0,-1.5,1.5]  
x平均数：4  
y平均数：7

其次求x/ySD表现下的乘积:  
 x * y = [0.75 , -0.25, 0.00, -0.75, 2.25]

最终通过计算x * y得到值的平均数，得到相关性系数：  
sum(0.75 , -0.25, 0.00, -0.75, 2.25) / 5 = 0.40

r值原理:  
**标准差描述了变量在整体变化过程中偏离均值的幅度。协方差除以标准差，也就是把协方差中变量变化幅度对协方差的影响剔除掉，这样协方差也就标准化了，它反应的就是两个变量每单位变化时的情况。这也就是相关系数的公式含义了**。

通过x项y项平均值点引出垂线，并在平均数点相交，可以将散点图划分为四个象限。左下角和右上角x/y之积均为正数；而左上角/右下加x/y之积均为负，乘积之和为相关性系数。换言之，相关性系数是同时通过测算x 和 y两个单独变量在各自轴上的分布位置，判断两个变量是否都在相似的分布位置(平均数上/下)。如果x/y值分布均为正/负（均在平均数以上/以下），即x/y分布位置相同，则两个正象限占主导地位;反之则相反。

相关系数（r）应该在+-1之间：  
既然相关系数是协方差除以标准差，那么，当X或Y的波动幅度变大，的时候，它们的协方差会变大，标准差也会变大，这样相关系数的分子分母都变大，其实变大的趋势会被抵消掉，变小时也亦然。  
于是，很明显的，相关系数不像协方差一样可以在＋无限到－无限间变化，它只能在＋1到－1之间变化。

相关系数越大线性关系越强，当相关系数为1时被称为**完全相关**，即y=+-x的状态，所有点均位于一条直线（SD线）上，因此变量间存在**完全线性关系**。正常情况下，两个变量不会出现完全线性关系的情况。

相关系数仅仅是一个常数而不代表数据分布，即0.80相关性，即不代表有80%的点靠在线上，也不意味着其线性程度是0.40时候的二倍。  
相关系数分级：1.0-0.7强相关 0.7-0.3 部分相关 小于0.3被认为不相关

***相关性系数分布在+-1之间，且为+-1范围内的任意值。当正相关时散点总体方向为斜上，即自变量x增加时因变量y也会一同增加;负相关时则向斜下，即即自变量x增加时因变量y相对减小;***

### 相关系数的特点

1. 相关性系数只是一个纯粹计算出的指标/数字，因此并不会带有任何原始变量下的单位。同时，因为计算相关性系数时使用了标准差单位(SD)对x轴/y轴上的原始数据进行了拟合/转化。x轴/y轴上的数据同时乘或加一个标量数据并不会引起相关性系数的变化。（例如，x/y轴数据同时乘以3，则平均数，离平均数的偏差和方差均增加三倍；在计算方差时此倍数将会被消去；x/y轴同时增加一个标量时，平均数增加7，但是离平均数的偏差不变，方差也不变）
2. 根据相关性系数的计算方法可知，互换变量（x/y和y/x）相关性系数是完全相同的(x * y == y * x)
3. 当出现大量离群点，亦或者数据分布不成线性相关的情况下，相关系数无法完美的描述散点图：离群点的存在会很大程度上拉低相关性系数，甚至使其降至0。而非线性相关的情况下(随着x增加，y值先增后降，类似成年人体重和年龄之间的相关性)，此种情况下，即便两个变量相关，则相关系数亦是0.故，只要可能，则应该通过观察散点图检查/确定离群点和非线性相关：相关系数r仅适用于线性相关情况，而不是一般意义下的相关。

## SD线

相关性数据当中，用于拟合且表示散点图趋势的线被称作**SD线**。SD线穿过对于x/y两个变量的来说平均数的差都为SD的倍数的所有点。该线穿过平均数点，以美横向增加1SD，竖向增加1SD的比例上升。例如坚持人身高和体重的关系，若身高比平均身高多1SD且体重比平均体重多1SD，则此点落在SD线上，而若身高增加1SD而体重增加0.5SD，则不在线上

SD线的斜率是: 上升（+-Y的1SD值） / 前移（X的1SD值）

### 改变SD

散点图中，点形成的形状和点的密集程度均由标准差单位(SD)来决定：两个相关性系数完全相同的数据，因为SD大小的不同，而在散点图中显示的分布不同，SD越小越密集且离SD线越近；反之则相反。这是因为r的计算考察的不是按照绝对值度量集群程度，而是按照相对SD的值而决定。

***相关系数度量点围绕直线的集群的程度，但这只是针对SD而言的***

### 相关系数与距SD线的间距

***如果相关性系数r靠近1，则一个代表点在SD线之上/之下的仅为纵向SD的一小部分地方。如果相关系数r接近0，则一个代表点位于SD线之上/之下一定的量，在大小上大致与纵向SD是可以比较的。横向SD也是相同的***

## 相关性和因果性

***因果性不意味着相关性：相关性系数度量的是变量之间的相互关系，但是相互关系不等于因果关系。计算相关性系数不能帮助理清第三因素的影响***

例如：经检查，学校中儿童识字率和鞋尺寸的大小之间存在相关性，但这不意味着学习新词汇会引起鞋尺寸的变化，而是因为当中存在第三个自变量**年龄**，因为儿童成长学会了更多单词，且需要使用更大尺寸的鞋。

故，在实验中，仅能通过增加内部分组的方式，防止第三因素对相关性系数的影响。

## 和自然/生态话题下的相关性系数

***生态相关往往是基于比率或者平均数的，它们通常用于政治，科学和社会领域，它们更多的倾向夸大相关程度。因为在社会/生态等方面下存在大量的样本，往往宏观下的系数因为在偏性/误差及其他因素的影响下，往往和宏观数据不相符***

例子：通过研究吸烟率（按照人员计算）和肺癌死亡率这两个指标并绘制散点图，可以发现吸烟率（按照人员计算）和肺癌死亡率之间呈现正相关。最终发现吸烟率和肺癌死亡率两个数据呈现正相关，且相关性为0.70。

此类案例中，因为数据检查的人的吸烟率烟率/肺癌死亡率而非国家的吸烟率/肺癌死亡率，故应使用各个国内人员的吸烟率和肺癌死亡率，而非国家级别的吸烟率/肺癌死亡率和相关性系数进行比较。

例2：美国人口调查：受教育程度和收入的相关性：

在统计如此大范围内的数据时，应使用个人的受教育程度和死亡率进行分析：通过收集地理划分下的9个区域中的男性的受教育程度和收入水平的平均数，然后计算9对平均数据之间的相关性。如果仅仅使用每个区域的相关性系数去估计个人维度的相关性系数，则因为区域数据中存在大量数据散步和离群点，必须使用平均数将此部分*脏数据*排除在外。

# 回归

***回归方法描述的是一个变量如何地依赖另一个变量***

***回归线：回归线之于散点图，等同于平均数之于数据变。y关于x的回归线估计了相应于每个x值的y的平均数；在回归线上，平均而言，自变量以平均数为基点，每增加一个SD单位的数据，相应的y则增加 相关系数r * y轴SD个数据的值，这种通过相关系数估算每个x值对应的y的平均数的方法叫做回归方法***

即：y = y_mean + r * x(SD单位值) * y_SD

回归方法中涉及到自变量和因变量双方的SD值：  
x轴/自变量的SD值用于测量x的变动范围，而y轴/因变量的SD值则用于测量Y的变动范围。

## 回归方法与个体数据推断

根据上述定理，当仅仅知道自变量或因变量的时候，一方推断出另外一方；通常，研究人员通过研究求出回归估计，再对数据进行外推，并将回归估计应用于推算新的对象。

例：大学学生SAT数学分数（200-800）和第一年GAP（0-4.0）之间的关系，自变量（SAT数学分数）和因变量（GAP）数据之间的差距：  
SAT_mean = 550,  
SAT_SD = 80  
GAP_mean = 2.6
GAP_SD = 0.6
r = 0.4

若一学生SAT分数为650，求其GAP分数:  
SAT(标准单位下) = (650 - 550) / 80 = 1.25SD  
GAP相对平均数增加的单位 = 0.4 * 1.25SD = 0.5SD,即在SAT现有的数据下，GAP数据应偏离了平均数 0.5个GAP_SD单位  
当SAT分数为650，则其GAP分数应是：2.6 + 0.5 * 0.6 = 2.9

此定理在大多数情况下有效，但是无法用于正确预测离群点下的数据。而且，此类推断得到的数据仅能代表当下状态下数据的结果，适用范围很广。（例中推断的数据仅能用于当前案例，即仅能适用于当前学校内学生，对于外校学生无法进行估计，因为数据差异会很大）

## 使用回归方法预测百分位数

回归方法也可以用于推断/预测百分位数排序：如果通过预测得到百分位数为90%，则说明超过了90%的数据。

回归方法预测百分位时，主要需要在自变量和因变量均服从正态分布的情况下，依据正态分布面积/SD单位换算进行。

例：已知SAT分数及GAP分数均为正态分布，相关性系数r为0.4，当某个学生SAT分数排名为90%，求其GAP分数的百分位数

首先需要确定SAT 百分位数为90%时的所在的标准单位（SD）；通过题目可知，该学生SAT排名(百分数数)为90%。设定90百分数位置标准单位为Z，90%位置据100%位置相差了10%，根据正态分布可知+-Z位置数据占全部数据位置的80%（100%- 10% - 10%）;根据正态表可知，占据80%面积的标准差单位（SD）为+- 1.3SD，即可知x所在位置为1.3SD。通过回归方法可知Y所在位置为0.4*1.3SD，即0.5SD。根据正态表可知+-0.5SD所占面积，最终得到百分位数69%

***此类计算中，SD仅仅用于表示x/y点所在的位置，并未直接参与计算；而相关性系数r值才是计算的关键，百分位排序以正态规则的方式给出标准单位***

***在缺乏任何数据支持的情况下，正常情况下应预测数据为中位数。但是在得到部分具体数据的情况下，可以预测在中位数数据上/下进行浮动（预测一个物理很好的学生的数学成绩 v.s 制陶课程很好的学生的数学成绩）***


## 平均数图

平均数图：将每个自变量中对应的因变量的平均值使用点标出（x,y），并标注出该点所含的样本量的图表被称之为平均数图。

***回归线图是平均数图的光滑形式，如果回归数图正好是一条直线，则回归线和平均数图必然和为一条直线。***

当变量间存在非线性相关的情况时，不应使用回归线而是使用平均数图。

## 回归谬论与均值回归效应

***在所有考试/再考试的情形中，都存在一种现象：第一次考试成绩比较低的对象在第二次考试中分数均会平均提高，而第一次考试成绩较好的学生则会在第二次考试中平均下降。这被称之为回归效应***

1886年英国遗传学家Francis Galton在研究人类身高的时候，发现一个有趣的现象：父母平均身高高于人群平均值的时候，他们孩子的身高会比父母低一点，而父母平均身高低于人群平均值的时候，他们孩子的身高会比父母高一点。也就是说，下一代的身高会向均值“回归”。 Galton称之为“回归平庸”现象。

### 均值回归效应

均值回归效应出现的原因，是因为两此比较测试中测试对象/样本对象得到的分数不尽相同，这有可能是因为试卷中出题的知识点不同，考生当时的状态变化，运气等原因造成的。故从整个样本群体的角度去诠释数据时，数据总会向平均值进行集中，因为最终数据等于：考试观察到的分数 = 实际水平分数 + 机会误差。

从统计学上简单的解释，如果组变量X和Y不是互相独立的，也不是完全线性相关（即相关系数不等于1或-1），且X是自变量，Y是因变量，那么一定有X与其均值距离较远（标准差大），Y与其均值距离较近（标准差小）。所以说，均值回归现象是普遍存在的，距离均值越远，偏差越大，均值回归越明显。另外要说明的是这是一个统计规律，**只适用于群体，不适用于任何特定个体**。

故，根据上述推论可知：样本数据在SD线周围分布并不均匀（不会均匀的分布在SD线的上/下部分），在SD线下部（以X轴为单位），数据分布大量分布在SD线上方；在SD线上部，则存在大量数据分布在SD线下方。而针对回归线，样本数据则会大量分布在回归线的上方和下方。即：从总体数据来看，第一次考试成绩低的数据第二次考试成绩将上升，第一次考试成绩高的，第二次考试成绩将下降。

***回归谬论认为，回归效应出现的原因是因为某些重要的因素引起（未考虑统计学上随机起落的回归现象，造成不恰当的因果推论），而不仅仅是因为围绕直线散布所致***

***那么如何避免均值回归导致的误判呢，首先要认识到这个问题的存在，然后是对于某些指标，可以重复多次测量，取变化的平均值，从统计上尽量消除均值回归的影响。***

## 两条回归线

***回归线和相关性系数的求值方法的不同，导致了针对自变量/因变量的回归线可以画出两条回归线，这两条平均线将分别穿过自变量和因变量的中心***

# 均方根误差

如之前提到，在回归方法中可以使用自变量推算因变量；然而推算出的数据和实际数据间往往存在差距。这双方的差距被称之为**残差**。而经过计算的整个数组的残差，被称之为**均方根误差**。

## 残差

***残差：残差指的是实际因变量和回归线之间的差/上下的垂直距离。残差是使用回归方法进行预测的预测误差的图形表示。在散点图中，每个点都有一个残差，用于表示回归方法带来的误差。***

***残差 = 实际值 - 预测值***

通过对数据组中全部的残差进行均方根计算后得到的简约值，被称之为**回归直线的均方根误差（将所有残差值平方求和，求其均值，再开平方，就得到均方根值）**。

## 均方根误差

***均方根误差指的是：通过回归推算出的Y值/因变量值和实际因变量值之间的差值的平均情况；均方根误差以绝对数，度量了点沿回归线散布的情况；而相关性系数则度量了点沿SD线的散布情况***

均方根误差能提供：一个代表点距回归线的有多远。

***散点图中的点，按照与均方根误差大小相似的残差偏离回归直线（上/下），均方根误差与回归直线之间的关系，相当于标准差于平均数之间的关系***

数据的残差，实质上也**服从正态分布**，即：***68%的点实际分布在回归直线+- 1 均方根误差的范围内，而95%的点分布在回归直线 +- 2 均方根误差的范围内；大部分的数据都适用于此规律***

## 均方根误差的计算

关于自变量x和因变量y的回归直线的均方根误差的计算公式:**(1-r^2)开根号 * y_SD**  
**算式中应使用待预测变量/因变量的SD进行计算**；**因为计算均方根误差时使用了标准单位/SD，故均方根误差存在单位，单位和因变量的单位相同**

通过均方根误差计算可知：如果在r值相对较小的情况下，均方根误差值会相对增大，甚至可能接近/超过标准单位值。故可以论证：当相关性系数相对较小时，数据拟合较差，因为均方根误差较高。另一方面，通过均方根误差也可以了解到回归数据的拟合情况。

## 均方根误差计算的实质

均方根误差计算，实质上将相关性系数和因变量的标准单位两个数据联系在了一起。

**因变量Y的SD度量的是一个代表点在Y轴平均数点延长线之上/之下的距离**。即：如果不考虑自变量x仅用y的总平均数预测y值，则SD实际度量了误差的大致大小。而均方根误差代表了点在平均数之上/之下的距离，均方根误差小一些，因为回归直线更加接近散点。而均方根误差比SD小的精确因子则为 **(1-r^2)开根号** 个单位（即均方根误差是y_SD的(1-r^2)开根号倍）。

当r = +-1 和 r = 0 这三个极端情况下，可以确认均方根精确因子的正确性：  
当 r = +-1 时，自变量x和因变量y完全拟合，且SD线和回归线完全拟合，均向左上/右上延申。在此类情况下，回归线将穿过散点图中全部点且残差为0，且根据均方根误差因子计算公式(1-(+-1)^2)开跟号可推算，此时的均方根误差值为0，符合实际情况。  
当r = 0时，则证明自变量和因变量完全无关，即双方无线性关系。同时此时均方根误差等同于SD。

## 残差图

残差图类似于平均数图，即：保持自变量x位置数据不变，计算并显示x位置对应y值的残差（y值在回归线上下的+-距离）。

**残差图中，残差的平均数为0，且残差图的平均线是水平的（所有向上/向下的趋势都已经从残差中剔除，且表现在回归数当中了）**。

***在多元线性回归中，残差图可以更加灵敏的检查数据是否线性相关：当残差图中大部分数据趋向y轴为0时，残差数量最小，证明数据线性相关，反之则不符合线性相关。***

## 对纵向条形的考察

纵向条形图：在散点图中，根据单位在x轴中选取两个端点(一般为四舍五入为箱中心点的数据，即3.5，4，4.5)制成的条形图，用于确定条形图中含有的点的关系（因为X轴数据可以四舍五入为一个的原因，被设为一个箱）。

***当散点图中，所有纵向条具有相似的散布时，这个散点图会被称之为等方差的***

一般来说，等方差的散点图的残差图，是椭圆形的。检测等方差性的的最好办法，是检测残差图。  
当散点图等方差时，整个回归直线上任意一点的预测误差值相近。

***异方差性：当自变量上升时，因变量值上升，且数据散布同时上升。即无法通过自变量精确推送因变量***  
当散点图为异方差时，散点图的不同地方的回归方法偏离不同的量。  
在此种情况下，回归线的均方根误差仅仅是提供了一些平均误差--对于所有不同的X值。

**假定散点图是等方差的，且残差中没有一定格式，取一窄纵向条形图当中的点，他们的Y值与回归线上的偏差在大小上与均方根误差相近**。

## 纵向条中正态曲线的应用

当纵向条形图是等方差的，且数据厚厚密集于图的中部，而在两边相对稀疏，则可以使用*正态近似*对纵向条进行研究。

***考虑一个橄榄球型散点图中一个窄纵向条形图中的所有点，它的y值是一个新的数据集，新数据集的平均数使用回归方法估计，新SD约等于回归直线的均方根误差。正态近似可以像通常那样，但是需要使用新的平均数和方差***

例:LAST考试分数和第一年成绩之间的关系：  
LAST考试成绩平均数：32，SD：6  
第一学年平均成绩：68，SD：10，r = 0.60

求：当LAST考试成绩等于35分时，第一学年成绩在75分之上的学生占比

题目中在LAST考试为35分的数据部分形成了一个纵向条，为了求出纵向条部分数据中，因变量（第一学年平均成绩）75分以上的数据占比，则需要线算出纵向条选中区域的新平均数和方差后，利用正态近似的方法，求出该点Y值所在SD，并最终换算出Y值所在面积，最后求出Y值之外的面积。

1.计算纵向条区域内y的平均数：  
使用回归方法估计，即通过回归方法算出的该点的Y值，即为此纵向条中Y值数据的平均数：先通过x轴偏离平均数的sd判断Y数据偏离平均数的SD。(35-32)/6 = 0.5SD,x偏移平局数0.5SD，r * SD = 0.6 * 0.5 = 0.3SD，68 + 0.3 * 10 = 71，即新区间Y轴平均值为71。  

2.计算新区间范围的SD:  
新区见的SD值，可以使用均方根误差来代替：(1-0.6^2)开根号 * 10 = 8（通过LAST成绩求第一学年平均成绩，平均成绩为因变量，此处SD选8），即新SD为8。

3.使用新平均数和新SD。计算Y轴上的正态近似以计算百分位数  
(75-71) / 8 = 0.5，即Z = 0.5。由此结合正态表可以推出：+- Z所占总面积的38%，而75分以上面积占31%。

# 回归直线与多元回归

## 回归线的斜率和截距

任何直线都可以用**斜率**和**截距**进行表示，通过计算直线的斜率和截距，可以计算出直线的**直线方程式：y = 斜率 * x + 截距，即：y=mx+b**，回归直线也是直线，故可知：回归直线也可以使用直线方程式进行表示。

对于回归线而言，**斜率**意味着**x每增加一个单位SD，Y相应的平均变化的大小**；根据回归方法可知：自变量增加1个SD，因变量增加r个SD，y = r * x(SD表示) * y_SD + y_mean，故可知回归线的斜率计算为：**斜率 = (r * y_SD) / x_SD**

对于回归线而言，**截距则为X=0时的y预测值**

回归直线中的方程被称之为**回归方程 = (r * y_SD) / x_SD + 截距**

***回归方程是使用自变量x推算因变量y的另外一种方法，但是通过回归方程，研究人员可以通过小样本数据计算一次回归方程后，将数据直接带入到此方程中进行计算，最后得到预测值。***

例：通过受教育水平（年），计算平均收入，求回归公式，和 8/12/16年教育水平下的收入：
平均受教育水平：12年，SD：3.5年  
平均收入：11600美元，SD：10500美元，r = 0.40

1.求回归方程：  

根据回归方程公式可知：y = 斜率 * x + 截距，回归线中斜率等于(r * y_SD) / x_SD = (0.40 * 10500) / 3.5 = 1200美元 / 年，即每增加/减少1年教育收入将增加/减少1200美元。  
已知：截距等于x = 0 时 y的预估量，即受教育水平为0时的平均收入，根据斜率可知：每减少一年教育年限则减少1200美元收入。故，相对平均年龄的12年，当x=0时收入应减少 12 * 1200 = 14400美元；故，当受教育平均市场为0时，收入为 平均收入 - 14400美元 = -2800美元。（或可使用回归方法对数据进行估计，即：(0-12)/3.5 * 0.40 * 10500 + 11600 = -2800）

根据上述计算，回归方程为：y = 1200 * x + (-2800)

2.计算8/12/16年教育水平下的收入

将教育年龄带入回归方程中可得：  
8年教育水平下收入：1200 * 8 + (-2800) = 6800美元  
12年教育水平下收入：1200 * 12 + (-2800) = 11600美元  
16年教育水平下收入：1200 * 16 + (-2800) = 16400美元  

在回归方程的范围内，我们仅仅知道自变量和因变量之间存在**相应的关系**，而不是绝对相关。以上例为例，通过回归方程计算，我们仅仅可以知道受教育水平增加1年，相应的收入增加1200美元。但是针对收入的差异是否是受教育时间影响所产生这一议题，回归方程则无法解释；因为数据中可能混杂了其他原因，例如个人的智力，家庭情况等。这些因素和自变量因素实际混杂在一起，形成了回归方程中的斜率，最终影响了因变量。

针对上述情况，可以通过增加内部观察组的方法进行解决，或者可以通过进行**多元回归**的方法进行计算。

总而言之**在观察研究中，回归直线的斜率和截距都仅是描述性统计量，只能说明观察统计中一个变量的平均数如何与另一个变量的值进行相联系；如果研究者改变了X，则Y不一定/不能使用斜率来预测Y值的对应变化**。

## 最小二乘法

有时，散点图中的点沿着一条直线进行延申（线性关系较高，相关性较强），为了拟合此种情况下的散点图，可以寻找一条直线，保证散点图中的*点到此直线的距离相同(移动这条线将使得直线到散点图中某些点的距离增加，故找到和散点图中全部点距离相同的位置，即是拟合最好的位置)*。这时此直线即为*回归线*。  
为寻找到适合的位置，需要满足两个要求：1.定义一个直线到所有点的平均距离；2.在平均距离附件移动直线，直至平均距离尽可能的小。

针对第一个问题：  
因为此直线将作为回归线，用于使用自变量来推算因变量；故针对因变量/y值来说，点到此线的垂直距离，就是点到线的距离，即是回归方法中的**残差**；**统计学中，定义平均距离一般使用均方根进行**，这些点到回归线的平均距离则可以被视作**均方根误差**。

针对第二个问题：  
为在此点附近移动直线，使得均方根误差最小，**在所有直线中，由x预测y的均方根误差最小的那条直线，被称为回归直线**。  
而回归直线也被称之为**最小二乘直线：将误差平方以计算均方根误差，回归直线使得均方根误差尽可能的小**。

例：列文虎克计算弹簧的长度和负重关系：  
列文虎克通过在一个弹簧上加挂不同重量的砝码，计算出弹簧的长度和负重之间呈线性关系。  
假定弹簧在无负重时长度为b，悬挂x千克重物后长度为y，弹簧本身的材料系数为m。则可知弹簧长度和负重的关系为 y = m * x + b。  
此类实验中，m和b的值均需要使用实验得出，根据实验结果可知：

|重量(千克)|长度(厘米)|
|:---|:---|
|0|439.00|
|2|439.12|
|4|439.21|
|6|439.31|
|8|439.40|
|10|439.50|

因为这些点并未在一条直线上(相关系数为0.99)，穿过这些点的线可以有很多，但最适合的线中，**m和b将使得均方根误差为最小，这被称作最小二乘法，此时的y = m * x + b公式则为回归线**。  
此时数据的m为回归直线的斜率，b为回归直线的截距，这被称作**最小二乘估计**。**最小二乘估计，可以估计回归线的斜率和截距**。

相对于使用描述性统计方法（回归方法）拟合的数据，**使用最小二乘法拟合的数据会更加精准**，因为在正常实验和观察中，总会出现机会误差，导致使用一般拟合方法时存在误差。**使用最小二乘法拟合数据时，会使用到散点图中全部的点进行拟合；且因为取均方根误差最小的数据，则可以将随机误差降到最低**，得到的拟合回归线则会更加精准。

**最小二乘法和回归方法相似，但使用时机不同**。最小二乘法的使用时机则根据计算的实际情况而定。如果数据间相关性较强，可以使用最小二乘法进一步对数据进行更精准的拟合，如果相关性较弱，最小二乘法带来的好处相对较弱，则可直接使用回归方法。

## 回归是否有意义

回归直线可以在任何散点图中进行绘制，但是在计算回归线之前，需要了解：  

1. 变量间的关系是否为非线性关系，如果为非线性关系，则计算回归线会误导研究者。
2. 回归是否有意义：这应该基于数据产生的方式和逻辑进行判断，即因变量是否由自变量产生而产生，或者双方的内在关系。如果因变量和自变量之间没有完全的直接关系，而仅仅是间接关系。则计算回归线/回归方程仅仅会误导研究者，即便在相关性系数相对较强的情况下也是如此（毕竟相关性不同于因果性）

而针对多个影响因素共同影响数据的情况，则可以使用**多元回归**的方式*控制其他变量*。  
在拟合受教育年限和收入时，可以添加E：受教育水平，s：父母地位度量，相关公式则为 y = a + b * E + c * s

# 概率与机会

***统计：小范围样本推理总体；  
概率：通过总体推断下一次出现的小范围样本及其概率***

***机会的频数论，大多可以直接用于能够独立地在同样条件下一次又一次重复的机会过程***

***当某一个基本过程，在相同条件下独立地一次又一次的进行时，某事件的机会给出期望该事件发生的百分数***

例如扔硬币扔出1点的概率一直为六分之一。

机会的两个基本事实：  

1. 机会在0%至100%之间。如果某件事不可能发生，则机会为0%，反之某件事一定发生则机会为100%，一切机会则分布在这两个端点之间。
2. 对某件事的机会等于100%减去其对立时间的机会。如有45%的概率赢，则可推出55%的机会输。

## 终久论点

在随机情况下（保证每次测试均独立/互不影响，即实验对象外形/重量匀称，且每次实验后均将对象归位且打乱顺序），每个实验对象被抽取到的概率时相同的，即每个实验对象被抽取到1次的概率时相同的。无论是哪个分组的实验对象。

例：盒中装有若干外形/重量/手感完全相同，仅颜色（红色/蓝色）不同的塑料球，拿到红球得1分而蓝球不得分，以下哪种情况得分概率最高：  
* 盒中红旗3个蓝球2个  
* 盒中红球30个蓝球20个

两种方案下得分大体相同，因为两个方案中取到红球的概率相同，概率的计算均为：红球数 / 总球数，而不受蓝球/红球客观数量的限制  
这是因为在大量实验的情况下，两个方案抽取到红球的时间相同。第一个方案中，每个球同时被取到1次时，红球在3/5的时候出现，即取出数据的概率为3/5  
在第二个方案中，50个球的情况下，需要大约50次抽取后每个球被抽到1次，而红球将在30/50即3/5的时候被抽取到

***一件事发生机会的大小，将依据一件事发生的机会数 与一件事发生和不发生的机会数之比，即：发生概率 = 发生机会数 / 发生不发生的全部机会数。表示发生和不发生的概率的和为1，因为设想下两个概率的分子之和等同于公共分母***

在计算此类问题的概率时要注意，抽取实验对象后需要归位，保证每次抽取时样本对象完全相同。即取出球并记录后需要将球放回箱中并摇匀。

## 条件概率

***在求多次事件发生的概率中，给定第一次事件发生的条件，且第二次事件发生的概率被设置/基于第一次事件的结果，这种情况被称之为条件概率***

例：在一套52张扑克牌中抽取两张牌，如果第二张牌为红桃A，则得分，问：1.得分概率；2.翻开第一张牌为梅花7，求得分概率

1. 得分概率为 1/52，因为红桃A必定存在在当前牌中，一共存在52个可能的位置，故第二张牌抽取到红桃A的概率为1/52（红桃A出现在第一张牌中出现等同于未抽中）
2. 得分概率为 1/51，因为已确认了第一张牌的花色（并且在第二张牌抽牌时并未将第一张牌放回），即可以推断出在剩余的51张牌中（50张牌+第二张牌）中一定有1张红桃A，故第二张牌为红桃A的概率为1/51

上述例中，问题2中的概率1/51就被称之为**条件概率**，因为问题中被给定了第一次事件的条件，即：第一次为梅花7。统计时可以讨论：**如果**第一次为梅花7**且**第二次为红桃A的概率。  
同时，问题1中1/52则被称之为无条件概率，即没有限定第一次发生事件的概率。

***第二次为红心的概率可用数学公式P(第二次为红心)代替，P为概率/"Probability"缩写；已知第一次抽牌为梅花7，求第二次抽牌为红桃的概率可写为P(第二次抽牌为红桃|第一次抽牌为梅花7)，中间的直线表示"已知"***

## 乘法规则

***乘法规则用于求两个事件同时发生的机会，即两件事一起发生的机会等同于第一次发生的机会乘以已知第一次事件发生情况下第二件事件发生的概率***

例：盒子中存有三个分别印有"R","W","B"字样的卡片。首先从盒中取出一张卡片，之后再取出一张卡片（第一次取出卡片不放回），求第一次取出"R"而第二次取出"W"卡片的概率：

依据乘法规则第一次取出"R"字样卡片的概率为1/3，而第二次取出"W"字样卡片的概率为1/2，两者同时发生的概率为 1/3 * 1/2，即1/6。  
相关理解如下：第一次取出"R"牌的概率为1/3，这1/3的人中再进行一次取牌操作，取到"W"牌的人占1/3概率人中的1/2。  
或可以理解为：600人同时进行操作，其中200人取得了"R"牌，200人再次取牌后仅有100人取得"W"牌，这100人占全部取牌的600人的1/6。

## 独立性

***如果两件事被认定为互相独立，则如果给定第一件事，无论结果如何，第二件事发生的机会不变/不受影响；反之则证明两件事之间不独立***

比较标准的互相独立的事件是**抛硬币**：  
抛一枚硬币两次，两次抛出行为之间就是完全独立的：  
第一次抛出结果为正面不会影响第二次抛出的结果，即：第一次抛出正面的概率为1/2；第二次抛出背面的结果也为1/2；第一次抛出正面而第二次抛出负面的结果，根据乘法规则，则应计为1/2 * 1/2 = 1/4

例：盒中存在标识为"1","2","3"的黑色和"1","2","3"白色卡片各一套，从盒中随机抽取一张票时：  
1.抽取时发现票为黑色，则取出票面编号为"2"的概率为1/3  
2.抽取时发现票面为白色，则取出票面编号为"2"的概率同为1/3  
3.卡片颜色维度和卡片编号两个条件相互独立，因为：取出卡片的颜色不会改变卡片号码，故颜色和号码是相互独立的。

例2：盒中存在标识为"1","2","2"的黑色和"1","1","2"白色卡片各一套，从盒中随机抽取一张票时：  
1.抽取时发现票为黑色，则取出票面编号为"2"的机会变为2/3  
2.抽取时发现票面为白色，则取出票面编号为"2"的概率同为1/3  
3.卡片颜色和编号两个维度不独立，因为：取出卡片的颜色和编号出现的机会有关，即取出票的颜色不同，编号出现的机会也是不同的。

***随机有放回抽取时，各次抽取之间是独立的。不放回抽取时，各次抽取之间是不独立的***

***如果两个事件是独立的，那么两个事件同时发生的机会等同于各自无条件概率的乘积***

例：盒子中放置了5个卡片："1","1","2","2","3"；现在保持**有放回的方式抽取**，出现以下事件的机会为：  
1.第一次抽取为"1",第二次抽取为"2"的机会：2/5 * 2/5  
2.第一次抽取为"2",第二次抽取为"2"的机会：2/5 * 2/5  

当条件变为**无放回抽取**时则：  
1.第一次抽取为"1",第二次抽取为"2"的机会：2/5 * 2/4  
2.第一次抽取为"2",第二次抽取为"2"的机会：2/5 * 1/4

乘法规则这样的概率运算是为了处理机会游戏而创造的，在游戏中，可以在有限条件下进行多次重复的独立事件，但是现实生活中不存在如此完美的条件。  
***机会的数学理论适用于某些场合（条件/误差控制较强的场合）,而在另外一种场合中则会引起谬误***

## 枚举法/列举状态法

***在演算一个事件的机会时，有时枚举出/列出机会过程可能出现的全部状态是十分有用的；如果列出全部状态十分困难，则可以列出部分典型示例***。

例1：投掷*1枚*骰子，出现一个偶数的机会有多高  
使用枚举法时，可以列出全部可能出现的机会过程，此例中，任意投掷一枚筛子得到的机会过程为："1"，"2"，"3"，"4"，"5"，"6"六个点数；其中点数为偶数的机会过程为"2"，"4"，"6"三种。  
故,出现偶数的概率为3/6,即 50%。

例2：投掷*2枚*骰子，出现点数之和为2的情况即机会有多高  
使用枚举法列出所有可能：两个筛子的点数之间出现了笛卡尔积：  
筛子1:1,1,1,1,1,1,2,2,2,2,2,2......  
筛子2:1,2,3,4,5,6,1,2,3,4,5,6......  
最终根据乘法规则，第一此投骰子会有6种机会而第二次投骰子同样存在6种机会（1-6点），这两个骰子事件一起的机会一共有6 * 6 = 36个。  

    1，2，3，4，5，6  (第一次骰子结果)
    1
    2
    3
    4
    5
    6
    (第二次骰子结果)

而，投掷两枚骰子时，出现点数之和为2的情况只有一种，即"1","1"  
故，可知，出现两次骰子点数之和为2的情况的机会为1/36；  
**也可以通过计算乘法规则的方法求出此值，即：第一次投骰子得到1点的机会为1/6，而第二次投出骰子得到1点的机会也为1/6，两次机会相互独立，故两次投掷骰子结果为"1","1"的概率为 1/6 * 1/6 = 1/36***

如果引入第三个骰子，则情况还会再变化，即匹配得到的结果应为6 * 6 * 6= 216

## 加法规则

***加法规则：求两件指定事件中至少有一件发生的机会，先检查是否互斥/互不相容/不可能同时发生(检查是否会重复计算相容部分)，如互斥/互不相容，则可以将两次的机会相加***

### 互不相容事件

***两件指定事件中至少有一件发生的机会：或第一件发生，或第二件发生或两件都发生。其中两件事是否可能同时发生，由事件本身决定：如果两件事的发生互斥，即一件事发生会制止另一件事发生，则两件事不会同时发生***

从洗好的牌中抽出一张牌，这张牌*不可能即是红心又是黑桃*。  
如果为两个骰子投出得到"1","1"的结果这个事件，则不互斥：因为第一个骰子和第二个骰子结果之间相互独立。

例1：在52张扑克牌中，抽取1张牌，抽到红桃的概率是1/4,抽到黑桃的概率是1/4，问：收到红桃或黑桃的概率  
因为抽牌行为中，抽到红桃和抽到黑桃两个事件互斥（不可能同时发生），故相关概率为：1/4+1/4=1/2

例2：在投掷*2个*骰子时，得到*至少*一个1点的概率:  
因为投掷骰子这个事件中，每个骰子事件之间相互独立且互不影响，故无法使用加法规则(两个骰子皆投中1点的可能性会被重复计算)  
根据笛卡尔积可知：第一个骰子投中1点的事件为6，第二个骰子投中1点的事件数为6，而双方都投中1点的事件被重复计算了1次，故最终概率为(6+6-1)/(6 * 6) == 11/36；  
**或直接减去1次重复计算的双方皆为1的概率**：6/36 + 6/36 - 1/36 == 11/36

***何时使用加法规则而何时使用乘法规则，取决于：  
1、将机会过程简化为例1，例2两种情况；  
2、确定需要求出机会的事件  
随后试图将当前事件和已知机会的简单时间相联系，并计算简单事件中发生一次，或全部发生的概率  
当两个事件互斥时，如果想求至少一次发生的机会，则使用加法规则将两个事件的机会加起来  
如果想求全部发生的机会时，使用乘法规则***。

***通俗解释：  
加法法则应用于并列关系的事件  
乘法法则应用于不相干关系的事件  
如果把概率看成某些事件在样本空间中的占比，并规定数字1被分配到这些占比——也就是概率，则每一个概率都是一个小于等于1的实数。  
那么概率的乘法就是“一些事件在样本空间的占比”的乘法，由于所有占比（概率）都小于等于1，  
所以概率乘法是乘得越多其结果越小，这同时意味着某些事件的占比就越来越小了，换言之，它越不可能出现。  
比如：P(AB)=P(A)P(B|A) ，P(AB)实在太小了，小到比P(A)和P(B|A)都要小。如果有人先给出P(A)，要求你把它凑出P(AB)，那么你必须想办法把P(A)“压缩”至P(AB)为止，如此就给P(A)乘以一个小于1的权重让它变小至P(AB)吧。那么这个权重究竟是多少呢？对比P(AB)和P(A)，前者占比之所以比后者小是因为它要求事件A和B同时发生。因此你只需要找出一个占比让A缩至A∩B。现在考察P(B|A)，如果把P(B|A)看成事件B在样本空间A中的占比的话，那么很显然为了找出A与B的重合部分A∩B，你只需要将P(B|A)这一占比乘到P(A)上去。于是有P(AB)=P(A)P(B|A)P(AB)和P(B|A)之所以不一样是因为他们的样本空间不一样(前者是Ω，后者是A)，彼此的占比完全不是一回事。  
至于概率的加法，互斥的事件在样本空间中不重合，所以它们的占比之和可以直接作为几个互斥事件在样本空间的占比***。

***有时通过直接计算难以计算出机会的情况下，可以转换思路，即通过赢的机会 = 100%-输的机会，这一个定律入手，通过计算出每次输的机会/对立的机会再用乘法规则相乘，之后用100%减去结果，即是成功机会***

注意：实验以及计算过程中，所有条件均为理想条件，即骰子完全对称，每次投掷力道相同，且骰子没有灌铅。反之结果机会会有很大不同。

# 二项系数

***二项系数主要用于计算多次相互独立的事件中，某一个特殊事件出现的机会。例如：  
投一枚骰子10次，恰好得到3个1点的机会***

例：盒中存在1红球及9黑球，进行**随机放回**形式的抽取5次后，求恰好有两次取到红球的机会：  
使用枚举法可知，满足条件的形式可为：RRBBB形式，出现此类形式的机会为：1/10 * 1/10 * 9/10 * 9/10 * 9/10，即为(1/10)^2 * (9/10)^3。  
满足条件的另一个形式为BRBRB，出现此形式的机会为：9/10 * 1/10 * 9/10 * 1/10 * 9/10，同样可以被计为(1/10)^2 * (9/10)^3。  
经过实验发现，RRBBB形式和BRBRB形式机会完全相同，实际上每个恰好抽取到2个红球和3个黑球的形式下的机会都是相同的，这是因为抽取到2个红球的RR形式贡献了(1/10)^2的机会，而3个黑球BBB的形式贡献了(9/10)^3的机会，再根据乘法规则，两个形式组之间需要使用乘法连接。故，所有形式机会之和应等同于 *形式的个数 * 公告的机会*。  
而计算每一个2R3B形式的数量，得到的就是形式的个数。  

***二项系数可以计算多次独立事件中，一个固定形式出现的全部次数**  

***一个互相独立的事件中，一个固定形式出现的全部机会 = 二项系数求出的固定形式出现次数 * 成功时的机会^成功事件次数 * 失败时的机会^失败事件次数***

就上例而言，相关等式为 (5*4*3*2*1)/((2*1)*(3*2*1) = 10，即2R3B的格式会有10种搭配，最后等式为 10 * (1/10)^2 * (9/10)^3 = 7%

为了保证总结出的二项系数数据不会特别凌乱，数学家在一个数字前使用 **!表示阶乘/连乘，即这个数字与它前面的所有正整数一起相乘的结果**  
例：4！ = 4 * 3 * 2 * 1 = 24，读作*4阶乘等于24*，其中数学约定 0! = 1  

故，上例公式可以改为 5! /((2!)*(3!)) ，这是将 2R3B排列成一行的所有组合；分子种的5是分母中2和3的和。

例2：4R1B的排列方式组合个数：5！/(4！*1！)

## 二项系数公式

***一个事件在n次中恰好发生k次的机会由以下公式计算n!/(k! * (n-k)!) * P^k * (1-P)^(n-k)  
其中：n为实验次数，k为事件发生的次数，P为任何一次特定的实验时，k事件发生的次数  
使用二项式系数公式的条件为：  
1、n的值必须事先规定  
2、P的值必须对每次实验都是相同的  
3、实验必须是互相独立的***

例：一个骰子掷10次，得到两1点的概率：  
根据条件，每次骰子事件均为独立事件，且规定了总实验的次数，故可以使用二项系数公式：  
n=10,k=2,P=1/6；则二项公式为：10！/(2!*8!) * 1/6^2 * 5/6^(10-2) == 29%  

例2：投一枚骰子，直到出现6点为止，求出现2个1点的概率：  
因未规定事件次数，故无法使用二项系数求解。如果实验次数仅为1次，则实质是求投一次骰子结果为6的机会，以此类推

例3：随机放回的从装有1，1，2，3，4，5六个卡片的何种抽取10次，最后一次抽取前拿掉盒中的5号卡片：  
无法使用二项系数，此实验中实验次数给定，但最后一次实验前要拿掉卡片5，则最后一次抽取的概率将变为1/5而不是之前的1/6，故不能使用二项系数。

# 平均数率

作为互相**独立**的实验，一枚硬币**每次投掷时有50%的概率投出正面，且无论上次实验的结果是什么，故不会出现之前几次/上次投掷的硬币为正面，则下次投掷一定为背面的情况**。  
**补偿对于平均数律不起作用。举例而言，抛了10次硬币之后获得了10次正面，但平均数律并没有对第11次抛掷获得反面的概率进行补偿，它依然是50%**。  
经过大量测试之后，**投到正面的数量理论上等于投到背面的数量**。但实际情况下，因为机会误差出现的原因，**正面数=抛次数的一半+机会误差**；故从结果上看，**抛到正面的次数和期望数（总抛次数的一半）不会相等，且之间数量差距较大，但是和抛的次数的比值/比率差距很小**；这是因为，机会误差随着抛硬币的次数不断积累，故绝对数量会相当的大。而，随着抛硬币的次数进一步增加，则机会误差和总实验次数的比值/比率会相对**变小**。故最终可知：**相对硬币实验的初始部分，随着实验的进行，硬币抛到正面的次数和期望数（总抛次数的一半）的差值将上升，而比率将越发接近期望比率（50%）**

每次投掷硬币，抽到 正面 和 背面 的概率分别是 50%。所以10000次投掷后，我们期望获得5000**左右**的 证明 和5000**左右**的 背面，二者之和等于10000。这就是平均数律，它告诉人们***机会过程的结果是一个随机变量，但它不会偏离平均值太远**8。

**平均数率一般以百分数为措辞重述，尽管数据投出正面的百分率不会刚好是50%，但是在大量实验的基础下，将会尽量向50%的机会靠近**

## 机会过程

***机会过程是指一系列独立重复的随机试验，并且机会过程可以被抽象为盒子模型***。

通过上述实验数据可知，*因为机会误差出现的原因，事件数量会收到机会误差的影响，使其不再完全等同于预期数量*，这被称之为**机会变异**。故，计算机会误差造成的差距数量则至关重要，即计算*机会过程中确定的数据的误差*。在实际生活中，因为出现得机会变异，每次抽样得到得数据结果将不尽相同，有时这将影响到实验得结果；

例1：轮盘赌中输或赢的金额，或者说轮盘赌博本身即是一个机会过程，而赢或输的金额依赖于结果，且互相独立：轮盘再次旋转后，之前的赢家有可能变为输家。  
例2：通过抽样调查的方式，抽取部分选票，选票中民主党人所在的比率；此例中，抽取流程即为随机过程。所以，样本中民主党人的数量由运气绝对，且每个样本中的比率不同，另一个样本中，民主党人所在的比率很有可能出现微量不同。

机会过程控制的主要原则：***盒子模型***  
在所研究的过程（例如抽取选票）与从盒中随机抽取数之间的相似处  
把研究事件中的变异（民主党选民的估计），与从一只盒子中抽取的数之和的机会变异/机会误差之间建立联系。

***机会过程不是随机过程，因为机会过程的试验之间不具有时间相关性。举例而言，在一个盒子中有放回地抽取100次与同时在100个相同的盒子中抽取一次没有任何区别***。

***盒子模型：一个机会过程与从一盒中做抽取，这两者间的类似被称之为盒子模型；这是因为，如果将机会过程事件抽象为从盒中抽取数字之和的机会变异在数学上更加容易分析，许多负责的过程/事件都可以通过这种方法抽象并进行分析处理***。

机会过程和使用二项系数公式计算的数据不相同：**使用二项式系数计算数据时，已经给定了结果，仅仅在求结果出现的机会**。机会过程则在研究**指定条件和次数下出现的结果，和不同结果出现的机会**

## ‍机会变异（机会误差）‍

***机会过程的结果相对于平均值的偏移称为机会误差***。

机会误差可以是绝对误差：  
10000次抛硬币试验获得的头像总数 - 5000

也可以是相对误差：  

    absolute（10000次抛硬币试验获得的头像总数 - 5000）/ 5000

***机会变异告诉我们：  
当抛的次数增加时，头像数与抛的次数的一半之间的差变得较大，但是头像的百分比与50%之间的差异却变得较小。
也即，随着试验次数增加，绝对误差有增大的趋势，而相对误差有减小的趋势。***

## 盒子模型‍

每次抛硬币可以类比成从一个盒子中有放回地抽卡片，这个盒子里只有两张卡片，上面分别写着 0 和 1。

如果用卡片 1 代表头像，则10000次抽取后，所有取得的卡片数字的总和就等于在抛硬币10000次后获得的头像数。
从一个盒子中*有放回地抽取*标有数字的卡片就是一个*机会过程*，而我们关注的随机变量是卡片上数字的和大概有多大。

### 抽得数之和：盒子模型的基本形态

例子：盒子中存在6张卡片【1，2，3，4，5，6】，随机从盒中抽取一些票，求抽取得票总数之和。抽取事件基于**随机放回**步骤：抽取前摇动盒子混匀卡片，抽取时随机取出卡片并记录，抽取后将卡片放回盒子中并摇匀，准备下一次得抽取。  
**有放回**规定了每个抽取事件均为独立事件，即确定了每个抽取事件基于同样调剂，存在相同概率。  

如果，随机有放回得抽取两次，每次抽取1张卡片，求两次抽取卡片得总数之和(第一次3，第二次5，总数为8；第一次3，第二次3，总数为6)存在多种可能，**因此2次抽样数据得到数据加和后得值受机会误差得影响：如果抽取得到得数据为1种情况，则它们得和为一种情况；如果抽样的状态不同，则得到的和也不同**。  
问：从盒中抽取25次，结果之和大概有多大。  
因为每次抽取的卡片不同，而卡片之和也不仅相同，故重复25次抽取的事件10次，最后得到的结果也不尽相同；  
通过计算机重复进行实验可知，数据结果为88，84，80，90，83，78，95，80，89。值的范围从最小的78到最大的95，出现了肉眼可见的分布变化。  
原则上来说，值得变化范围可为25 * 1 直至 25 * 6；而实验中数据的分布范围为75-100。而随机过程则在研究：随着实验次数的继续增加  
1.数据的趋势是否会保持不变  
2.和所在75-100区间的机会为多少  

上例即为大富翁类游戏中常见的一种规则：投一对骰子，根据两个骰子得到的结果之和确定在游戏中前进的步数。掷骰子即可抽象为从盒中取卡片。

### 建立盒子模型

***盒子模型构建的目的，是为了分析机会变异，在构建盒子模型时，有三个基本问题需要先考虑：  
1.什么数字进入盒中  
2.每一种数字有多少张  
3.抽取的次数有多少***

盒子模型的使用：以Nevada赌轮为例：  
Nevada赌轮中存在38个球袋（38个选项）00,0,range(1-36)，除了0，00两个涂有绿色的球袋，其余36个球袋交替涂有红色/黑色两种颜色。旋转转盘并将球放置到盘中，让其落入到38个球袋中，根据打赌的游戏规则确定输赢；  

规则1：猜花色，如果落入红色球袋赢（本金 * 2），落入黑色或绿色球袋则输（失去全部赌注），每次押注1元；  
针对此类问题可以使用盒子模型：  
1.针对盒子内数据：因为模型仅涉及到挣钱和亏钱，则盒中票需标注+-1元  
2.每一类卡片的数量：例子中，18个红色球袋落入1个就算赢，18个黑色球袋和2个绿色球袋落入1个就算输，故应该准备38个卡片，其中18个标注了+1元，20张-1元，即：【18张1元，20张-1元】

就涉及到的机会来说，把1元押在红色球袋就相当于从上述盒子中抽取1张卡片。  

***盒子模型的最大好处，就是可以撇去研究事件中所有不相干的细节，仅仅表示/突出最重要的信息***，例如此例中的赌场，轮盘，荷官等。

求问题：每次押注红色，进行10次，求净利润：  
回到盒子模型中，进行10次赌博相当于有放回在盒子中随机抽取10次（两者均为独立事件且机会均等）。净利润则是这10次抽取的标数之合。  
作为可能的结果，10次抽取结果可为：R,R,R,B,G;R,R,B,B,R（R:Red；B:Black；G:Green）；结果及净利计算如下：

|赌博状态|R|R|R|B|G|R|R|B|B|R|
|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|输/赢钱数|1|1|1|-1|-1|1|1|-1|-1|1|
|净利|1|2|3|2|1|2|3|2|1|2|

根据上述规则：净利润根据抽得卡片标注的金额总额进行计算，得到红色净利润+1，得到绿色合黑色净利润-1；故净利润为2。

规则2：押1元至Nevada轮盘中任意数字，数字出现时赢35元，出现其他数字时输掉押入的1元（这被称之为打1赔35），如果进行100次实验，且每次都花费1元押在数字17上，净利润应是随机放回式的从盒中抽取多少次得到数据之和。  
解析：设定盒子规则：规则中赢得到35元而输得到-1元，故牌面中仅为+35及-1两种；根据规则，只有从38个球袋数字中取到指定的1个数字就算赢，反之37个取到事件被算做输，故牌中存在1个+35牌及37个-1牌：【1张35，37张-1】  
抽取的次数需要合进行实验的次数相同，即为100次，且每次抽取之后需要放回，从而不改变每次实验的机会。

***盒中标明在单次下注中能赢/输的各种不同的金额；  
从盒中抽取的任何一个特定数字的机会必须等于单次下注时赢得那一金额的机会（此处为数学上的赢，赢得一个负金额等价于赌博中输掉这个金额）  
抽取的次数等同于下注参赌的次数  
净利润等于所有卡片标明数据之和***

# 期望值与标准误差

***随机过程中产生的数围绕着数据的期望值进行变化，变化的幅度基本上遵循标准差。  
如果机会过程仅仅产生了一个数据，则此数据将会在期望值和周围大概相差了一个标准误的某处***。

## (机会过程中的)期望值‍

例：从盒【1,1,1,5】中*有放回的随机抽取*100次，求抽得的卡片总数。  
题中使用有放回且随机的方式抽取卡片。故每次抽取卡片的过程均为随机。其中卡片总数为4，包含1个5号及4个1号卡，故单次抽取到1号卡的机会为3/4，而抽取到5号卡的机会为1/4；  
故，100次抽取后，应获得100 * 3/4 = 75张1号卡和 100 * 1/4 = 25张5号卡。故最终分数之和为：25 * 5 + 75 * 1 = 200。  
此时的"200"即是期望值。

***当每次随机有放回的从盒中抽取卡牌时，每次抽取都将抽取一个大约等于盒子中卡片号平均数的量***

故，总结可知：  
***随机放回地从盒子中抽取所得数之和的期望值等于（抽取次数）×（盒平均）  
盒平均数，即单次的平均期望值 = (盒中全部卡片点数之和) / (盒中全部卡牌数)***

上例中，盒平均数 = （1+1+1+5）/4 = 2；故最终，此例中期望值应为：2 * 100 = 200

例2:假如有这样一个盒子：  
【1，1，3，5】

它的盒平均是：  
（1+1+3+5）/ 4 = 2.5

如果做100次抽取，我们期望卡片和为：  
100 × 2.5 = 250 左右。

***机会过程的期望值其实就是之前提到的平均值***。

例3：游玩Keno游戏时，规则上押1元钱有1/4的机会赢且获得2元回报（并收回本金），输一次则失掉本金，求进行100次游戏后的利润。

根据上述规则可建立盒子模型：【-1，-1，-1，+2】，盒平均为：（-1-1-1+2）/4 = -1/4，即每次游玩期望值为-0.25，而100次游玩后应为-25元。

## （机会过程的）‍标准误差/SE‍与平方根法则

***在实际情况下，盒子模型的期望值和实际值并不相等，这是因为存在机会误差的原因，实际盒子模型的最终值应等于 期望值 + 机会误差  
SE是什么呢，一般来说，自然界里很难获得总体数据，我们只能用样本（无论是各种实验还是社会调查抽样）去近似估计总体，这样问题就来了，估计的准不准（平均值）？
我们可以理论上这样做，既然不能获得总体，我们可以尽可能多（无限）的从标准差为σ的总体数据里抽取大小为 n 的样本，每个样本各有一个平均值，所有样本平均值的标准差就可以用"68-95-99.7法则"(即约 68% 数值分布在距离平均值有 1 个标准差之内的范围，约 95% 数值分布在距离平均值有 2 个标准差之内的范围，以及约 99.7% 数值分布在距离平均值有 3 个标准差之内的范围)评估准不准了（这就是所谓的置信区间），样本平均值的标准差可以被证明如下公式表达：SD = σ/平方根(n)  
但由于通常σ为未知，此时可以用研究中取得样本的标准差 (S) 来估计：SE = s/平方根(n)  
这就是SE的来源，即样本平均值的SD***。

***‍‍平均数律与‍机会变异定性地描述了机会误差与试验次数之间的关系。而标准误差可以定量地衡量机会误差。  
一个和可能在它的期望值附近，但是偏离一个其大小与标准误差相似的机会误差  
最终值的机会误差和抽取总结果相关***。

为了计算一个抽取中的机会误差，可以使用**平方根公式/平方根法则**:  
***如果随机变量之间是独立的，那么随机变量和的方差等于随机变量方差之和，即: 方差(X+Y) = 方差(X)+方差(Y)  
因为一般情况下，我们使用的都是标准差而非方差，则使用标准差的方式表示上述公式为: 平方根(X+Y) = 平方根(X) + 平方根(Y)***
***而在从装有标上数字的卡片的盒中作随机有放回的抽取时，抽得数之和的标准误差是***：

                SE = 平方根(开根号)/SquareRoot ( 抽取次数/样本量N ) ×（盒子的SD/σ）

公式由两个部分组成：*抽取次数的平方根* 和 *盒子的SD*；  
这里的机会误差是绝对误差，SD是盒子中卡片数字的标准差，此时的SD用于测量盒子中所有值的散布，显示了数字的离散程度。  
可以看：**出机会误差随着抽取次数的增加而增加，但是增加的速度慢于抽取次数（抽取次数越多，结果更加无法预料，但因为平方根的存在，抽取造成的误差增加速度相对较缓慢）；盒子中卡片的数字差异（SD）越大，机会误差就越大**    
后者不难理解：  
【5，5】，【1，9】  
这两个盒子具有相同的盒平均（等于5），左边的盒子SD=0，无论抽取多少次都没有机会误差。右边盒子SD>0，它具有机会变异的可能。

***而针对抽得结果的平均数/均值进行求标准误差处理的话，则需要将抽得结果的和的标准误差除以抽取数据N***，结果如下：  

    SE = 平方根(开根号)/SquareRoot (抽取次数/样本量N) x (盒子的SD/σ) / 抽取次数/样本量N
    则此公式可以简写为：
    SE = (盒子的SD(σ))/平方根(开根号)/SquareRoot (抽取次数/样本量N) 

***平方根法则的原理是互相抵消：每当抽到高于平均数的值时，抽到低于平均数的值的情况也即将发生；  
故，最终误差将被抵消到一定程度，故抽到的数之和相对接近于期望值***。

【标准差SD】 和 【标准误差SE】 不同。前者衡量**一系列数字的离散程度**，后者衡量**机会过程中的机会变异**：  
***1.标准差（SD）更能反应离散程度。  
paper里需要Mean±SD这个信息，就是便于读者进行判断数据的离散性，e.g.，一般我们把偏离平均值2或3个SD的值作为outlier（i.e., 异常值）。  
2.标准误则比较适合用于评估精确性或准确性的问题。  
paper里根据需要也可以提供Mean±SE这个信息，就是便于读者进行判断数据的不确定性，e.g.，95%置信区间是用的Mean ± 2 * SE***。

例：针对盒子【0，2，3，4，6】  
有3种抽取方案，分别是抽取25次、100次和500次，每种方案执行100次

盒平均 = （0+2+3+4+6）/ 5 = 3
卡片标准差 = 2

所以三个方案的期望分别是：3*25=75,  3*100=300,  3*500=1500  
所以三个方案的标准误差分别是：squareRoot(25)*2=10,  squareRoot(100)*2=20,  squareRoot(500)*2=44.72

最后分别求出了3种方案平均机会误差的绝对值和相对值。

从结果可看出: ***随着试验次数的增加，机会误差发生变异，变异的趋势是：  
绝对误差增大，相对误差减小。  
并且绝对误差在标准误差附近  
原则上来说，机会过程最后的结果的绝对误差可以为0，而最大可为25 * 6；但大多数情况下不会超过2SE - 3SE***。

## 正态曲线与机会过程

***当实验/事件的次数达到一定程度(充分大)时，可以利用正态曲线计算机会过程之和落在一定范围内的概率***。  
可以发现：***随机过程得到的数据之和符合正态分布，即因每次抽得总数之和的机会误差，数据分布在期望值左右。此时期望值可被视为正态曲线的平均数，而标准误差则充当正态分布中的标准单位的角色***。

根据上述定理可知：***正态分布曲线下的面积即为随机过程数据之和落在指定数据（正态曲线面积的两个端点）下的机会***；  
上述方法一般用于计算**随机过程数据之和在某个指定范围之内的机会，具体步骤为：  
1.基于实际情况设置盒子模型  
2.基于盒子模型中的卡片及面值计算期望值和标准误差  
3.基于期望值和标准误差及范围数据拟合正态曲线，标准单位  
4.基于标准单位拟合正态曲线下的面积，最终计算出在指定范围内的机会**。

例1：针对盒子【0，2，3，4，6】  
抽取25次，求数据在50-100之间的机会。

上例中：  
单次期望值 = (0+2+3+4+6)/5 = 3  
整体期望值 = 3 * 25 = 75
标准差 = 平方根(((0-3)^2 + (2-3)^2 + (3-3)^2 + (4-3)^2 + (6-3)^2)/5) = 2  
标准误差 = 平方根(25) * 2 = 10  
根据提供的要求（50-100范围内的机会）可知，此范围的左右端点为50和100，根据上方计算可知：  
50所在位置的标准单位为(50-75)/10 = -2.5 SD；100所在位置的标准单位为：(100-75)/10 = 2.5 SD；  
根据正态表中数据，+-2.5SD所在正态曲线中面积为99%，即可得出结论:上述例子中的情况，连续进行25次事件的数据和，在50-100范围内的数据应占99%。

***对于标准正态分布，随机变量落在 [-SD, +SD] 范围内的概率是68%，[-2SD, +2SD] 范围内的概率是95%***。

例2：针对盒子【0，2，3，4，6】  
有3种抽取方案，分别是抽取25次、100次和500次，每种方案执行100次

类比上面的第二个方案，期望值是300，标准误差是20，对应的1个标准误差范围是 [280, 320]，2个标准误差范围是 [260, 340]。经过统计，落在 [280, 320] 内的方案执行数是72个，接近68%的比例；落在 [260, 340] 内的方案执行数是96个，接近95%的比例。

例3：Nevada赌轮下，赌徒每次仅将1元押在红色部分上(38个球袋中占据18个球袋)，进行10000赌博，求*庄家*净利润超过250美元的概率。  
根据之前的条件可知：押颜色游戏中，压1元时赢得1元(本金返还)，输时本金不返还；故，根据上述全部规则，盒子模型可为：  
【20个1，18个-1】（**根据上述规则，此时计算得是庄家得净利润，因为庄家和赌徒在此模型内为对头，故庄家赢时赌徒输，故代表得18个黑色和2个白色为赢时得颜色**），  
单次期望值：(1 * 20 - 1 * 18) / 38 = 0.05元，即每次赌博庄家平均赢0.05元  
10000次时间后得期望值：0.05 * 10000 = 500 元  
标准差：1元
标准误差：平方根(10000) * 1 = 100元
利润超过250美元所在得标准单位：(250 - 500)/100 = -2.5 SD  
根据正态表可知：+-2.5所在位置占全部曲线得99%，故之外得位置共占1%左右，而一边占0.5%；故-2.5起始至百分位数100%，共占正态曲线得99.5%。

上例说明了为什么十赌九输的原因：***因为在期望值的净利润为负的情况下，一切赌博的事件的最终净利润都会是负数***。唯一给赌徒的救赎，就是标准误差。

## 输赢仅有两种面值的情况下，计算标准单位/标准差得方法

***当盒中仅有两个面值的卡片（输和赢两种情况下的卡片）时，可以使用一条更加简便的方式计算标准单位/标准差：标准单位/标准差 = (卡较大面值数 - 卡较小面值数) * 平方根(较大面值卡占比 * 较小面值卡占比)***。

例：针对盒【1，1，1，5】，求标准差：  
因盒中票的面值仅有5和1两种，故可以使用次方法求SD：(5-1) * 平方根(1/4 * 3/4) = 1.73

例2：赌徒在赌Nevada赌轮时，每次均花1元押10号球袋上，已知当前规矩为打1赔35（押1元，赢时得35元；输时输掉本金。），求100次游玩后得期望值和误差  
根据上例可建立盒子模型：【1张卡+35元，37张卡-1元】  
故，单次平均期望值：(35 * 1 - 37 * 1)/38 = -0.05元，即平均每次时间赌徒将赢-0.05元（输掉0.05元）  
100次游玩得整体期望值为：100 * (-0.05) = - 5元，即100次游玩后，赌徒将赢得-5元  
因例中盒子模型仅存在两个面值得卡片，故可以使用快捷方法求标准差：(5-1) * 平方根(1/38 * 37/38) = 5.76  
故标准误差应为：平方根(100) * 5.76 = 58元，故赌徒进行100次随机过程后，净利润应为-5 +- 58 元（**大SE给予赌徒赢得更多钱得诱惑，但是也有可能输的更惨**）

## 分组与计数

使用平方根，可以**计算某些随机过程中的数量及其标准误差**，前提条件是需要正确的建立盒子模型。  
***根据需要进行的随机过程中的新条件（针对特定牌面值的计数），应通过修改并建立新的盒子模型的方式模拟新的情况***。

例：投骰子60次，求：1、骰子总数的范围和标准误差；2、6点出现的个数和标准误差；  
根据上例可建立盒子模型：【1，2，3，4，5，6】，  
故平均单次期望值为：(1+2+3+4+5+6)/6 = 3.5  
故60次投掷的期望值为 60  * 3.5 = 210  
经过计算可知：盒中面值标准差/SD为 = 1.71  
故标准误差为：平方根(60) * 1.71 = 13  
故，第一题中，60次掷骰子总数在210上下13左右

针对第二题，应修改之前的盒子模型：题中希望得到骰子投出"6"的次数，根据新的条件可知：一个骰子中仅有一个"6"，而仅有投中"6"可被设置为赢(为了计数，投中"6"可计为1，未投中则投中"6"的次数应不变，即为0)；  
故：新的盒子模型可以修改为：【0，0，0，0，0，1】，即投中1时投中"6"的次数加1，反投中"6"的次数不增加  
此时，单次平均期望值为：(0+0+0+0+0+1)/6 = 1/6，即投6次中会有一次投中"6"点，和投中"6"点的机会相同  
经过60次投掷后的期望值为：60 * 1/6 = 10，即投60次骰子中，会有10次投中"6"点。
此时，因牌面中仅有【1，0】，故可使用快捷方式计算标准差/SD：(1-0) * 平方根(1/6 * 5/6) = 0.37  
故，标准误差为：平方根(60) * 0.37 = 3  
最终可知：投60次骰子中，投中"6"点的次数为10次左右+-3。

**尽管很多机会过程相关的问题看似不同，但是可以使用相同的方法进行解答**：  
就上例而言，问题被分为了2类：  
1.随机从盒中抽取部分票，对抽取到的数据实施运算，并要求返回给定区间内的机会（例：从盒【1，2，3，4，5，6】中随机抽取60次，求总和在200至225之间的机会）  
  **此时抽取一般作为定量数据的来处理，一般可以相加，且对抽取所实施的运算为加法（此次抽取的点数是多少，并加总到总和数量上）**。
2.随机从盒中抽取了若干数量的卡片，求某一个标号卡片出现的次数，及在给定范围内出现的机会（例：从盒【1，2，3，4，5，6】中抽取60次，其中抽得"6"的次数在10-20之间的机会）  
  **此时的抽取是作为定性数据来处理的，对抽取到的数据实施的是分类和计数（每次计算时，在求得是：此次抽取中得到得结果是否为"6"，随后增加抽取"6"的次数）**  
故，***针对相似的问题，可以使用定量/定性；加法/分类计数两个方法，但是从根本上，仅仅需要通过改变盒子模型就可以实现不同方向的计算***。  

***如果必须对抽得的数据进行分类和计数，则可以改变盒子模型；将盒中卡片计为0/1两个类别，其中需要进行计数的卡片计为1而其他卡片计为0***

例：针对抛硬币得到正面的计数：抛硬币100次，1、求得到正面的次数范围；2、和次数在40-60之间的机会。  
根据例题可知，抛硬币共有两个可能结果：正面(赢)和背面(输)，故可设置盒子模型为【1，0】  
根据盒子模型可知：单次抽取到到正面的期望值为(1+0)/2 = 0.5，即每次投硬币，得到正面的次数是0.5次，  
故根据题中100次投掷要求下，得到正面的期望值为：100 * 0.5 = 50，即投掷100次硬币应得到50次正面；  
因盒子模型中仅有【1，0】两个卡面，故次模型可以使用*平方根法则*计算标准差/SD：(1-0) * 平方根(1/2 * 1/2) = 1/2  
故，此模型下的标准误差/SE应为：平方根(100) * 1/2 = 5；  
故综合上述条件可知：投掷100次硬币可得到50次左右+-5的正面；  

同时，根据上述条件可知：40-60次数在此随机过程中形成的正态曲线所在的标准单位为：40：(40-50)/2 = -2SD；60：(60-40)/2 = 2SD；  
根据正态表可知：+-2SD所占正态曲线的面积为95%；故可知：投掷正面次数在140-60的机会为95%；

## 平方根法则与平均数率

***假设抛一枚硬币大量的次数，根据平均数率可知：正面数 = 抛出正面的期望值 + 机会误差；  
根据平方根法则，抛硬币事件中的机会误差 = 平方根(抛硬币次数) * 1/2(抛到正面的SD)  
标准误差随着抛硬币的次数而增加，例如在抛10000次硬币时，标准误差为平方根(10000) * 1/2 = 50；  
当抛硬币的次数增加至1000000时，标准误差同样增加。不过因为计算时使用了平方根的原因，在1000000次抛硬币下，标准误差为 500。  
即：当抛硬币的次数增加时，标准误差/SE的绝对值将越发上涨，但是相对于抛硬币的次数而言，因为进行了平方根计算的原因，标准误差相对减小；  
这就是随着抛硬币次数的增加，抛到正面的比率相对增加且接近期望值50%的原因；平方根法则就是平均数率的数学解释***

# 概率直方图的正态近似

按照平均数率，一枚硬币在被投掷充足的次数后，正面出现的比率应接近50%。此实验是基于以下假设进行的：每次抛硬币都是独立的，且每次抛硬币的结果，即出现正面/背面的机会是均等的。  
基于平均数率可知，在抛出5次硬币时，正面和背面互相存在 2^5=32 个不同的组合，在这32个组合中有20个组合抛到正面的机会接近一半（5次事件中存在2或3次正面）；

根据之前的发现，平均过程可以使用正态曲线进行拟合；而实际上，平均过程拟合正态曲线的过程使用的是平均过程**概率直方图**拟合而成的。通过拟合后的正态曲线，可以计算任意投中正面的情况的机会。

## 概率直方图

如之前所说，直方图存在的意义便是使用面积表示各个分组的占比。概率直方图也不例外。  
***概率直方图表示的是指定箱(Bin)下的总体机会，而不再是绝对值数据***

类似于其他类型的直方图，**概率直方图用面积表示实验中指定组出现的次数占总实验次数的百分比**；  
例：投两个骰子10000次，求每次的点数之和；  
针对前100次投骰子得到的结果，其中投得点数之和为7的次数为20次，占全部100次投骰子的20%；  
故，在针对前100次投骰子事件的概率直方图中，点数7所在的直方图的面积应占20%。  

在经过100次，1000次及10000次事件之后，随着事件次数的上升，每次观察时的经验直方图（由实验观察到的结果绘制的直方图）将逐步收敛成为理想的概率直方图，即在大概率上拟合了对应的正态曲线的概率直方图。

***概率直方图使用面积表示机会，直方图由矩形组成，对于抽得数之和，每一个矩形的底以可能值得中心（例如上例中，可能值为7，则图形底为6.5-7.5的位置），矩形得面积为获得该值得机会，直方图得总面积为100%***。

一般情况下，概率直方图中，每个可能的值为一个单独的箱(Bin)，而每个箱都存在一个指定的占比，即是Y轴对应数据。

## 概率直方图与正态曲线

概率直方图和正态曲线的绘制方法中存在一定不同：根据上方经验可知：概率直方图跟进每个单独的箱和箱对应的占比进行绘制；通过概率直方图及原事件提供的数据可绘制正态曲线，而正态曲线则使用标准单位为底，且Y轴单位为针对每个标准单位所占的百分比形成对象的面积绘制而成（可以使用标准单位/标准误差换算关系搞清每个标准单位下所占的面积）。

通过绘制100次，400次及900次抛硬币得到正面的次数的概率直方图可以发现：直方图和正态曲线的拟合越来越好，从之前的略有锯齿至之后的完全曲线拟合；  
这也正面了平均数率的存在：随着实验次数的上升，数据分布逐渐收敛

## 正态近似：正态曲线推算出现次数机会的逻辑原理

例：1枚硬币抛100次，求正面数：  
1.在45-55之间（含端点）  
2.在45-55之间（不含端点）  
3.恰好为50

针对之前得到的数据可知：  
此例中，100次抛硬币得到头像期望值为50  
此例中标准差为1/2  
此列中标准误差为5

使用概率直方图求解时，问题1：  
问题1可化解为概率直方图中，底数为45-55的箱的面积之和；因为概率直方图和正态曲线之间拟合度很高，则实质等同于求至此段正态曲线的面积。  
而在概率直方图中，箱的面积为底数四舍五入的值（45：44.5-45.5）  
故，此问题所求结果为概率直方图中，底数在44.5至55.5之间的面积  
44.5和55.5，通过转化为标准单位后，数据为-1.1 和 1.1  
故，实质上是在求标准单位-1.1 - 1.1 之间正态曲线的面积  
根据正态表可知,-1.1 - 1.1之间的面积占正态曲线的72.8%，  
故题1结果为72.8%

问题2：不含端点时的45-55之间的（不含端点）机会，等同于概率直方图中46-54之间的直方图的面积；  
即45.5-53.5之间的面积  
等同于+-0.9个标准单位之间的面积  
根据正态表可知，+-0.9个标准单位之间的面积可约等为68%，故题2中机会为63.19%

问题3：正好在点50（期望值）位置的机会，等同于概率直方图中底数为50所在的箱的面积；  
即49.5-50.5之间的面积，换算为标准单位为+-0.1SD  
根据正态表可知，此处面积占7.97%；故最终得数为50时的几率为7.97%

***正态近似，是在计算概率直方图的面积之前，使用正态曲线替换实际概率直方图进行计算的方法；这种替换仅能在概率直方图符合正态曲线时才合理。  
近似的意思是：概率直方图的面积常常难以计算，而正态曲线下的面积则可以使用正态表进行查询***。

**通常情况下，如果问题仅仅要求回答两个点之间的机会，且没有规定端点，则可以直接将机会之和换算成，标准单位后进行正态曲线面积的计算，计算端点得到的机会结果固然精准，但如果矩形面积不大，或没有特意对端点/精度进行要求，则可以使用此种方法近似的得出机会**。

## 正态近似的范围

***针对从盒中抽取的情况，盒中诸数的直方图偏离正态曲越大，则在取近似之前每次事件需要的抽取数就需要越多***

例如【9个0，1个1】，此盒的概率直方图向0倾斜较大，而抽得数据之和的概率直方图也会向0倾斜。  

***当事件重复次数大时，经验直方图可以收敛为概率直方图（抛硬币实验）；当抽取次数大时，和的概率直方图更加接近正态曲线（盒中抽取实验）；因此，当事件的重复次数和抽取次数都大时，和的经验直方图将更加接近正态曲线***。

正态曲线一般与抽取数据之和有关，针对抽取数据之乘积的情况，正态曲线将非常不同；这是因为计算结果成绩的原因，曲线将更加离散，即一些质数将不会包含在曲线当中。而随着事件数量的增加，数据本身的分布将更加极端。

***当使用随机放回的方式在一个盒子模型中进行抽取时，即使盒子所装的票子面值并不遵循正态，但是抽得数据之和的概率直方图必将遵循正态曲线。  
在计算中，直方图必须换算成标准单位，且抽取的次数必须适当大（直到概率直方图完美拟合正态曲线）***  

一般来说，抽取的数量很少有一个确实的**适合大**的标准，因为抽取的数量依赖于盒子中卡片牌面的面值分布。但一般100次抽取得到的概率直方图已经可以很好的拟合对应的正态曲线了。

当概率直方图拟合正态曲线时，正态曲线可以使用期望值（代平均值）和标准误差/SE（代替标准单位/标准差）对曲线进行刻画，因为概率直方图可以完美拟合正态曲线：  
***期望值将概率直方图的中心定在水平轴的指定位置上，而标准误差则确定了概率直方图的散布***。  
而根据之前所知：***使用平方根法则时，期望值和标准误差可以使用以下数据求出：  
抽取次数  
盒平均数/单次抽取平均期望值  
盒SD***
因此，这三个值确定了抽牌结果之和的的行为，即为何盒子的SD成为其散布程度的一个重要度量的理由。

# 数据来源于抽样调查

## 数据量来源的分类

总体来说，数据总是来自**调查**或**研究**

对于**数据使用者**，数据可以分为：  
* 直接来源：数据由自己通过调查/试验收集，直接获取的一手数据  
* 间接来源：数据由别人通过调查/试验收集，仅仅加以使用

### 数据的间接来源

**数据的间接来源：如果数据原先已经存在，使用者仅仅是将其进行加工/整理，使之成为**统计分析可以使用的数据**

基于搜索范围，**间接来源的数据**可以分为：  
1. 取自系统外部的数据：统计部门和各级政府公布的有关资料(期刊/报纸/年检/会议/讨论)/调查与信息咨询机构/经济信息中心/互联网或图书馆查阅到的资料  
2. 取自系统内部的数据：公司或机构内部的业务资料(单据/记录/报表/)

总和而言，系统外部得到的**二手资料**，搜集容易，数据采集成本低，可以很快得到。  
二手资料用途更多，可以：提供研究背景，帮助研究者更好的定义问题，检验和回答某些疑问/假设，寻找研究问题的思路和途径

故，间接数据/二手资料是首先考虑采用的，分析也应该首先从二手资料开始

间接数据/二手资料的**缺陷**：**二手资料可能不是为了特定的研究问题产生，所以在回答相应问题时可能是有缺陷的**，例如：  
* 资料的相关性不够  
* 资料的口径不一致  
* 数据不准确  
* 数据陈旧过时

故，使用*间接数据/二手资料*时，需要**保持谨慎的态度**，并且需要**对二手资料进行评估，确定其是否适用**，评估二手资料时，需要考虑：  
1) 资料是谁收集的；收集人员/单位在相关领域的**实力/社会信誉度**；  
   例如：对于全国性质的宏观数据政府公布的数据的**可信程度**大于调查机构  
2) 二手资料为什么目的而收集；如果是为某个集团为利益收集的数据，是值得怀疑的  
3) 二手资料收集的方法：基于不同方法收集的资料可信度不同，不了解资料收集方法，则无法客观对数据质量做出评价。  
   **数据质量源于数据产生的过程**  
4) 数据收集的时间。过时的数据，其说服力会受到质疑

适用二手数据，要注意数据的：定义/含义/计算口径/计算方法。避免：错误/误用/滥用

在引用二手数据的时候，需要注明数据来源

### 数据的直接来源

二手数据存在**针对性不足**的问题，故：仅仅依靠二手数据，无法回答研究中的**全部问题**时，就需要**通过调查和试验的方法直接获得一手资料**

数据的**直接来源**，被分为两种：  
1) 调查数据：通过调查方法得到的数据  
2) 实验数据：通过实验方法得到的数据

调查数据通常取自有限总体，如果针对调查总体中的全部单位进行进行数据收集，则被成为**普查**；  
普查得到的数据，有：**信息全面/完整**的特点；  
而当总体较大时，进行**普查**的**成本较高**，其涉及的范围广，接受调查的单位多，故更加耗时/费力，故**总体较大时，普查难以进行**  

大多数情况下，获得的是样本数据，即取自总体数据的一个**有效样本**

**实验数据，往往是针对自然现象进行的实验而言的**

## 抽样

调查人员常常需要归纳整个一个个体，这被称之为*总体*。但是针对一个总体的全部进行研究不切实际（内部样本数量太多，消耗太大等）；故，一般情况下，仅仅研究*总体中有代表性的一部分*，这部分就被称之为**样本**。  
而研究人员，根据样本对整体进行归纳，即根据样本对总体进行**推断**。

在调查研究中，通常存在部分关于总体的数值特征，这被称之为**参数**；一般情况下，总体的参数是无法被精确测量的，仅能依据样本进行估计。参数一般由统计量，或者根据样本计算的某些数值进行估计  
只有样本充分代表了总体的时候，根据样本估计参数才是合理的。这可以通过比对样本和总体在某些方面的一致性进行。  
例如，在对美国大选结果预测的研究当中，存在两个参数：  
1.全体合法选民的平均年龄  
2.当前登记投票的全部合法选民的百分数

简单随机抽样/有放回随机抽取的实质：**通过简单随机抽样方法对样本进行抽取，抽取得到的样本中各参数/特性的占比和总体中相同；故可以认为：研究抽取的样本就是研究总体本身**。

## 抽样调查原则

***抽样的程序应该合理，以公平的方式选择样本，以获得具有代表性的横剖面；  
如果在抽样样本阶段，抽样程序将单一/多个类型的样本组合排除在抽样样本之外，则这种系统性的倾向被称之为选择偏性***

例：1936年美国大选，之前屡次正确预测出大选结果的《文学摘要》杂志在此次大选的预测中，出现失误（预测兰登大比例战胜罗斯福，而事实正好相反）  
这是因为《文学摘要》在选取样本时，使用了黄页/俱乐部的电话簿中的地址邮寄了问卷，这样导致穷人/不属于俱乐部的人员被排除在了样本组外，产生了相当大的选择偏性。

故：***当样本的选择存在选择偏性时，抽取一个大的样本对估计总体的情况并无帮助。它只不过会在较大规模下持续重复基本错误***。

同时，针对寄送了问卷的样本对象，也存在***不回答偏性，即存在大量未回答问卷的样本对象；在统计样本数据时，这些人将无法被统计，但是他们实际代表了总体的一个倾向；  
故，不回答者可能和回答者大不相同，当出现高不回答率时，谨防不回答偏倚***。

总体而言，某些样本确实很差，若想了解一个样本是否可取，需要检查获得样本的原因，是否存在选择/不回答偏倚。

***定额抽样：调查人员常常对需要抽取的样本对象赋予固定定额（根据总量中的相关分布），这样样本可以更好的代表总体数据针对研究内容的倾向/特征。  
但是定额抽样会存在一定的无意的偏倚：针对抽样样本的定额划分仅仅基于调查已知的方面进行的划分，但调查中还存在若干之前无法了解到的影响因素（甚至包括调查目的本身分布的影响）  
同时，因为针对定额抽样中，每个定额下的实际样本由抽样人员主管选择，故容易产生偏性（某些特定调查中，调查目样本相对更易接触到，比如大选中，共和党支持者相对富裕，有固定住所/电话）***。

## 使用概率/机会方法抽样

***概率方法设计时，一般针对总体中的每个个体都有相同的概率被抽中进入样本***

在使用机会方法抽样后，使用的样本量和精度（误差）均有了相当的下降，在之前的抽样逻辑中，针对选取的样本进行判断被认为是需要的（例如，定额抽样保证样本中男士的百分比），但随后证明，添加了判断针对预测精度的提升很小，还会产生较大的偏性（抽样人员针对样本的挑选等）；这是因为选择和判断中一般都潜藏有偏性，而机会则不带有任何偏性。故：  
***为了极小化偏性，应使用不带有偏袒性且客观的概率方法选取样本***

## 抽样的分类

### 概率抽样和非概率抽样

在数据采集阶段，统计学家面临的关键问题，是如何抽选出一个好的样本；**好的样本都是相对而言的**，**相对**的意思有两个：  
* **针对研究的问题，而言**：不同的研究问题，对于样本的要求会有差别。例如：  
  研究顾客满意度，样本应该来自该产品的用户；如果研究消费者对该产品的购买意愿，样本应来自全部潜在客户
* **针对调查的费用与估计的精度而言**：**调查费用**和**数据精度**之间，存在一定冲突/矛盾；一个好的样本，应该有好的性价比，及：**在相同调查费用条件下，获得数据的估计精度最高；或在相同的估计精度条件下，调查成本最低**；  
    在研究中，针对**估计结果的精度要求是可以有差别的，对于重要问题，希望精度更高；对于不太重要的数据，可以放松调查精度，以节省更多大量的调查经费**

抽样的方式，可以分为：  
* 概率抽样Probability Sampling：也称**随机抽样**，指**遵循随机原则进行的抽样**，总体中每个单位都有一定机会被选入样本，相关特点：  
    * **抽样是按照一定的概率以随机原则抽取样本**，随机原则：**抽取样本时，排除主观有意识的抽取调查单位，使得每个单位都有一定机会被抽中**  
      注意：随机，不意味着随便，随机有严格的科学意义并可以使用概率来描述，随便带有主管因素  
      例：对于一栋楼抽取10个居民，随机：将该楼全部居民进行编号，随后通过随机化程序抽出样本，使得每位居民都有一定机会被选择；随便：在楼前选择最先走到楼的10位居民(楼内全部居民不是全有寄回被选择)  
    * 抽样中，每个单位被抽中的概率是已知的/可计算出来的  
    * 使用样本估算总体的参数时，要考虑每个样本单位被选中的概率，即：**总体参数的估计量，不仅与样本单位的观测值有关，也与其被选入的概率有关**  
    * 抽样不等于**等概率抽样**：概率抽样中，总体中的单位都有**一定的非零概率被抽中**，**总体内单位之间被抽中的概率可以相同(等概率抽样)也可以不同(不等概率抽样)**  
* 非概率抽样non-Probability Sampling：相对于**概率抽样**而言的抽样方法，指**抽取样本时，不是依据随机原则而是基于研究目的对数据的要求，采用某种方式从总体中抽出部分单位对其实施调查**

**概率抽样和非概率抽样的比较**

概率抽样和非概率抽样，是两种完全不同的抽样方式，调查中采用哪种方法，取决于多种因素，包括：研究问题的性质/使用数据说明的问题/调查对象的特征调查费用或时间

由于**非概率抽样**是**不依据随机原则抽取样本**，样本统计量的分布是不确切的，因而**无法使用样本的结果对总体的参数进行推断**，故如果调查的目的是**对总体相应参数进行估计**，则不应采用**非概率抽样**  
**非概率抽样**的特点是：**操作简单/时效快/成本低/对统计学技术要求不高**；  
**非概率抽样**适合：**探索性研究，使用调查结果用于发现问题/得到定性结果，为更深入的数量分析做准备/找方向**

**概率抽样**是**依据随机原则抽选样本**，这时**样本统计量的理论分布是存在的**，因此可以**根据调查结果对总体的有关参数进行估计**，计算估计误差，得到总体中参数的置信区间

故，如果调查的目的是**掌握研究对象总体的数量特征，得到总体参数的置信区间，就应使用*概率抽样*的方法**

概率抽样要求的**技术含量更高，对于样本抽取和调查数据分析，均需要较高的统计学知识，同时调查的成本较高**

实际使用时，可以同时结合**概率抽样**和**非概率抽样**，发挥各自的特点，满足研究中的需求

### 简单随机抽样

***简单随机抽样：针对总量对象进行 多次(总计划抽样次) 无放回（防止重复抽取）的抽取；在每次抽取时，总量中的全部对象均有相同的概率被抽中  
此种方法可以最大现多的减小抽样中的偏性，且每个对象有相同的概率入选样本，根据平均数率，如果抽取次数充足，则抽取到的投票分布等同于实际总体中的百分比***

简单随机抽样固然可以最大限度的减小偏性，但是针对范围(物理/跨度)较广的事件中（如美国大选），实际难以实施：  
首先需要一份拥有投票权的全部公民名单，其次需要根据抽样的结果加派调查人员实际赴现场进行调查

故，针对某些调查，简单抽样不符合实际情况，而可以使用***多阶段分群抽样***的方法进行调查（结合了定额抽样和简单随机抽样）：***以某些重要的影响因素为划分（大选进行的物理区域），开展多个独立的调查研究，在调查区域中再进行分组，针对分组进行抽样；针对抽样得到的分组再依据调查目的进行分组（大选中的选区），再针对分组进行抽样；再针对抽样结果内的对象进行随机抽样调查***  
使用此类办法，可以在**避免访问人员主管偏性的同时，使用明确且包含随机机会方法**进行抽样

1. 概率抽样：  

简单随机抽样  
简单随机抽样(simple random sampling ，SRS)是最简单的概率抽样方 法 ，也是其他抽样方法的基础 。它指的是：从一个单元数为 N 的总体中逐个抽取单元并且无放回 ，每次都在所有尚未进入样本的单元中等概率地抽取 ，直到 n个单元抽完。*简单随机抽样*中，每个样本单位被抽中入样的概率是相同的

简单抽样需要结合抽样框/Sampling Frame,一个包含了**总体中所有有资格被抽中的单位的，及其全部相关信息的数据集合**

适用场景：当总体N较小或者总体方差S2与任意局部方差基本相当的情况；

分层抽样  
分层抽样(stratified sampling)是指先按照某种规则把总体划分为不同的层 ，然后在层内再进行抽样 ，各层的抽样之间是独立进行的 。特别地 ，如果各层内是简单随机抽样 ，则称为分层随机抽样 。分层抽样的估计是先在各层内进行的 ，再由各层的估计量进行加权平均或求和 ，从而得出总体的估计量 。

适用场景：适用于层间有较大的异质性，而每层内的个体具有同质性的总体；

整群抽样  
整群抽样(cluster sampling)是指先把总体中的个体划分成称作群的单个组，总体中的每一个个体属于且仅属于某一群。以群为单位抽取一个群作为简单随机样本。并且检查整个抽取到的群中的样本。当群中的个体不同质时，整群抽样得到的结果最佳。在理想状态下，每一群是整个总体小范围内的代表。整群抽样的值依赖于每一群对整个总体的代表性。如果所有的群在这个意义上是同质的，则抽取小量的群就可以得到关于总体参数的好的估计。

适用场景：适用于群间差异小、群内各个体差异大、可以依据某种特征差异来划分的群体；

等距抽样  
在定量抽样调查中，等距抽样常常代替简单随机抽样。由于该抽样方法简单实用，所以应用普遍。等距抽样得到的样本几乎与简单随机抽样得到的样本是相同的。  
等距抽样的基本做法是，将总体中的各单元先按一定的顺序排列、编号，然后决定一个间隔，并在此间隔基础上选择被调查的单位个体。  

样本距离可通过下面公式确定：  
样本距离 =总体单位数∕样本单位数

例如，假设你使用本地电话本并确定样本距离为 100 ，那么 100 个中取 1 个组成样本。这个公式保证了整个列表的完整性。  
等距抽样方式随意用一个起点，例如，如果你把一本电话本作为抽样框，必须随意取出一个号码决定从该页开始翻阅。假设从第 5 页开始，在该页上再另选一个数决定从该行开始。假定选择从第 3 行开始，这就决定了实际开始的位置。  
等距抽样方式相对于简单随机抽样方式最主要的优势就是经济性。等距抽样方式比简单随机抽样更为简单，花的时间更少，并且花费也少。使用等距抽样方式最大的缺陷在于总体单位的排列上。一些总体单位数可能包含隐蔽的形态或者是“不合格样本”，调查者可能疏忽，把它们抽选为样本。

系统抽样  
系统抽样(systematic sampling)是指先将总体中的抽样单元按某种次序排列 ，在规定范围内随机抽取一个初始单元 ，然后按事先规定的规则抽取其他样本单元 。特别地 ，如果在抽取初始单元后按相等的间距抽取其余样本单元 ，则称为等距抽样 。

适用场景：适用于容量很大且个体的排列是按照随机顺序排列的总体；

多级抽样  
多级抽样(multi-stage sampling)可以看作整群抽样的发展 ，在抽得初级抽样单元/群之后 ，并不调查其全部次级单元 ，而是再进行抽样 ， 从入选的初级单元中抽选次级单元 ，这种抽样方法称为二阶段抽样 。二阶段的第一阶段指抽取初级单元 ，第二阶段是指抽取次级单元(在二阶段抽样中，也就是基本抽样单元)。类似地 ，可以定义三阶段抽样 ：先抽取初级单元 ，在其中继续抽取次级单元 ，在抽中的次级单元中再抽取三级单元(基本单元)。依此类推 ，可定义四阶段抽样等 。二阶及二阶以上抽样统称为多级抽样 。

2. 非概率抽样：指调查者根据自己的方便或主观判断抽取样本的方法。它不是严格按随机抽样原则来抽取样本，所以失去了大数定律的存在基础，也就无法确定抽样误差,无法正确地说明样本的统计值在多大程度上适合于总体。

非概率抽样依抽样特点可分为方便抽样、定额抽样、立意抽样、滚雪球抽样和空间抽样。

① 方便抽样  
样本限于总体中易于抽到的一部分。最常见的方便抽样是偶遇抽样，即研究者将在某一时间和环境中所遇到的每一总体单位均作为样本成员。“街头拦人法”就是一种偶遇抽样。某些调查对被调查者来说是不愉快的、麻烦的，这时为方便起见就采用以自愿被调查者为调查样本的方法。方便抽样是非随机抽样中最简单的方法，省时省钱，但样本代表性因受偶然因素的影响太大而得不到保证。

② 定额抽样  
定额抽样也称配额抽样，是将总体依某种标准分层（群）；然后按照各层样本数与该层总体数成比例的原则主观抽取样本。定额抽样与分层概率抽样很接近，最大的不同是分层概率抽样的各层样本是随机抽取的，而定额抽样的各层样本是非随机的。总体也可按照多种标准的组合分层(群)，例如，在研究自杀问题时，考虑到婚姻与性别都可能对自杀有影响，可将研究对象分为未婚男性、已婚男性、未婚女性和已婚女性四个组，然后从各群非随机地抽样。定额抽样是通常使用的非概率抽样方法，样本除所选标识外无法保证代表性。

③ 立意抽样  
立意抽样又称判断抽样，研究人员从总体中选择那些被判断为最能代表总体的单位作样本的抽样方法。当研究者对自己的研究领域十分熟悉，对研究总体比较了解时采用这种抽样方法，可获代表性较高的样本。这种抽样方法多应用于总体小而内部差异大的情况，以及在总体边界无法确定或因研究者的时间与人力、物力有限时采用。

④ 滚雪球抽样  
以若干个具有所需特征的人为最初的调查对象，然后依靠他们提供认识的合格的调查对象，再由这些人提供第三批调查对象，……依次类推，样本如同滚雪球般由小变大。滚雪球抽样多用于总体单位的信息不足或观察性研究的情况。这种抽样中有些分子最后仍无法找到，有些分子被提供者漏而不提，两者都可能造成误差。

⑤ 空间抽样  
对非静止的、暂时性的空间相邻的群体的抽样方法。例如，游行与集会没有确定的总体，参加者从一地到另一地，一些人离去又有一些人进来，但这些事件是在一定范围内进行的。对这样的总体在同一时间内抽样十分重要，以便样本组成不会经历时间上的太大变化。具体作法是:若干调查员间隔均匀的距离,从某一方向开始，访问离他最近的人，然后每隔一定步数抽取一人为调查对象。

⑥ 自愿样本  
自愿样本，指的是被调查者自愿参加，成为样本中的一份子，向调查人员提供有效信息。自愿样本和抽样的随机性无关，样本的组成往往集中于某些类特定的人群，尤其集中于对该调查活动感兴趣的人群，因此样本是有偏的，而不能使用样本估计总体，但是可以使用样本得到一些有用的信息，反映某类群体的一般看法  
例如：报刊杂志上的调查问卷活动，热线电话等。

概率抽样以概率理论为依据,通过随机化的机械操作程序取得样本,所以能避免抽样过程中的人为因素的影响,保证样本的客观性.虽然随机样本一般不会与总体完全一致,但它所依据的是大数定律,而且能计算和控制抽样误差,因此可以正确地说明样本的统计值在多大程度上适合于总体,根据样本调查的结果可以从数量上推断总体,也可在一定程度上说明总体的性质,特征.概率抽样主要分为简单随机抽样,系统抽样,分类抽样,整群抽样,多阶段抽样等类型.现实生活中绝大多数抽样调查都采用概率抽样方法来抽取样本.

非概率抽样:又称为不等概率抽样或非随机抽样,就是调查者根据自己的方便或主观判断抽取样本的方法.它不是严格按随机抽样原则来抽取样本,所以失去了大数定律的存在基础,也就无法确定抽样误差,无法正确地说明样本的统计值在多大程度上适合于总体.虽然根据样本调查的结果也可在一定程度上说明总体的性质,特征,但不能从数量上推断总体.非概率抽样主要有偶遇抽样,主观抽样,定额抽样,滚雪球抽样等类型.

### 搜集数据的基本方法

在确定了样本单位后，需要对这些单位实施调查，即从样本单位那里得到所需要的数据。

1. 自填式：在没有调查员协助下，由调查者自行填写，完成问卷。可以通过：调查员分发/邮寄/网络邮件/把问卷刊登在报刊上等方式进行。  
   因调查员不在现场，则要求问卷：结构严谨，有清楚的说明辅助被调查者回答问题。自填式问卷，要求被调查者有一定文化素养，可以读懂并理解问卷  
   自填式调查的优点：  
   * 管理容易，仅仅需要将问卷正确的送到被调查者手中即可  
   * 成本最低，增大样本量对调查费用的影响很小，适用于大范围的调查  
   * 对被调查者压力很小，更容易进行自主决策不受外部影响，可以填写更多敏感信息  
   自填式调查的缺点：  
   * 问卷回收率低：被调查者不够重视，在完成问卷上没有压力  
   * 问卷容易遗失：因为被调查者不够重视，故容易损坏/遗失问卷  
   故，自填式问卷一般需要做很多跟踪回访，争取得到更多的回收率  
   * 自填式问卷不适合复杂的问卷：因为许多被调查者不会认真阅读问卷指南，遇到问卷中的转跳/转答问题，被调查者会给予错误回答  
   * 自填式调查周期长，对于问卷的寄送和寄回方法需要进行推敲和研究  
   * 自填式调查在搜集数据的过程中如果出现问题，难以进行调改  
2. 面访式：现场调查中，调查员于被访者面对面，调查员提问而被访者回答的调查方式。  
   面访式的优点：  
   * 提高调查的回答率：在面对面调查中，更易调动被访者的参与意识，可以说服不愿参加的被访者  
   * 提高数据质量：调查人员当面对问卷中的问题进行答疑  
   * 采取更多技术手段：调查问卷由经过培训的调查员控制，可以使得调查问题的组合更加灵活，更加科学  
   * 借助更多的调查工具：面对面调查问卷可以借助：图片/照片卡片/实物等工具，丰富调查内容  
   * 控制调查进度：调查进度由调查员控制，可以通过增加调查员加快调查速度  
   面访式的缺点：  
   * 调查成本较高，且与样本量直接相关：需要调查员的培训/工资/交通费，及给被调查人员的报酬与礼品  
   * 质量控制问题：调查得到的数据质量和调查人员的主观态度/责任心有直接关系，不好管控  
   * 难以回答敏感问题：因为存在第三方(调查人员)，被调查人员倾向不填写敏感信息  
3. 电话式：调查人员通过打电话的方式向被调查人员实施调查。  
   电话式的优点：  
   * 速度快：可以在很短的时间内完成调查  
   * 成本低：特别适合样本在地理上十分分散的情况，可以无视地理距离进行调查  
   * 容易控制访问过程：调查人员在一起工作，可以及时处理遇到的问题，同时方便督导监控；同时可以使用计算机机器学习对调查人员的表现进行监控  
   电话式的缺点：  
   * 实施限制：对于没有电话的区域，不好使用此方法  
   * 时间限制：被访者一般不希望进行冗长的电话交流，尤其在对被调查内容不感兴趣时由是如此  
   * 调查内容限制：电话调查的调查内容需要简单，防止因**不直观的交互方式**导致忘记题目或答案内容，造成进度迟缓，以至于引起被调查者挂机  
   * 难以说服被调查者：因为缺少面对面互动，很难说服不愿参与的被调查人员  
4. 其他调查方法：  
   * 观察式：调查人员直接通过观测的方法获取信息

#### 数据收集方法的选择

选择数据收集方法时，需要考虑：  
* 抽样框中的信息：如果抽样框中没有通信地址，就无法寄送自填式问卷；如果抽样框中没有被调查人员的电话，则无法使用电话式调查  
* 总体目标的特征：如果整体目标单位识字率较低，难以单独理解问卷，则不能使用自填式问卷；如果样本分布的地理距离很广且分散，导致面对面调查成本很高，且难以监控质量，则应尝试使用电话调查  
* 调查问题的内容：对于负责问题应该优先选择面访，由调查员对模糊的问题进行解释和澄清，并且基于被调查人对于题目的理解，调查员可以对问卷进行转跳，使得得到的数据符合要求；如果调查的内容涉及到敏感隐私信息，则应使用**匿名式数据搜集方法**，类似自填式问卷或电话调查  
* 有形辅助物的使用：有形的辅助物，对于调查常常是有用/有帮助的。例如：在调查的时候显示产品/产品样本/广告等，有时也会邀请被调查人实际使用产品后接受调查。这种情况下，使用面访式最有效，使用邮寄问卷的自填式问卷时，可以附上图片或视频/音频，但是对于电话调查，则无法使用有形的辅助物  
* 实施调查的资源：包括预算/人力/物力(设备)/调查时间。调查的预算重要性是最高的，需要负担调查员的开销，和设备的费用  
* 管理与控制：有些数据搜集方法比其他方法更容易控制，比如：电话式调查中，调查人员集中办公，容易管理/控制。面对面调查中，调查人员需分散/独立的工作，更加难以管理  
* 调查质量要求：如果调查员经过选拔，有较好的素质和责任心，且经过专门的培训，则面访调查时能有效的减少被访者的错误回答(向被访者提供清晰无误的概念解释)，有经验的调查员可以分辨被调查人回答的真实性，并使用相关技术进行澄清，以保证高质量的数据。

**搜集数据不同方法的特点**

|项目|自填式|面访式|电话式|
|:---|:---|:---|:---|
|调查时间|慢|中等|快|
|调查费用|低|高|低|
|问卷难度|要求容易|可以复杂|要求容易|
|有形辅助物的使用|中等利用|充分利用|无法利用|
|调查过程控制|简单|复杂|容易|
|调查员作用的发挥|无法发挥|充分发挥|一般发挥|
|回答率|最低|较高|一般|

没有一种方法是最好的，在选择数据搜集方法时，要考虑：  
* 调查所需的信息的性质  
* 调查对象的特点  
* 对数据质量和回答率的要求  
* 预算/时间  
等

如果没有一种方法适用时，应考虑数据收集中的主要需求，适当做出取舍。

各种方法间不是互斥的，而是可以**互相结合使用**以进行互补的。例如：  
**对选中的调查单位，先邮寄自填式问卷，对于未填写寄回的人员，再进行电话访问或面访**

### 多阶段分群抽样的问题及解决办法

即便使用了**多阶段分群抽样**的方法，最大限度的在有判断抽样和无判断随机抽样当中进行了平衡，但是抽样过程中终究会产生一些偏性。  

***不参与活动/不投票者偏性***：在进行抽样/问卷调查时，部分抽样过程中抽得的样本对象不愿参与活动，但是他们可能正常的填写了问卷（例如明知不会参加总统大选投票，但是依旧正常的填写了问卷。因为不参加此类活动，或许对样本对象来说是一种耻辱/丢人/离群）因为实际参与投票的人和未参与投票的人的倾斜可能不同，故针对此类对象，可使用问卷中的一个/多个问题对此类样本对象进行筛选。（类似：是否知晓投票点，上次是否投票）

***未决定者***：在抽样过程中，部分被抽到的对象尚未做出决定。这时，可在问卷中询问做出决定的倾向，而非直接询问最终的决定。还可以使用预先做好的非记名投票材料，在不影响样本对象的情况下（不进行施压）得到正确的结果

***回答偏性***：问卷内的行文方式及抽样调查员本身的态度/语气等外部问题同样可能会影响样本对象的选择（过于晦涩/复杂的问题）。故需要标准化问卷及访问流程，尽量使用不记名问卷/投票的方式进行。且要注意/简化描述/用词/问卷布置方式

***不回答偏性***：并非所有被抽中的样本对象都原因作答，而他们恰恰可能一样会参与活动。故，针对可以访问到但是难于得到回答的对象需要加大权限。

***家庭/群组偏性***：在抽样时，最小样本单位往往不一定是个人，而有可能是某个群体（例如家庭）。而一个群体的内个体的数量往往不相同。故需要对不同群体/家庭的对象设置不同的权重。

***检验数据***:因为某些客观存在的情况（受教育程度和投票倾向），因针对此类问题的权重进行倾斜，即：使用**比估计**方法，客观的为不同群组的样本对象赋予不同的权重。

***针对抽样调查员的控制***:为了证明抽样调查员是否依据流程进行了抽样，可以通过增添一个关于抽样流程的问卷，对此问题进行评估

## 电话调查与网络调查

从客观角度讲，随着电话及互联网的的普及程度的增加，可以使用此类新渠道对进行抽样；且因为不会直接接触抽样人员，也可以避免因抽样人员引起的偏性。  
网络/电话调查同样基于多阶段分群抽样的方式：首先抽取区域（依据电话中区域字段），再从抽得的区域中抽取对象。

要避免在不方便的事件和样本对象进行沟通：吃饭时间等，可以集中在傍晚及周末进行联系。若无人接听，可以重复联系

## 实验数据Experiment Data

实验中，一个/多个变量将被控制，在有控制的情况下得到结果。而**实验数据Experiment Data**是：在实验中，控制实验对象而搜集得到的变量数据。

### 实验与对照组

实验不仅是一种搜集数据的方法，同时也是一种研究方法。

实验的基本逻辑：有意识的改变某个变量(变量A)，观测另一个变量(变量B)的变化。如果B随着A的变化而变化，则说明A对B有影响。

为此，实验需要将实验对象分为两个组：  
* 实验组Experimental Group:随机抽取的实验对象的子集  
* 对照组Control Group:每个单位不接受实验组成员所接受的特殊处理

具体情况见上文

### 实验中的若干问题

使用实验方法，其逻辑相对严密，可以较好的证明假设，分析事物的因果关系，但是在实验过程中，同样会遇到一些问题：  
* 人的意愿：在划分实验组和对照组时采取随机原则，但是因为负责划两个组的人存在**主观意愿**，即：自身的处事原则/兴趣爱好，则不一定会采取**随机方法**，而是在分组时掺杂了主观意愿  
* 心理问题：针对有些实验，如果被实验对象意识到了他们参与到了实验当中，会因此产生影响。例如：  
  研究光照对工厂中的工人生产效率进行实验时，发现**无论增大或减小光照**，实验组的工人生产率/产量均有上升，之后发现**增加产量的原因**是不是因为照明度，而是因为工人意识到**有人注意到了他们的行为，而表现出的一种容易被社会认可/接受的行为，尽管这种行为并不是他们愿意的**  
* 道德问题：对于某些实验，涉及到道德问题时，实验人员会处于进退两难的尴尬境地。例如：  
  研究艾滋病新药的药效，需要将**病人**划分为**实验组和对照组**，这就意味着**对照组**病人将因服用**安慰剂**而耽误治疗，面临死亡的威胁(这些病人本身可以接受其他已经确认的治疗)；当然，如果发现新药存在副作用风险，使得服用的病人/**实验组**存在更高的死亡率，则**对照组**中的病人将避免此类问题  
  这当中存在**道德困境**  

### 实验中的统计学

在实验中，统计学起到了以下的作用：  
* 确定实验的样本量个数，保证实验在可以达到**统计显著/一定的精确程度**的基本要求下，尽量做到成本最低(样本量最小)：基于实验目的和置信区间  
  一般来说，实验中的数据/样本量越大越好，但是对于大规模的实验来说，手机样本数据的成本较高，实际搜集时间较长，通过统计分析可以在维护**精度**和**成本**的平衡中提供**可以参考的信息**  
* 在实验设计中，融入统计学思想，使得实验设计符合统计分析标准。实验设计研究的是如何根据研究问题的需要，科学的安排实验，使得使用**尽量少的实验获得尽量多的信息**。  
  实验设计本身就是统计学问题。  
* 提供最有效的同时研究多个变量影响的方法：在对实验收集到的数据进行分析时，统计学可以提供最恰当的分析方法。  
  一个好的实验，其应该在两个方面都有效：  
  * 内部的有效性：即实验测量的准确性；实验通过控制变量的方法，尝试理清考察/控制的自变量和观测到的因变量之间的因果关系，而如果实验观察结果受到了其他无关变量的影响，则难以判断自变量和因变量之间的因果关系  
  * 外部的有效性：觉得是否可以将实验发现的自变量和因变量之间的因果关系，是否可以推广到实验环境之外的的情况。  
    如果可以，则存在以下问题：  
    * 结果可以推广到什么样的总体  
    * 结果可以推广到什么样的环境  
    * 结果可以推广到什么样的自变量/因变量  
    * 因为很难找到和实验环境完全相同的外部/社会环境，则推广到外部/社会环境之后，结果是否还有效  
    为了回答这些问题，需要使用统计方法。例如：  
    * 使用**多元回归分析**，区分各个变量的影响，在满足一定的条件下，可以**定量的比较各个自变量对因变量产生的影响**  
    * 使用**协方差分析**，调整组内因变量的平均值，达到消除无关变量影响的目的

# 抽样调查中的机会误差

调查中的误差，可以认为是**调查搜集到的数据**和**研究对象真实结果**之间的差异。一般调查数据中的误差被分为两种：  
* 抽样误差  
* 非抽样误差(谬误)  

## 抽样误差

**抽样误差Sampling Error**,是由**抽样的随机性引起的*样本结果*与*总体真值*之间的误差**

在**概率抽烟**中，







简单抽样调查可以被视作从盒中随机有放回的抽取部分卡片（***标有1/0，代指参数***）。故一样可以视作机会过程。故，一样也存在机会过程中存在的机会误差。  
***样本仅为总体的一部分，故样本的百分比组成成分和总体的百分比组成成分存在稍许不同***  
故对事件参数进行调查可以被视为：盒中抽取到1的百分比 = 盒中1的百分数 + 机会误差 + 事件偏性（在更复杂的情况下）。  
***故，概率样本中的机会误差的大小也一样由标准误差得出***

故，作为机会误差，一般会存在一下三个问题：  
1.机会误差的大小是多少  
2.针对样本大小及总体的依赖程度  
3.为了控制机会误差，样本容量该是多少

***针对一个已知成分的总体进行随机抽样，机会误差所占的百分比依赖于样本容量，而不是总体大小***

## 抽样调查中的随机误差及其百分比

***为计算一个标准误差/SE的百分数占比，则可以先计算出标准误差的绝对值，再换算成样本容量的百分比***

针对一个简单随机抽样模型，可以先尝试将模型抽象成为盒子模型

例:从6672名参与者（3091男，3581女）中抽取100名参与者，求男性人数标准误差的占样本总量的百分比：  
首先建立盒子模型，因目标为男性计数，则抽到男性时+1而抽到女性时男性样本数量不变，故盒子模型应为：【3091个1，3581个0】  
由此可知，单次平均期望值为0.46  
100此抽取后总体的期望值约为46  
有因为盒中仅有两种情况，故可以使用平方根法则求SD，(1-0) * 平方根(0.46 * 0.51) = 0.5
故，100次实验中，会有 平方根(100) * 0.5 = +-5次的标准误差，标准误差量占样本总量的5%

根据平方根定律可知：如果增大抽样/实验次数，则误差出现的次数上升，但是相对误差占比减小：  
接上例，如果抽样次数升为400次，标准误差为 平方根(400) * 0.5 = 2.5%，  
即：**样本容量上升4被，而百分数SE除以 平方根(4) = 2***

***样本容量乘以某一个因子，百分数SE则除以这个因子的平方根（样本总量乘以4，而百分数SE则除以平方根(400)），这个规律对放回抽样是精确的。  
即使针对不放回抽样，只要抽取票子的张数与盒子中票子的总张数相比少的多，则也是个近似值***

***样本中的数据为定量数据，而问题求得的是定性数据时，需要在两者之间进行转换***  
只要将随机抽样当中的实际情况转化为盒子模型，即可使用随机过程对实际抽样实验进行模拟

例：电话公司存在100000个客户，其中仅有20%的客户年收入在五万元以上，问：抽取400此得到收入五万元以上客户的数量，及可能误差的百分比；和抽取样本中18%至20%的为五万以上收入的机会  
首先建立盒子模型，根据要求可知，需要求得抽取的五万以上收入客户的*数量*，故可知，此类问题为计数问题。故盒子模型情况如下：【20000个1，180000个0】  
根据随机过程可知：单次平均期望值为：20000/100000 = 0.2  
根据平方根法则可知，此模型SD为：(1-0) * 平方根(0.2 * 0.8) = 0.4，标准误差为：平方根(400) * 0.4 = 8，即400此抽取的2%  
而400次抽取的最终期望值为 0.2 * 400 = 80。  
故，最终此类问题结果如下：抽取400个客户，应存在80个收入5万之上的客户，误差为+-8个客户，即抽取数量的2%

问题二中，求18% 至 20%为 五万元之上收入的机会  
根据使用的机会过程制作的机会直方图拟合回归曲线可知，  
此回归曲线中，平均值为期望值80，即400个样本中占20%，而标准误差为8，即样本总量的2%  
故题中18%-20%区间即为回归曲线内+-1SD的位置，故，随机至此范围的机会为68%

上例中，通过将全部总体的收入，这个条件转化为*是否大于5万*这个判断条件，成功的将原本的定量数据转化为了定性数据。在建立了定性盒子模型，最终得到了结果。

***使用定量/定性盒子模型的时机：  
使用定性盒子模型时，一般用于将样本值求平均数；  
分类计数后求百分率  
等情况***

## 修正因子

***估计百分数时，决定精度的是样本的决定容量，而不是样本相对总体的比例/大小。这在样本仅占总体很小一部分的情况下依旧正确***。

例：美国大选中，新墨西哥州存在120万合法选民，而德克萨斯州存在1250万合法选民，从两个州各抽取2500名选民作为样本研究投民主党的比例，问两个测试中，**哪个测试机会误差小**。  
答案为：**机会误差一样小**。

针对此问题，可设置两个盒子模型：MN（新墨西哥）与TX（德州）

MN中存在1200000个票，假设此州中投民主党的合法选民占50%，即使用*随机不放回*的方式进行抽样（即简单随机抽样）时，存在约600000个1（民主党）和600000个0；  
调查公司在进行数据估算时，会抽取2500张票，并根据样本总量中的投票情况对总量进行估计，而得到的百分比等于：NM盒子中的百分数 + 机会误差

如果加入德州选民投民主党的比率也为50%，则TX盒子中存在12500000个票。使用*随机不放回*的方式进行抽样（即简单随机抽样）2500卡时，存在约6250000个1（民主党）和6250000个0；  
同样的，调查公司在进行数据估算时，会抽取2500张票，而TX盒子中的得票比率为：TX盒子中的实际百分比 + 机会误差

若针对MN合TX两个盒子进行**有放回的抽取时**，根据平方根定律，两个盒子标准误差相同(因为两个盒子的抽取次数和标准差相同，标准差使用平方根法则时仅考虑盒中面值及几率)  
即 平方根(2500) * (1-0) * 平方根(1/2 * 1/2) = 25，占总样本的25/2500=1%  
故，如果使用随机有放回的方法进行抽样时，两个盒子的标准误差及偏离期望值的比例相同，和盒子大小无关。

同时，根据之前所说，**当样本和总量之比非常小时，每次抽样后对总量内事件的比例的影响很小，故随机有放回抽取的标准误差和随机无放回的标准误差接近**  
而根据上例，当不放回的抽取了1和0的时候，抽得的结果不会大比例的影响盒中1和0卡片的组成和分布。故下次抽取得到1的比例依旧可以约等于50%。  
故此时，有放回抽取和无放回抽取的标准误差相同

根据统计学推断，***当进行了无放回抽取时，每次抽取会使得盒中变的更小，并且略微减弱变异性，故无放回抽取的标准误差要略小于有放回抽取的标准误差。  
相关公式如下：不放回抽取的标准误差 = 修正因子 * 放回抽样时的SE  
而修正因子的公式为：平方((盒中的票数-抽取的票数) / (盒子中的票数-1))  
而，当盒子中的票数相对抽取的票数很大时，修正因子接近于1且可以忽略，  
故，样本的绝对容量通过抽样的SE来决定精度，总体的大小并不重要，而当样本是总体中较大一部分(即需要进行大比例抽取)时，必须使用修正因子***。

通过非数学情景进行比喻：  
***假设从一只瓶子中，取一滴液体进行化验。若液体充分混合，则这一滴液体可以完美反应瓶子整体的成分，而瓶子的大小则无需考虑。  
瓶子中的每一分子对应盒子中的每个卡片；  
液体充分混合且液滴随机抽取，而抽取液滴中的分子数对应抽取样本中的卡片数***。



# 统计推断：百分数的准确性与置信区间

之前的大部分例子中，都在研究概率：即从已知成分的盒子中抽取一定量的元素，求抽取到的对象的机会。  
而有时，则需要根据到手的样本推断出总体的情况，即**统计推断方法-通过样本对象推断总体**，而**通过样本推断得到的总体中存在的某种特性的比例被称之为总体百分数**。  
因为在正常调查研究中*总体百分数*是调查的对象无法天然得到，故可以使用简单随机抽样样本中，特定特性样本所占的百分数（即**样本百分数**）去推断总体中的百分数

***（有放回的）随机抽取对总体的推断的隐藏逻辑：因为使用简单随机抽样的方式抽取到的样本中，数据的分布理应和总体中的数据保持一致；故，样本中的分布/平均/标准差也可以认为说是总体中的相关数据***

例如：美国大选中，调查公司可以通过简单随机抽样或多阶段分层抽样的方法，抽取并了解到美国某个地区的选择民主党人的合法投票人数，及其比例。  
而通过此随机抽样行为，可以推断出总体-即全美合法投票人的投民主党的情况/百分比。而这一切均由盒子模型和随机过程/平方根法则推断出

***当从未知的定性/0-1盒子中进行抽样时，可以使用样本中0/1的比率代替盒子中未知的比率以便估计盒子的SD/SE。当样本量足够充分大的时候，这个方法行得通  
而由于机会误差，样本百分数会偏离总体百分数，样本百分数中的SE将表示偏离的可能大小***

例：学校针对全校25000个学生进行调查，估计住在家中学生的百分比。为了进行此项调查，一共使用**简单随机抽取**的方法了400个学生样本，其中存在317个样本住在家中。求标准误差的百分比。  
根据条件可创建盒子模型【317个1，83个0】  
其中单次抽取期望值为 317/400 = 79.25%  
故盒子模型中的全部期望值为317  
根据平方根法则可知，SD为 (1-0) * 平方根(0.7925 * 0.2075) = 0.41，标准误差则为 平方根(400) * 0.41 = 8   
故，可知标准误差占样本的2%  
根据样本推断可知：总体学校中，约有79%（+-2%）的学生住在家里

## 置信区间

上例中，得到：样本数据中79%（+-2%）的样本对象住在家中。作为随机抽样可知：总体的对象中，也应有79%（+-2%）的对象住在家中。  
因为样本百分数 = 总体百分数 + 标准误差，故总体百分数一般认为在+- 1 SD/SE的范围内，即77% - 81%之中。  
当然，**由于样本误差在可能和不可能之间不存在明显界限**，故总体的百分数也有可能偏离+-1 SD/SE的范畴，但是相关几率会大大降低。

这里，***通过标准误差单位换算的回归曲线下的标准单位圈占的回归曲线的面积换算的比例，被称之为置信区间，而调查总体的置信区间的设置则是根据样本的SE/SD值向样本的期望值左右两侧的平移产生的面积比例得到的；置信水平可从正态曲线读出，但此方法仅能应用于大样本时***。  
例如，根据上例，如果使用+-2SD/SE部分的数据，则总体的百分位数置信水平约为95%的置信区间，即在此区间内有95%的几率在75%-83%的样本区间内获得总体的数据  
***置信区间上的相关比例符合正态分布中的标准单位的分布产生的面积比：  
区间样本的百分数+-1SE是总体百分数的近似68%置信区间  
区间样本的百分数+-2SE是总体百分数的近似95%置信区间  
区间样本的百分数+-3SE是总体百分数的近似99.7%置信区间  
但是没有SE的倍数能给出100%的面积，因为总存在极小的可能性出现很大的机会误差；  
且数学上这一点由正态曲线没有限定范围这一事实反映/体现，即无论所选区间多大，均存在部分面积没有被纳入***。

***置信水平被引述为大约这么一个程度，理由是标准误差已通过数据估计出；另外则是因为使用了正态近似，故不存在严格的判定规则。  
进行的最好方式是：想象总体了样本存在相同的百分比成分，然后试图判定正态近似能否适用于取自对应盒子的抽取数之和  
例如：样本的百分比接近0%或100%表明盒子的成分偏向一边；故接收正态近似之前需要大量抽取  
而如果样本的百分数接近50%，则100次左右的抽取后，正态近似应是相当满意***

例：针对一个拥有25000个合法投票者的镇子进行大选投票检查。使用简单随机抽样的方式抽取了1600份样本后，发现样本中存在917个民主党人，问25000个总体对象中，民主党人所占的百分比（近似95%置信区间）。  
根据题目设置样本的盒子模型为定性盒子模型【917个1,683个0】  
故，单次抽取期望值为917/1600=57%,而整体期望值则为917  
根据平方根法则，此盒子的标准差为：(1-0) * 平方根(0.57 * 0.43) = 0.5，故标准误差为 平方根(1600) * 0.5 = 20，占样本总量的 20/1600 = 1.25%  
根据题目可知，要求总体对象使用95%置信区间，故总体样本中，民主党的比例为 57% +- (2 * 1.25%)

针对学校在家住宿学生的统计进行95%置信区间可以得到：总体的概率为75%-83%，因为总体的概率 = +-2SE + 样本的概率，这可以被称之为：*总体的百分数在75%至83%之间的概率为95%*.  
但在频率理论中，机会表示事务发生次数的百分比，而无论进行多少次调查，学生回家居住的比例是不会改变的（即在75%-83%间，亦或者不在），即***参数不受机会变化的支配***，而实际则无法确定百分比是否落在这个区间里。  
这就是为什么统计学家认为**机会存在于抽样过程之中，而非参数中**。故使用*置信*二字作为提醒（***使用置信陈述而非概率陈述***）。

***置信区间依赖于样本，如果样本不同，则置信区间也不相同***。  
例：雇佣不同的公司研究一个装有红色和黑色球的盒子中，红球所占的比例（所占比例为80%）。每个公司使用简单随机抽取的方法抽得2500个样本进行研究，并使用公式求得“样本中红球百分比 +-2SE”从而计算出红球百分比的95%的置信区间。但是因为抽样的公司不同，导致存在的样本对象不同，故标准误差不同，故每个公司得到的置信区间，中心和长度也不尽相同。某些机构得到的数据覆盖率总体中红球的百分比（95%），而其他公司则没有（5%）

对应某些样本，区间“样本的百分数+-2 SE”*覆盖*了总体的百分数，但是对于其他样本来说，置信区间未覆盖  
故，置信区间+-2SE可被解释为：所有次数抽样样本中的大约95%，区间“样本的百分数+-2SE”能覆盖总体的百分数，另外5%的次数不能覆盖。  
+-2SE的置信区间也可被认为：95%的时候可以覆盖总体中的相关百分数数据，方法是通过针对简单随机抽样的方式抽取并计算样本中相关事件的机会，再在此机会左右取+-2SE的区间。（类似于从装满盒子的区间中随机抽取区间，其中盒子中装有的区间有95%的机会覆盖总体中事件的百分数，而存在5%的机会未覆盖）

***因为机会误差，样本的百分数将偏离总体的百分数，标准误差反馈偏离的误差大小***

***注意：有关简单随机样本的公式仅仅适用于简单随机抽样，对于其他的样本并不适用  
这是因为当前所有的定理的基础为平方根法则，即：仅仅针对每次抽样概率不变的情况。而无论适用放回/非放回的方式进行随机抽样，只要抽取的样本相对总体影响概率较小的话，就可以适用平方根法则  
而针对其他的抽样方法，即样本并非通过随机抽取的方法得到，则抽取中每次抽取样本的机会总在变化（非独立的），故平方根法则不适用，且有可能得到错误的结果***

调查公司不使用简单随机抽样的原因有很多，可能是因为成本问题，但是通过比较可知：大部分情况下，简单随机抽样得到的结果会比其他方法下得到的结果更能反应总体的情况。  
例如盖洛普公司进行的大选调查中应用了多阶段分群抽样，但是每次抽样的结果和最终的得票情况相差依旧较大。  
这是因为调查公司仅仅对可能参与投票的对象进行研究，而进行简单随机抽样时，对象则是全部合法选民。针对盖洛普公司的数据求得的标准误差也无法正常覆盖实际样本中的结果，这是因为盖洛普公司并未使用简单随机抽样。

# 估量就业率与失业率：概率与统计的应用

***失业率是政府发布的最重要的指标之一，而失业率是基于大量的现场人口调查进行的***。

## 抽样样本的计算

针对社会科学的计算中，大部分的计算均是基于抽样进行的。这是因为再大部分情况下，因为主观和客观条件的原因，不能使用普查的方式得到想要的信息（时间/金钱成本太高）。  
这时，抽样中抽样样本容量的计算就是一个问题

### 概率抽样样本容量的计算

**在概率抽样当中，样本容量的计算的逻辑，是找出/计算出能够代表当前总体数据分布的样本数据量的最小值  
由抽样分布理论可知，在大样本条件下，如果总体为正态分布，样本统计量服从正态分布；如果总体为非正态分布，样本统计量渐近服从正态分布。**

确定研究样本量最简单的方式就是：看类似研究中的样本量是多少。我们做的很多研究前人都已经做过了，他们的研究结果有很好的借鉴意义。  
不过你很难保证别人的研究准确性，特别是一些质量不高的论文并不值得信赖，你可能也会被带坑里去。  
或者，如果你的样本量不算很大的情况下，你也可以根据自己的实际能力，尽可能多的进行调研，开展“小普查”。

不然，我们还可以使用公式估算样本量。在估算样本量大小的时候，如果样本量太小，样本缺乏足够的代表性，会影响研究的可靠性；  
如果样本量太大，有可能劳民伤财；  
同时，随机抽样过程中还应该尽量减少误差，使抽样效果最大化。  
因此，在计算样本量之前，研究者需要考虑的因素很多，其中包括：总体大小、置信水平、误差范围和标准偏差等多方面。

#### 影响必要样本容量的主要因素

影响样本容量的因素是多方面的，在抽样调查总体、调查费用和调查时间既定的情况下，为确定最佳的样本容量，应首先分析影响样本容量的因素。  
从理论上说，影响样本容量的因素有以下几个方面： 

1. 单位标志变异程度:单位标志变异程度一般用方差σ^2或成数方差P(1－P)的大小来表示。在其他条件不变的情况下，为了达到同样的研究目的，总体单位标志的变异程度大，样本容量应越大；反之，总体单位标志的变异程度越小，则样本容量就应越少。二者成正比关系。  
2. 抽样极限误差抽样极限误差又叫允许误差，是指在一定的把握程度下保证样本指标与总体指标之间的抽样误差不超过某一给定的最大可能范围。在抽样推断中，需要把这个误差控制在一定的范围之内。抽样平均数极限误差一般用Δx̅或者E表示，抽样成数极限误差用Δp表示。在其他条件不变的前提下，所允许的抽样极限误差越小，即抽样估计的精确度要求越高，样本容量应越大；所允许的抽样极限误差越大，所需的样本容量就越小。二者成反比关系。  
3. 抽样推断的可靠度:抽样推断的可靠度是指总体所有可能样本的指标落在一定区间的概率度，即允许误差范围的概率保证程度。概率度用Z或Zα/2表示，即置信水平1-α的统计量，一般简写为t。在其他条件不变的情况下，抽样估计所要求的可靠程度越高，即概率保证程度越高，要求样本含有的总体信息就越多，只有增加样本容量才能满足高精确度的要求；反之，概率保证程度越低，所需的样本容量就越小。二者成正比关系。  
4. 抽样类型和方法:概率抽样的主要类型有简单随机抽样、系统随机抽样、分层随机抽样、整群随机抽样、多阶段随机抽样等。在简单随机抽样中，根据同一单位是否允许重复抽取方式的不同，抽样方法可分为重复抽样和不重复抽样。由于在同样的条件下，不同的抽样方式会产生不同的抽样误差，因此，样本容量也应有所不同。一般来说，分层随机抽样和系统随机抽样的样本容量可定得小些，若用简单随机抽样和整群随机抽样方式，抽样的样本容量就要定得大些。至于抽样方法，由于不重复抽样的误差小于重复抽样的误差，因此，不重复抽样的样本容量可比重复抽样的样本容量小些。

#### 简单随机抽样的样本容量计算

确定样本量容量，首先需要确认以下信息：  
1、总体大小n：在进行抽样调查之前，了解自己的研究总体非常有必要。这个总体大概有多少人？它们有什么特点？总体间的差异大不大？谁适合你的样本？……不同的总体可能会直接影响你的抽样方式和样本量。  
2、置信水平Z(通过Z检验统计量表示的置信区间数):常用的置信区间是95%、99%和90%；它们分别对应的z标准化分数是1.96、2.575和1.645。置信度越高需要的样本量越多；95%置信度比90%置信度需要的采样量多40%；在社科研究领域，通常使用95%的置信区间；即，95%的置信区间将会包含总体均值。即：有效抽样数据占样本容量的比例，一般常用置信度有95% 90%这些，在把置信度的z值带到公式里算样本量n。  
3、误差范围（置信区间）E（可以根据均值的百分比设定）:抽样调查过程中不可避免会存在误差。简而言之，置信区间就是你对样本的调查结果允许的正偏差和负偏差。或者，换句话说，你调查的结果与真实结果之间的偏差。比如你调查到某市的平均工资是5000元，误差幅度是5%，那么说明抽样误差在±250元以内。在样本量相同的情况下，置信水平越高，置信区间越宽。由于是倒数平方关系，抽样误差减小为1/2，抽样量需要增加为4倍  
4、方差σ：抽样个体值和整体均值之间的偏离程度，抽样数值分布越分散方差越大，需要的采样量越多；
5、标准误差S:用于代替总体标准差σ;标准偏差用来表示抽样个体值和整体均值之间的偏离程度。标准差越大，表明样本的离散程度越大，实际需要的样本量也就越多。

***简单随机抽样下（有放回），样本总量n的标准计算公式为：  
n = ((Z x σ)/d)^2 或 (Z^2 x σ^2) / d^2  
其中，Z(Zα/2)为置信区间、n为样本容量、d为抽样误差范围、σ为标准差，一般取0.5  
当总体标准差σ未知时，可以使用之前推算的总体标准误差s代替总体标准差σ，得到的公式为  
n = ((Z x s)/d)^2 或 (Z^2 x s^2) / d^2***。

***简单随机抽样，且在不重复抽样条件下，样本容量的计算公式为：  
n = (N x t^2 x σ^2) / (N x Δ^2 + (t^2 x σ^2)) 或 n = (N x t^2 x (Px(1-P))) / (N x Δ^2 + t^2 x (Px(1-P)))  
N代表样本总数，n代表样本容量，t代表概率度Zα/2，Δ(E)代表极限误差，σ^2代表总体方差，Px(1－P)表示成数方差***。

计算样本量的几种情况

##### 给定置信区间、置信水平和标准差的情况下估算样本量。

在统计调查过程中，如果样本容量太小，样本对总体的估计缺乏代表性，难以保证分析结果的可信度；但如果样本量过大，又会浪费人力物力，增加不必要的工作量。因此，选择合适的样本容量非常重要。

在设计统计调查和实验时，我们经常提前知道**可接受的误差幅度**，以及**置信度**。然后根据标准误的公式以及给定的误差幅度计算需要的样本量n。  
例如：我们在居民家庭收入的调查中，已知样本标准差为s=53794.82，那么需要多大的样本容量才能保证抽样误差控制在±800元以内（置信度为95%）？  
根据标准误的公式以及给定的误差幅度，得到如下计算公式：
n = (Z x σ / d)^2 = (1.96σ/E)^2

**公式中的1.96对应的就是95%的置信度。在统计学中，如果没有特殊说明，置信水平一般取95%。对应的显著水平为0.05**。

准确的样本容量公式需要知道总体标准差σ, 在实际操作中, 我们很少会知道**总体标准差**。  
因此，为了使用样本容量公式，我们通常根据先前的研究、预备试验或有根据的推测来估计总体标准差。在此，我们用**样本标准差s代替总体标准差σ**：  
n = (Z x σ / d)^2 = (1.96σ/E)^2 = (1.96s/E)^2

E表示的是误差幅度。将s和E代入公式，得到样本量n:
n = (Z x σ / d)^2 = (1.96σ/E)^2 = (1.96s/E)^2 = ((1.96 x 53794.82)/800)^2 = 17371

实际的样本容量必须是一个整数，所以我们可以将样本容量公式的结果取一个最接近的整数。任何一个样本容量如果大于满足给定误差幅度要求的样本容量，则其误差幅度与之相同或较小。  因此，要想将抽样误差控制在±800元以内，需要将样本容量至少要增加到17371个。

***值得注意的是：只有样本容量足够大时，这个结果才理想。如果从非正态分布中抽取小样本，那么用s来代替σ结果将会很差***。

##### 给定置信区间、置信水平，但不知道标准差的情况下估算样本量

这时候，我们可以通过估计总体比例的方式选择合适的样本容量。

***使用下面这个公式（Cochran公式）：  
n = (Z^2 x P x (1-P)) / E^2  
其中，Z(Zα/2)为置信区间、n为样本容量、E为抽样误差范围、P为估算的具有希望研究的相关属性的样本占总体的比例***

注意：公式中E的值和置信区间一般会事先确定，如果能够知道具体的总体比例 ，就能够直接求出样本量。但是在实际调查中， 一般未知，可以采用试调查得到一个初始样本，以该初始样本的比例作为P的估计值

但P的取值无法确定时，用 (1−p)的最大可能值代替实际的 (1−p)，这个近似计算出的样本量比实际所需的样本量一般要大，只有当P接近时，样本量的计算结果才是精确的。  
例如，预期以99%的置信区间和不超过1.5%的误差幅度估计样本量。根据公式计算过程如下：  
n = (Z^2 x P x (1-P)) / E^2 = (1.92^2 x P x (1-P)) / E^2 = 1.92^2/4E^2 = 1.92^2/4E^2 = 1.92^2/4 x 0.015^2 = 4296

***如果我们研究的总体较小，还可以使用以下公式修改我们在上述公式中计算的样本量：  
m = (n×N)/(N+n-1)  
m:修改后的样本量；  
n：原样本量；  
N：总量***。  

这里n是用Cochran计算得到的样本量，N是总体大小，m是新调整后的样本大小。在我们之前的例子中，如果调查总体是10000，我们会计算得到：4269 /（1+（4269/10000））≈2992因此，对于这个较小的人口，我们只需要2992个样本，样本量明显减小

上述只是估算样本量的基本方法，其实在实际操作过程中，需要考虑的因素可能更多（不过对于一般的问卷调查基本够用了）。  

下面是大家常面临的几个问题：  
1、 我们常说问卷样本量至少要是问卷量表条目（或自变量数目）的5-10倍，或10-20倍，这其实是为了方便后续开展因子分析和建立结构方程模型。  
2、 我们在设置调查问卷的时候，如果设置了较多的分类变量（比如不同的职业、年龄段等），且要对它们进行分析和比较，那么请尽量保证每种类别的样本量超过30；如果按城市分类，尽量保证每个城市样本量不低于100。  
比如你想要比较不同职业群体对某事件的看法是否存在显著差异？如果某个职业的样本量太小（小于5），则不能进行卡方检验。

#### 分层随机抽样的样本容量

分层随机抽样，也称类型随机抽样，是指首先将调查对象的总体单位按照一定的标准分成各种不同的类别(或组)，然后根据各类别(或组)的单位数与总体单位数的比例确定从各类别(或组)中抽取样本的数量，最后按照随机原则从各类(或组)中抽取样本。

对于分层抽样，在总的样本量一定时，一个重要的问题是各层应该分配多少样本量。实际工作中有不同的分配方法，可以按对各层进行常数分配，也可以按各层单位数占总体单位数的比例分配，还可以采用在总费用一定条件下使估计量方差达到最小的最优分配等，其中等比例分配是较为常用的方法。分层抽样是对每一组抽样，不存在样本组间误差，抽样平均误差取决于各组内方差的平均水平，即以各组样本单位数为权数，计算各组内方差的平均数。因此可用组内方差平均数计算出抽样平均误差。

重复抽样时的样本容量：

***在重复抽样条件下，样本容量的计算公式为：  
n = Z^2 x mean(σ^2) / Δ^2 或 n = Z^2 x mean(Px(1-P)) / Δ^2
n代表样本容量，t代表概率度Zα/2，Δ(E)代表极限误差，mean(σ^2)代表组内平均方差，mean(Px(1-P))表示成数的平均组内方差***。

不重复抽样时的样本容量:

***在不重复抽样条件下，样本容量的计算公式为：  
n = (N x t^2 x mean(σ^2)) / (N x Δ^2 + (t^2 x mean(σ^2))) 或 n = (N x t^2 x mean((Px(1-P)))) / (N x Δ^2 + t^2 x mean((Px(1-P))))  
N代表样本总数，n代表样本容量，t代表概率度Zα/2，Δ(E)代表极限误差，mean(σ^2)代表组内平均方差，mean(Px(1-P))表示成数的平均组内方差***。

各层样本量的确定:

***当样本容量n确定之后，各层应抽取的样本单位数可采用等比例法进行分配，计算公式为：  
ni = (n x Ni)/N  
n为第i层应抽取的样本数，n为样本容量，Ni为第i层样本数，N为总体单位数***

#### 整群随机抽样的样本容量

整群随机抽样又称聚类抽样，是把总体先分为若干个子群，然后抽取若干群作为样本单位的一种抽样方式。整群抽样是对选中的群进行全面调查，所以只存在群间抽样误差，不存在群内抽样误差，因此抽样平均误差可根据群间方差推算出来。由于整群抽样一般是不重复抽样，故应按不重复抽样计算必要的抽样群数。

**由整群抽样的极限误差和抽样标准误差公式导出样本容量计算公式为：  
n = (N x t^2 x σr^2) / (N x Δ^2 + (t^2 x σr^2)) 或 n = (N x t^2 x (Prx(1-Pr))) / (N x Δ^2 + t^2 x (Px(1-Pr)))  
N代表样本总数，n代表样本容量，t代表概率度Zα/2，Δ(E)代表极限误差，σr^2 代表群间方差，Pr代表成数的群间方差**

#### 等距抽样样本容量的确定

等距抽样也称为系统抽样、机械抽样，是将总体中各单位按一定顺序排列,根据样本容量要求确定抽选间隔，然后随机确定起点，每隔一定的间隔抽取一个单位的一种抽样方式。根据总体单位排列方法，等距抽样的单位排列可分为三类：按有关标志排队、按无关标志排队以及介于按有关标志排队和按无关标志排队之间的按自然状态排列

无关标志排队的等距抽样  
若对总体采用按无关标志排队的等距抽样时，可采用**简单随机抽样**的公式确定等距抽样的样本容量。由于等距抽样一般都是不重复抽样，应采用在**不重复抽样条件下**的样本容量的计算公式。

有关标志排队的等距抽样  
若对总体采用按有关标志排队的等距抽样，则样本容量的确定，可采用**分层抽样**的样本容量公式确定样本容量。但应注意有序系统抽样的样本容量计算所需的平均组内方差应根据以往的资料作出估计。

### 非概率抽样样本容量的计算

非概率抽样不遵循大数定理，故不能使用一般方法数学/定量方法计算样本量

### 确定样本容量：经验法则

在抽样调查中,除上述利用公式来计算样本容量,还有一种常用的方法,即采用经验法则。  
经验法则是建立在过去抽取满足统计方法要求的样本量所累积下来的经验。使用这个方法时很少需要统计方法知识,但是得出的样本大小很接近统计方法计算出的结果。在采用经验法则时,有关样本量大小的一项原则是：总体越小,要得到精确样本,即有较高概率得出与总体相同结果的样本,抽样比率就要越大。较大的总体能够使较小的抽样比得出同样好的样本。这是因为随着总体人数的增长,样本大小的精确性会随之增加。

对于规模较小的总体(1000人以下),研究者需要比较大的抽样比率(大约30%)为要有较高的精确性,这时需要大约300个样本；  
对于中等规模的总体(如10000人),要达到同样的精确度,抽样比率为10%或大约1000个样本量就可以。  
就大规模的总体(超过150000)而言,抽样比率为1%或大约1500个样本量就能得出正确的结果。  
如果是非常大的总体（超过1000万）。研究者可以使用0.025%抽样比或者大约2500个样本,就能够得出精确的结果。  
当抽样比率非常小时,总体大小的影响力就不那么重要了。  
从2亿总体中抽取一个2500左右的样本,与从1000万总体中抽出同样规模的样本,它们的精确程度是完全相同的。

### 确定样本容量的相关问题

#### 有关总体方差的问题

样本容量的确定是在调查之前进行的，这样总体方差(或样本方差)一般是未知的。在实际工作中往往利用有关资料代替。  
如果在本次调查之前，曾搞过同类问题的全面调查，可用全面调查的有关资料代替；  
在进行正式调查之前，组织两次或两次以上试验性抽样，用试验样本的方差来代替；  
成数方差在完全缺乏资料的情况下，可用成数方差的极大值0.25(P=0.5)来代替。

#### 一次调查满足多项需要

应用公式计算的样本容量是最低的，也是最必要的样本容量。有时在进行抽样调查时，一次调查要同时满足平均数和成数两个方面需要，这样根据样本容量计算公式得出的必要样本容量可能不相等。  
为了同时满足两个推断的要求，一般应选用其中较大的样本单位数作为样本容量

## 现场人口调查设计：研究州级别的人口调查

整个州级别的失业率人口调查集中在每个州之内，目标总体的每个成员都存在相同的机会被选入样本。对于全国来说，抽样比大约为1500：1；而最小的州到最大的州，比例从200：1至2500：1不等。  
而设计的目的，是要求以接近相同的精度估计每个州/自治区中各自的失业人数；这等价51各州中，子样本容量大体相同。因此，各州的样本容量与总体的容量的比率必然存在区别。  
普查中，一般选择16个不同的基本抽样单元，以便交替轮换样本的一部分，以防止长时间多次访问样本对象而不受欢迎，导致出现偏性。

1. **首先确定抽样对象**，即将所有抽样对象（城市/县）分成不同的**抽样群组**，每个抽样群组包含一个市/县或一组相邻的县。继而**对不同的抽样群组分为多个层（基于相近的人口/经济特征；类似人口变化率，农业工人数等）**；层不跨州，且大抽样群组（纽约等）自成一层
2. 在**每个层中抽取一个抽样群组**，抽样时要求层中每个抽样群组被抽中的机会和群组中人口数量相关。而抽样均针对每个层中抽取到的抽样群组进行
3. **每个抽样群组中再划分多个基本抽样单元**，每个单元由4个住房组成。针对这些基本抽样单元进行随机抽取；并研究这些基本抽样单元中**所有年满16岁的人口**

## 调查的实施

使用上述方法，在八十年代末产生了67000个住房单元。其中11000个单元不可取（抽中空/拆毁的住房），另外3000个单元无法利用（无人在家，不配合）。  
故，最终剩下53000个住房单元接受调查。这些单元中，每个16岁之上的成员均被询问有关他们上周工作经历的问题。  
基于回答，总体来说可以分为3类：  
1、受雇的（上周从事任何有报酬的工的人/在某家庭业务中进行15小时工作/离开固定工作的休假者）  
2、失业的（上周没有受雇但可以工作，且过去四周来一直在找工作的人）  
3、劳动之外的人（既非受雇又非失业状态）

针对受雇佣的人，询问关于他们的上班时间和工作类型；  
对于失业的人，询问关于他们的最后职业，何时因何离职，及如果找工作;  
对于那些劳动之外的人，询问他们是否料理家务，或者上学或不能工作，或由于某种原因而不工作

根据定义，民用劳动力包括全部受雇或失业的平民（非军人），根据80年代的普查结果，民用劳动力总数为118.7+6.9 = 125.6百万人  
失业率为失业民用劳动率的百分数，根据上例，80年代的失业率为 6.9/125.6 = 5.5%.  
这个5.5%是所有民众子群失业率的平均数；如果希望对不同民众子群组进行研究，可以在不同维度上设计更多的详细分组（例如年龄，性别，受教育程度，种族，婚姻状况等），然后使用交叉表将数据进行展示。

当一个大的样本被交叉表列表时，在某些分类中可能仅仅保存有一些小的子样本。故，基于此的子总体的推断会变得靠不住。  
但是假设每个估计以概率95%在其真值的1%范围内，对1000个估计来说，它们中的少数几个出现比1%大约多的偏离不足为奇。  
当子样本讲到一定容量阙值时（50左右），这些状态应不再统计

## 样本加权

***加权有助于控制机会变差的影响  
例如样本中存在部分群组的事件机会较低，这样会引起样本总体的事件机会下降，最终引起对总体推断时出现偏性  
故，可以根据总体中相关群组所在的比例进行对此类群组赋予较小的权重，使得样本和总体一致  
另外，如果样本中抽出的某些群体不足时，也需要对这些群组进行加权，以矫正机会变差时引起的不平衡，并减小抽样误差***

假设统计局在所抽的115000个样本中发现了4536个失业的样本对象，而统计局的抽样原则为：1500人中抽1人。  
这很容易被想成样本中的一个人代表1500个总体中的对象，而得出总体中失业的人数约有1500 * 4536 = 680400人。  
但是实际上，统计局需要对分群组对每个样本进行加权（依据年龄，性别，种族，居住位置等）。

## 抽样中的标准误差

美国统计局进行的人口调查，实际存在较大的误差，这是因为他们采用的基本抽样单元是4个毗邻住房的整群。整群中，每个16岁以上的人都会加入样本当中，这存在了相当的偏性：  
生活在统一群组内的人互相类同（家庭背景，学历，就业状况等）。  
若使用了简单随机抽样，则类似的问题很难出现：同时抽中1个人和他的邻居的机会很小。故，每选一个新人进入随机样本中，都会提供另外的，独立于其他样本对象的信息。  
因此，统计局得到的抽样样本所含的信息小于同容量简单随机抽样样本的信息，精确性上有所降低。对于此问题，则需要使用加权的方法进行平衡。

***整群样本比同容量简单随机样本的信息少，因此针对简单随机样本有关的标准差公式不适用此情况***。、

***整群样本的标准误差可以使用半样本法由数据估算出（一种细节复杂，需要大量计算，但是逻辑简单的估算方法），即将样本刨析成两个互相独立且具有相同机会习性的两个部分进行对比，并查看他们多模相符。  
实际上，如果统计局希望了解人口调查的精准程度，可以按照完全相同的方法再进行一次独立的调查；再比对两次调查的结果，但是成本较高，不推荐使用***。

例如：假设调查的一部分民用劳动力为125.5百万，另一部分为125.7百万，差异即为机会误差，而民用劳动力的总体估计为整体的平均数（125.5+125.7）/2， = 125.6百万  
两个分组分别估计偏离他们的平均数0.1百万，故0.1百万为标准误差。

如果基于一次的剖面分析得到的标准误差并不可靠，但是通过使用不同的剖面分析方法并利用取均方根取得标准误差的方式相结合，即可得到更加可靠的结果。  
为了计算标准误差，需要知道样本数据之外的更多问题：数据如何选取。故，针对简单随机抽样方法，存在一个标准误差，而对于整群样本则存在另外一个标准误差。  
***标准误差的公式必须注意考虑用以抽取样本的概率方法的细节，对于方便样本（即不使用概率方法抽取的样本），标准误差一般没有意义***

## 数据的质量

为了控制调查质量。需要标准化整体的调查操作，并且针对参与调查的调查人员，需要进行完备的培训。上岗之后，每月也需要固定数小时的培训。  
另外，约3%的月度样本（概率抽样程序选取）需要由主管人员亲自进行调查。并对存在不符的情况和调查人员重新讨论，并矫正。

## 偏性

偏性比误差更不易察觉，***当偏性多多少少分布在整个样本时，它不能通过仅查看数据检查出，且标准误差对这类偏性可以忽略不记***  
总体来说，偏性的影响是较小的，但是确切大小也是难以估算的。

总的来说，偏性存在以下来源：  
1. 人口调查数据设计基于人口普查数据，而人口普查数据中存在一定缺口（一个难以确定的小百分数）。很难调整失业的估计人数去补足这部分缺口  
2. 不回答偏性：现场人口调查缺失的人可能略有别于他们查找到的人  
3. 定义上相对模糊的部分：定义一定是主观的，"受雇"和"失业"间的界限相对模糊，例如打零工的人会和存在专职工作的人一同分类为受雇人群，尽管他们可能被分类为失业。 

故，失业率中的偏性被认为大于标准误差

# 平均数的精度：通过标准误差计算平均单次抽得数的机会变异

计算单次抽得的平均数和标准误差，可以通过计算指定次数的抽取数的总和与指定次数下的标准误差，再求其平均值即可

例：针对盒子【1，2，3，4，5，6，7】，求25次抽取下，单次抽取的值及其标准误差  
通过题目可知：此盒中单次抽取平均值/期望值为(1+2+3+4+5+6+7)/7 = 4，故25次抽取下期望值为100  
通过计算，盒中平均差为2，故25次抽取的标准误差为 平方根(25) * 2 = 10  
故，25次抽取时，得到的结果为100 +- 10，单次抽取时的结果为 100/25 +- 10/25 = 4 +-0.4  

***当从盒子中进行有放回式的抽取时，盒子的单次抽取的平均数的期望值等于盒子中的平均值；  
抽得的平均数可以用于估算盒子里的平均数，由于机会误差，盒子里的平均数的估计值将会有一定偏离，而SE则表示这些偏离的大小  
盒子的标准误差SE等同于：  
多次抽取的和的SE / 抽取次数***

***当从盒中进行有放回的随机抽取时，抽取的平衡数的概率直方图符合正态曲线，即使盒子里的数值并不如此；  
此时，直方图必须换算成标准单位，且抽取的次数必须充足多  
这是因为：在有足够充值的抽取次数后，盒子抽取数字之和符合正态曲线，而单次抽取的平均数等于和/抽取次数  
这一除法仅仅是在尺度上进行了改变，且会因为使用标准单位计算的原因所抵消***

例2：从盒【1，2，3，4，5，6，7】中随机抽取放回的方式抽取100次，问：单次抽取的平均数/期望值为多少，单次抽取平均数/期望值大于4.2的机会为多少  
根据题目可知：单次平均期望值为(1+2+3+4+5+6+7)/7 = 4，故100次抽取下期望值为400  
通过计算可知：盒子的标准差为2，故100次抽取得到的标准误差为： 平方根(100) * 2 = 20  
故，100次抽取后，抽取数据的和为 400 (+-20)；而单次抽取的平均期望值为：400/100 = 4，而平均标准误差为 20/100 = 0.2  
故：单次抽取的平均值/期望值为 4(+-0.2)  
根据平方根法则可知：标准误差在随机过程中可被视为标准差/标准单位，而单次抽取平均值/期望值则被视为正态曲线中的平均值；  
故，可知：4.2位置所在正态曲线中1SD的位置（(4.2-4.0)/0.2）；而+-1SD位置占正态曲线的68%，而+1SD，小于-1SD位置的面积/机会为32%；  
故，大于4.2/1SD的面积/机会为 32%/2 = 16%

综合例1/例2可知：当抽取次数增加4倍时(100 * 4)，则单次抽取的误差减少2倍（0.4 / 平方根(4) = 0.2）  

***当从一个装有票子的盒子中，随机有放回的抽取时，抽取次数乘以某一因子（例如上例中的4），则抽取平均数的标准误差/SE等同于：  
抽取次数未乘以某一因子的结果 除以 因子的平方根(平方根（4） = 2)。  
故，结合平均数率推断出：抽取次数增大时，抽取卡面之和的平均误差将增加，而平均数的平均误差将减小。  
这是因为：和的标准误差将随着抽取次数增大，而按照抽取次数的平方根增长；尽管标准误差的绝对值将增加，但是因为抽取次数需要经过平方根计算的原因，抽取次数的增长相对较小；  
于是，使用抽取次数相除，使得单次抽取的标准误差下降***。

当使用不放回抽取时，计算标准误差需要乘上修正因子，当抽取次数和盒中票子总数相比相对较小时，修正因子将接近1，则可以忽略乘修正的这一步骤

注：一个盒子中随机有放回的抽取数据，**抽取数据之和的标准误差/SE**为 **平方根(抽取次数) * 盒子SD**；  
故，**在盒子中单次抽取的标准误差为**:**(平方根(抽取次数) * 盒子SD) / 抽取次数**，此公式同时可以简化为：  
**(盒子的SD) / 平方根(抽取次数)**，也可以被简写为 **σ/平方根(n)**，  
此时的σ(Sigma)为盒子的SD，n为抽取次数

## 样本的平均数：从未知盒中中抽取样本，求盒子的单次抽取期望值和标准误差

***针对简单随机抽样样本，样本的SD可以用来估算盒子的SD。当样本容量足够大，则估计将足够好***

例：针对某个城市中存在的25000户家庭进行平均收入的调查，调查机构通过简单随机抽样的方式抽取了900户家庭进行检查  
这900户家庭中平均收入为32400美元，标准差/SD为18000美元，求25000户家庭的平均收入及相关的机会误差

通过题目可知：900户家庭平均收入为32400美元，因为使用了简单随机抽样，则可认为25000户中的平均收入也为32400美元  
根据题目可知，随机抽样等同于建立了25000个样本的盒中模型，盒子中卡片上标注了每户的收入，总共从中抽取了900次  
根据样本/盒中结果可知：**900次抽取的样本**的标准差/SD为18000美元，故盒中**900抽取收入之和的**标准误差为 平方根(900) * 18000 = 540000美元  
故，盒中的**单样本期望值**为32400，而**单样本标准误差**为540000/900=600  
故，总体中25000户家庭的单户期望值应为32400 +-600

问：上例中95%的置信区间的数据范围为多少？  
针对置信区间的问题，类似于定性数据的置信区间，可以使用盒子的平均值定性的推算置信区间。  
针对上例：25000个样本的单次抽取的平均值95%的置信区间，等同于单次抽取的平均值+-2SD/SE，即： 32400 +- 1200

**此时，盒子模型中的SD和SE承担了不同的角色：  
SD指出了一个盒子模型中，抽样结果的分布，即：指出了一个家庭的收入离平均数（一个典型家庭的收入）有多远  
SE则指出样本平均数离总体平均数（一个典型的样本）有多远**

***即使数据全然不遵循正态曲线分布，但是抽得样本的平均数的概率直方图依旧符合正态曲线（当抽取数据充足时，小样本情况下依旧不符合正态曲线）  
这是因为：分布直方图仅仅显示出总体/样本横轴/x轴对应区间下的占比/分布  
而抽取的概率分布直方图指的是：在进行抽取时抽得每个单位的概率，正因为分布不同，所以分布直方图中占比高的地方被抽中的概率高，即为概率分布直方图中面积大的部分，反之亦然  
故，最终的概率分布直方图，在一定充足的抽取次数后，一定符合正态曲线***。

## 机会过程/盒子模型中的SE

从宏观上来说，**标准误差**应该被定义为**机会误差的可能大小**  
**SE表示偏离量的可能大小，它是正/负的数目**

但是针对不同的有放回随机抽取的盒子模型(定性/定量)，SE的具体意义也不仅相同：  
***针对盒子模型中抽取样本之和的SE：平方根(抽取次数) * SD  
针对盒子模型中单次抽取平均数的SE：和的SE/抽取次数(σ/平方根(n))  
针对使用定性盒子模型(0-1盒子模型)中计数的SE：0-1盒子中抽取的和的SE  
百分比的SE：计数的SE/抽取次数  
这当中，针对盒子模型抽取样本之和的SE为所有SE的基础***

## 向前或向后推理

**向前推理**，即当前的情况中，***给出了盒子模型的平均值/期望值和标准差，用以推算总体中数据的情况***  
则可以使用标准差计算出标准误差。**此时盒子平均数的置信区间可以通过使用抽得数据的平均数向左右两侧平移1或多个标准误差来得到；而置信水平可由正态曲线得出（仅限大抽取次数）**

**向后推理**，即：***给出了总体的细节和抽样的具体要求，并要求使用当前的结果自建盒子模型，自行推算盒子模型的期望值，标准差和标准误差***    
在这种情况下，需要使用盒子中抽取的具体结果对数据计算平均值/期望值及标准误差。其中置信区间可根据正态曲线拟合，并使用标准误差作为标准单位求得，即平均值偏离多少个标准误差为偏离多少个标准单位/SD。  
此时的标准误差本身仅仅是标准误差的近似值（通过正态近似拟合时，没有求得概率直方图的端点；但是当样本本身数量相对很大时，误差可以忽略。），但是标准误差的含义相同：假设用样本平均数估计盒平均数，估计产生的平均偏离值。

***注意：当前的所有结论均为通过简单随机抽取的方式进行研究得到的，也仅仅适用于简单随机抽样的情况***

# 机会模型：测量误差模型

## 估计平均数的精度：使用机会的频率理论进行

**频率理论被发展出，用于处理一类非常特殊的问题：在机会游戏中计算可能性  
故，将赌场中的理论应用在赌场之外，需要将现实情况抽象成为赌场中的理想情况  
最终抽象成为盒子模型对实际中的情况进行模拟，这些盒子模型被称为机会模型/随机模型**

**机会误差的来源:任何测量/测量时间均存在机会误差，如果重复进行测试/实验，则机会误差就会出现稍许的不同  
因此，要得到机会误差的大小，最好重复测量若干次。这些测量值的离散程度，由他们的SD进行表示，  
并给出在单次测量中的机会误差的可能大小的一个估计；这被称之为平方根法则，且仅适用于有放回的随机抽取(或样本量比总体相对较小的无放回随机抽样)***。

例：针对标准10克单位进行100次测量，测量结果均不为10克。对测量结果计算可知：测量的标准差为6微克，而测量的平均值不到10克，为10克差404.6微克  
根据上述条件可知：100次测量的标准误差为 平方根(100) * 6 = 60微克，而单次测量平均值的标准误差为 60/100 = 0.6微克  
根据上述结果可知：标准10克单位实际重量为10克以下404.6微克 +- 0.6微克

**计算中产生的6微克和0.6微克的解释如下:  
6微克为标准差/SD，表示单次测量值精确到6微克左右。  
0.6微克为标准误差/SE，即表示100次测量得到的平均数精确到0.6微克左右**。

例2：针对一个砝码进行100次测量，100次测量得到的平均数为1千克又715微克，标准差为80微克，问：  
1.*单次测量值*可能偏离确切重量8微克还是80微克  
2.*100次抽取后*测量平均数可能偏离确切重列8微克还是80微克

1.根据题目可知，所求的为单次测量值的精确程度，即抽样中的标准差，故为80微克  
2.根据题目可知，所求的为100次抽取下的精确程度，即为 (平方根(100) * 80)/100 = 8微克

为了使得整体的估计更加准确，则可以引入置信区间，此例中，95%的置信区间为平均数+-2SE，即:  
1千克之上715毫克+- 2 * 8；即1千克之上699毫克至731毫克

***因为机会过程中存在机会误差的原因，故机会存在于测量过程之中，而不是被测事物当中  
上例中，砝码的确切重量不受机会变异影响；故，影响每次测量结果的条件，为测试过程中产生的机会误差，这证明了上面的推论***

只有进充足多次数的测量时，才可以使用正态曲线来拟合机会过程的概率分布直方图，最终计算出置信区间  
而抽样次数不充足时，概率分布直方图不符合正态分布，故无法使用正态曲线拟合。这时应使用**t_分布**

## 机会模型

针对盒子模型，只有当**总体数据的变异性**和盒子中重复抽取的**样本数据的变异性**想象时，通过整体求出平均数标准误差的方法才是可行的  
故，**如果整个抽取期间，数据呈现一定趋势（例如不放回的抽取使得概率上升）或一定规律模式，则盒子模型不能应用  
这是因为：从盒子里进行抽样时出现的趋势/规律不等于整个样本的趋势/规律  
故：平方根法则仅适用于抽样行为，即取自盒子模型的抽取数**

例：针对一段时间内的国家人口普查数据（20个数据，数据本身逐步上升），求得平均数，标准差/SD和标准误差/SE，这些指标是否有意义  
作为描述统计指标，平均数和标准差存在意义，即：通过描述数据分布的情况概况了数据  
但是标准误差/SE没有实际意义：数据本身并不是通过抽取得到，即和抽取的精度/偏离平均值的偏离度无关（数据本身已提供了精确结果，且数据本身不存在抽样）。

例2：气温模型：针对某地气温，显示出极强的季节性模式：总体来说，夏天气温高，而冬天气温相对较低。即：  
数据本身狭义来说**部分随机**，即在一定时间之内（季节出现变化之前）气温相对随机；总体来说呈现线性回归。  
**这时，数据并非通过盒子模型抽取，而不接受适用平方根法则**

***可以适用平方根法则的数据(盒子模型)一定是随机抽取的数据，这些数据绘图后不呈现任何趋势（上升/回归）仅仅是稀疏的散布在图中***

## 高斯模型

***高斯模型：针对某个量/事件做重复测量，每个测量值于确切值之间相差一个机会误差。这个误差就像从盒子(误差值形成的盒子/误差盒)中进行一次随机抽取一样  
因为这一系列的测量是独立的且在相同条件下进行的，因此每次测量的机会误差值就像从误差盒中随机有放回的抽取一样。
这一模型基于以下两点：机会误差不是系统的取正值或负值，且误差盒中平均数为0***

***在高斯模型中，没测量一次/事件发生一次，就从误差盒中随机有放回的取一张票。票上的数是机会误差。将其加到确切值上将得到最后的测量值。  
误差盒的平均数为0***。

***因为误差盒的平均值为0，故误差盒中的SD可被认为是衡量每次事件/抽样机会误差的标准。  
在使用高斯模型时，可以用一列重复测量的SD来估计误差盒的SD。误差盒的SD表示一次在一次测量中机会误差的可能大小。  
当测量值足够多的时候，这个估计是可用的***。

通常，误差盒中的SD是未知的，以10克标准单位的测量为例，取其测量100次的测量值。  
根据模型，每个测量值在确切值得附近，偏离为取自误差盒中得一次抽取得到得结果：  
第一次测试确切值=确切重量+误差盒第一次抽取得数  
第二次测试确切值=确切重量+误差盒第二次抽取得数  
...
第一百次测试确切值=确切重量+误差盒第一百次抽取得数  

**此例中，因为针对误差盒进行了100次抽取，即进行了足够得抽取/抽样；  
则实际误差盒中的SD可以使用此方法有效的得出**

这当中最重要的问题是：**抽取的数据（确切重量和误差盒抽取数）无法通过实验得到（确切重量是实验的目的）**；  
因为抽取样本中的机会误差等同于总体的机会误差，且测量数据的机会误差是基于机会过程，而非事件/被测目标本身的，故：  
**针对存在大量测量记录/经验的时候，可以使用之前抽得取的样本数据的标准差/SD去推算误差盒的标准差/SD；而此时得标准差也可以代表随机过程的标准误差**

**系列的平均数比起任意一次测试更加精准，相差一个测试次数的平方根组成的因子。这假定了数据符合高斯分布**。

高斯模型中存在的假设是：**测量过程中，测量结果没有被偏性所影响**。  
在出现偏性时，每次测量/事件得到的结果将由三部分组成：确切值+偏度+机会误差  
于是，样本的平均数的SE不再/不仅仅表示样本值得平均数距确切值得距离，而是表示据**确切值+偏度**得距离。  
而，偏度往往很难被发现，同时也很难被计算。

例：在对一个10克标准器具进行100次测量后，得到了测量值得SD为6毫克。在针对另外一个10克标准器具进行了25次测量后发现，这25次测量平均数为10又605毫克克，而测量值得标准差为7毫克  
求第二个标准器具的平均标准误差

根据上述结果可知：因为是针对标准器具进行的检查，大部分偏性已经被考虑在内并被处理，故当前的测量值中仅存在确切值和机会误差  
现在已知，机会误差存在于随机过程之中而不是检测对象当中；故，可根据针对第一个10克标准器具的检测的标准差，求出误差盒的标准差，最后测算出单次的平均误差；  
而不是仅仅使用第二次检查时得到的SD作为误差盒的标准差/SD  

根据题目可知，针对第一个标准器具检测实验的标准差/SD为6，即误差盒的标准差为6。即单次检测时机会误差的大小可能为6。  
而25次平均检查的平均标准误差为：(平方根(25) * 6)/25 = 1.2微克。即，25次测试的平均数的标准误差为1.2毫克。

**统计推断可以通过对数据提出一个明确的的机会模型，而证明其合理性。没有盒子模型，就没有推断**

***被测对象确切值得置信区间，可以通过测量值的平均数向左右适当移动数个SE求得置信水平则是由正态曲线获得（盒子模型适合，且存在充足的抽样次数）  
如果模型不适用，那么获得置信区间的办法也不相同；当数据存在趋势或规律模式时，使用简单随机抽取的置信区间公式的结果将存在较大差距***。

# 遗传学中的机会模型

孟德尔通过豌豆发现基因的故事：使用绿色和黄色两种豌豆，且一株作物可以结出两种颜色豌豆的种子。

首先：独立培养绿色系和黄色系的种子（仅挑选出结绿地/黄色的种子进行下一代的培育），然后将培育出的绿色系和黄色系的种子进行杂交(使用黄色系的花粉杂交绿色系的胚珠，或者反之)。  
结果：第一代的种子全部是黄色，使用第一代种子进行杂交，得到比例为75%黄色，25%绿色的种子。由此，可以证明存在基因：  
如果控制豌豆绿色的基因被称为g,控制豌豆为黄色的基因被称为y，则第一代基因中，yg和gy均显示为黄色，而杂交后第二代的种子中，yy,yg,gy均显示黄色，而仅有gg显示绿色。  
故，y被称作显性基因，g被称作隐性基因

通过统计学角度去观察，孟德尔的实验实质上是在进行盒子模型的抽取实验：  
杂交前的盒子模型为【y,y】和【g,g】，通过随机抽取，得到第一代杂交种子【y,g】  
第一代杂交种子进行杂交时的盒子模型为【y,g】和【y,g】得到的结果为【y,y/y,g/g,y/g,g】，从中随机抽取一个作为豌豆的颜色表达基因，其中抽取到绿色即g,g的概率是1/4，即上面体到的25%

## 孟德尔的遗传模型与机会模型

抛开出现这类情况的原因，孟德尔的遗传学实验中得到的结果不应，也不会完全符合25%-75%的定律，这是因为出现机会误差的缘故（例如基因损坏/突变）。

假如，使用8023个对第二代杂交种子进行实验，因为每次实验类似在盒子模型进行抽取，为了计算这之中的标准误差有多大，可以建立定行盒子模型(仅需要颜色而非显性/隐形基因的盒子模型)【0，0，0，1】  
则单次抽取期望值/平均值1/4，而8023个种子/抽取下，抽取的期望值应位2006  
而8023次抽取的标准误差位为 平方根(8023) * (1-0) * 平方根(1、4 * 3/4) = 38.8  
而根据孟德尔的实验报告，他观察到的结果中，第三代杂交结果基本在25%结果的+-5左右，即在8023次抽取的盒子盒子模型拟合的正态曲线的 5/38.8 = 0.129个SD的位置  
这约等于正态曲线面积的12%，即：88%的情况下，结果将不同于孟德尔的报告

最终可以证明：  
孟德尔运气很好  
或  
数据本身被修正过

## 回归率/平均回归的机会模型

针对高尔顿勋爵发现的平均回归趋势，可以使用简单的机会模型表示

此模型的建立基于两个假设：  
1.身高由一个基因对所控制  
2.控制身高的基因以完全可加的方式起作用：假如模型中，存在4个表示身高的基因变量：h*,h**,h',h''，每个基因都会对身高产生一定不同的影响；当获得其中任意一个基因的时，无论其和其他身高基因结合，其依旧会对身高产生正影响（不同于孟德尔的豌豆颜色，因为显性/隐性基因的缘故，绿色基因是否有效功效要由其结合的基因一同决定；身高控制基因不区分显性隐性，只是不同的基因配合在一起得到的结果/影响不同）

当使用大写H时，则表示基因所带来的影响，例如：h*+h'贡献了 H* + H'的身高

父亲和母亲均拥有一个控制身高的基因，而孩子的身高基因，则从父母那里分别得到。  
假如父亲有一对h*,h** 基因，而母亲有一对h',h''基因，则从父亲处得到h* 的概率为1/2，而从母亲处得到h'的概率为1/2  
因此，父亲对孩子身高的贡献值为：1/2 h* + 1/2h** =1/2 H* + 1/2 H** = 1/2(H* + H**)，即身高的一半；即高尔顿回归系数；  
母亲也相同，即母亲身高的一半  
根据上述结论可以推导出：如果在确定父亲和母亲的身高水平的情况下，孩子的身高水平应等于：1/2 (父亲身高 + 母亲身高)，即父母亲身高的中间数  
考虑到男性和女性之间身高的差距，则可以对女性乘以一个身高系数(8%)，使其身高和男性相同。

但是在实际实验的过程中，会发现部分数据不符合上述模型，这是由于机会误差引起的。即：  
***平均回归模型中，儿子身高不遵循父亲身高的正态分布，是因为从父亲身高基因中抽取出现的机会误差***

# 显著性检验/假设检验

例：新简化税法法案的假设检验

议员提出了一条新的简化税法的议案，新法案将不会改变国家总体税收的总数。在法案落实之前，为了保证法案的确是不会影响岁入，需要先使用*微型模拟模型*对法案草稿进行检验  
依据提案，针对现有的100000个个税报税单，使用新提案中的逻辑计算出新提案下的纳税金额，并计算出总体税收  
最后求出法案颁布前/后总体税收的差值，即：颁布提案后的总税收 - 颁布前的税收

根据之前的假设，提案本身不应影响总体税收，故**法案颁布前/后总体税收的差值应为0**。

通过随机抽样的方法，从100000个结果中，随机抽取100个结果，得到的100个报税单的法案颁布前/后总体税收的差值的平均值为(-219)，标准差为725

SD和平均数之间的差距过大的原因：  
数据中存在20%左右的无需纳税的申报单，而其余80%的申报单中应纳税金额差异很大(数据分布直方图中为左偏，曲线右边存在长尾)，故SD和平均数差距较大的情况

## 假设检验

假设检验(Hypothesis Testing)：是推断统计的最后一步，是依据一定的假设条件由样本推断总体的一种方法。  
假设检验其实就是假设和检验两步，先提出假设，之后再来验证假设是不是合理的。

***假设检验的基本思想是小概率反证法思想，小概率思想认为小概率事件在一次试验中基本上不可能发生，在这个方法下，我们首先对总体作出一个假设(原假设，一般假设的是没有异常/没有时间发生发生)，这个假设大概率会成立，如果在一次试验中，试验结果和原假设相背离，也就是小概率事件竟然发生了，那我们就有理由怀疑原假设的真实性，从而拒绝这一假设***。

上例中，通过计算得到了数据的平均值和标准差，只是在针对数据的理解上存在偏差：  
一方认为，数据的平均值存在机会变异，实际数据应在0上；另一方为人，数据可以完整的表示当前的情况，即平均值即是实施法律后的平均值；

为了区分这两种情况，对这两种情况均赋予了相应的专有名词：  
***原假设：即待验假设，假设的期望值，观察到的差异只反映机会变量，即认为平均值仅表现了机会误差；原假设一般使用H0代表  
备择假设：又被称之为对立假设，假设的观察值，即认为观察到的差异是真实的；备择假设一般使用H1代表***

确立原假设与备择假设时应遵循以下两个原则:

1. 原假设是在一次试验中有绝对优势出现的事件，而备择假设在一次试验中不易发生(或几乎不可能发生)的事件。因此，在进行单侧检验时，最好把原假设取为预想结果的反面，即把希望证明的命题放在备择假设上。

2. 将可能犯的严重错误看作第一类错误，因为犯第一类错误的概率可以通过a的大小来控制。犯第二类错误的概率夕是无法控制的。如医生对前来问诊的病人作诊断时，可能会犯“有病看成无病”或者“无病看成有病’的错误，相比较而言，“无病看成有病“的错误更严重，故应将“问诊人有病”

***如果在一次试验中小概率事件竟然发生了，我们就怀疑原假设原假设的正确性，从而拒绝原假设如果在一次试验中小概率事件没有发生，则没有理由怀疑原假设原假设的正确性，因此接受原假设***。

**为了证明原假设的真伪，可以建立一个盒子模型，把原假设和备择假设翻译成有关模型的陈述**：  
原假设认为：盒子模型中的平均数等于0  
备择假设认为：盒子模型中的平均数不等于0

***每一个合理的显著性检验总涉及到一个盒子模型，检验的目的是为了查明一个观察到的差异值是否为真，还是一个机会变异的问题。  
一个真的差异值确实说明了盒子中的某些情况，而不是仅仅抽样一次侥幸成功或失败的反映***。

拒绝域  
能够拒绝原假设的检验统计量的所有可能取值的集合，称为拒绝域；不能够拒绝原假设的检验统计量的所有可能取值的集合称为接受域；根据给定的显著性水平确定的拒绝域的边界值，称为临界值。  
拒绝域就是由显著性水平α所围成的区域。如果利用样本观测结果计算出来的检验统计量的具体数值落在了拒绝域内，就拒绝原假设，否则就不能拒绝原假设  
***拒绝域一般以P值为0.05的SE位置为起始点(被称为α)，向曲线的左边/右边延申***

拒绝域的面积与位置  
拒绝域的大小与人们事先选定的显著性水平有一定关系。在确定了显著性水平α之后，就可以根据α值的大小确定出拒绝域的具体边界值。  
在给定显著性水平后，查统计表就可以得到具体的临界值（也可以直接由Excel中的函数命令计算得到）。将检验统计量的值与临界值进行比较，就可做出拒绝或不拒绝原假设的决策。  
当样本量固定时，拒绝域的面积随着α的减小而减小。α值越小，为拒绝原假设所需要的检验统计量的临界值与原假设的参数值就越远。拒绝域的位置取决于检验是单侧检验还是双侧检验。双侧检验的拒绝域在抽样分布的两侧。而单侧检验中，如果备择假设具有符号“<”，拒绝域位于抽样分布的左侧，称为左侧检验；如果备择假设具有符号“>”，拒绝域位于抽样分布的右侧，称为右侧检验。

## 假设检验/显著性测试的步骤

做假设检验/显著性测试，首先：  
准备好数据，即对数据完成数据清洗工作  
其次：将原假设转为对应的盒子模型，并计算出检验统计量(检验统计量的公式为:(观察值-期望值)/SE，其中期望值的计算应使用盒子模型和原假设一同计算。)  
之后：找到适合的检验统计量的方法（**依赖于模型和所考虑的假设**），并使用方法度量数据和原假设下期望值的差距  
最后：计算所观察到的显著水平值P

上述步骤适用于几乎全部的假设检验模型，不同假设检验的方法的差别，仅仅是针对检验统计量结果的理解。且全部的假设检验模型均可用使用观察到的显著水平值，P值进行理解

**通常，检验的机会值，即观察到的显著水平被称之为P，表示概率；并且常常称为检验的P值**  
由于检验统计量Z依赖于数据，P值也是如此，则P被称为“观察”到的显著水平

***P值（P value）就是当原假设为真时，比所得到的样本观察结果更极端的结果出现的概率。  
P值为小的数值，是推翻原假设的证据，如果P值很小，说明原假设情况的发生的概率很小，而如果出现了，根据小概率原理，我们就有理由拒绝原假设，P值越小，我们拒绝原假设的理由越充分。总之，P值越小，表明结果越显著。但是检验的结果究竟是“显著的”、“中度显著的”还是“高度显著的”需要我们自己根据P值的大小和实际问题来解决***。

***小概率原理是指一个事件的发生概率很小，那么它在一次试验中是几乎不可能发生的，但在多次重复试验中是必然发生的。统计学上，把小概率事件在一次实验中看成是实际不可能发生的事件，一般认为等于或小于0.05或0.01的概率为小概率。***

针对观察到的显著水平P，统计学家认为的将P值进行了实际上的划分，即：P值为多少时，意味着原假设可用证明为有误  
**根据一贯的方法，统计学家将P值分为了三档：  
第一档在5%处，即如果P值小于等于1%，则结果被称为统计高度显著，即原假设被明显证明为小概率事件，故原假设可用确定被拒绝  
第二档在大于1%小于5%处，则结果被称为统计显著，说明较弱的判定结果，故原假设可用被拒绝  
第三档在大于5%处，即被成为统计不显著，说明结果更倾向于接受原假设**

假设检验中P值得逻辑有些反直觉：P值越小说明P值的拒绝域越大，即原假设发生的可能性越低；则原假设被拒绝/认定为否的概率越高

**假设检验不完全是排间的，原假设发生概率低不完全意味着备择假设发生概率的上升**

### 单尾双尾使用条件

***注意：假设检验的P值取值，会和原假设和备择假设的设定完全相关。  
如果备择假设设定为诸如期望值不为某值的情况下，为了保证备择假设相对显著，此时就需要使用双尾检验。  
而如果备择假设设定为大于期望值，则仅需要使用单尾假设即可***

单侧检验指按**分布的一侧计算显著性水平概率的检验**。  
用于检验大于、小于、高于、低于、优于、劣于等有确定性大小关系的假设检验问题。这类问题的确定是有一定的理论依据的。假设检验写作：μ1<μ2或μ1>μ2。

双侧检验指按**分布两端计算显著性水平概率的检验**，应用于理论上不能确定两个总体一个一定比另一个大或小的假设检验。一般假设检验写作H1：μ1≠μ2。

多数情况用双尾，比方说只想看一下A，B间是否右差异，而不具体关注A大于B，还是B大于A，这种情况用双尾

而当你有十足证据表明加了某种处理以后，使得A大于B（或A小于B），那么这给时候用单尾

总结一下，单尾检验是带有方向性的，即A大于B或是B大于A，而双尾检验是没有方向性的，往往只想看A，B之间是否有差异（A等于B还是A不等于B）

1.双尾检验，属于比较性检验，没有具体方向性，只是比较与一个设定值的是否相同，无关乎大小；

2.单尾检验，属于方向性检验，在科研实验或者干扰实验中比较多，给定一个处理，有一个预期结果：相对对照组大或小，已经预设了一个大小的方向关系。

例：

* 适合单尾检验的案例：一位治疗专家设计了一种新的干预方法来治疗某症，他认为新的方法比目前使用的方法费用更低、效果更好；对被试冥想前和后的血压进行比较，看看其血压是否显著下降。

* 适合双尾检验的案例：某心理学家对男女性进行比较，想知道他们在过去的一年里与异性冲突的平均次数是否有差异；比较在嘻哈和爵士两种音乐背景下老鼠的活动水平。

* 判断大耳白兔与青紫蓝兔的血糖含量是否有差异，这时就要用双尾检验，只需判断两者是否相等即可

* 若问大耳白兔的血糖含量是否比青紫蓝低，这时就要用到单尾检验，需判断两者血糖含量大小问题

## 几种常见的假设检验

1.有关平均值参数u的假设检验（Z检验、T检验）  
根据总体方差是否已知及样本容量大小，分为T检验与Z检验

2.有关参数方差σ2的假设检验（F检验(方差分析/ANOVA-test)/联合假设检验/方差检验）
F检验主要用于检验两个分布的方差是否相同

3.检验两个或多个变量之间是否有关系（卡方检验）
卡方检验属于非参数检验，主要是比较两个及两个以上样本率（构成比）以及两个分类变量的关联性分析，其根本思想在于比较理论频数和实际频数的吻合程度或者拟合优度问题。

通俗来说，卡方分布主要用于检验样本是否偏离了期望，例如偏离了期望的分布(拟合优度检验)，期望的比例(列联表)等

## 统计学假设检验的两类错误

假设检验的最终目的是：**去伪存真**，那么它对应的两类错误就是**弃真存伪**。

接受或拒绝H0(原假设)，都可能犯错误：  
* 第一类错误即I型错误，是指拒绝了实际上成立的H0(原假设)，为“弃真”的错误，其概率通常用α表示，这称为显著性水平。α可取单侧也可取双侧，可以根据需要确定α的大小，一般规定α=0.05或α=0.01。
* 第二类错误即Ⅱ型错误，是指不拒绝实际上不成立的H0(原假设)，为“存伪”的错误，其概率通常用β表示。β只能取单尾，假设检验时一般不知道β的值，在一定条件下(如已知两总体的差值δ、样本含量n和检验水准α)可以测算出来。

即：  
第一类错误：原假设是正确的，却拒绝了原假设。例如检查发现男性怀孕。  
第二类错误：原假设是错误的，却没有拒绝原假设。例如检查发现孕妇没有怀孕。

第一类错误为弃真错误，也就是原假设为没有怀孕，但是检验的结果落在拒绝域，因而拒绝没有怀孕的原假设，认定的男士怀孕了，而事实男士根本没有怀孕，这就犯了第一类错误，弃真。  
第二类错误为存伪错误，也就是原假设没有怀孕，检验结果落在接受域，所以接受没有怀孕的原假设，认定女士没有怀孕，而事实上女士是怀孕的，这就犯了第二类错误，存伪。  

扩展资料
我们在做假设检验的时候会犯两种错误：第一，原假设是正确的，而你判断它为错误的；第二，原假设是错误的，而你判断它为正确的。我们分别称这两种错误为第一类错误和第二类错误。

我们常把假设检验比作法庭判案，我们想知道被告是好人还是坏人。原假设是“被告是好人”，备择假设是“被告是坏人”。法庭判案会犯两种错误：如果被告真是好人，而你判他有罪，这是第一类错误(错杀好人)；如果被告真是坏人，而你判他无罪，这是第二类错误(放走坏人)。

记忆方法：我们可以把第一类错误记为“以真为假”，把第二类错误记为“以假为真”。当然我们也可以将第一类错误记为“错杀好人”，把第二类错误记为“放走坏人”。 

在其他条件不变的情况下，如果要求犯第一类错误概率越小，那么犯第二类错误的概率就会越大。这个结论比较容易理解，当我们要求“错杀好人”的概率降低时，那么往往就会“放走坏人”。

同样的，在其他条件不变的情况下，如果要求犯第二类错误概率越小，那么犯第一类错误的概率就会越大。当我们要求“放走坏人”的概率降低时，那么往往就会“错杀好人”。

同样的，在其他条件不变的情况下，如果要求犯第二类错误概率越小，那么犯第一类错误的概率就会越大。当我们要求“放走坏人”的概率降低时，那么往往就会“错杀好人”。

### 两类错误的理解

对于两类错误的理解上，公认的观点是：

犯Ⅰ类错误得危害较大，由于报告了本来不存在的现象，则因此现象而衍生出的后续研究、应用的危害将是不可估量的。相对而言，Ⅱ类错误的危害则相对较小，因为研究者如果对自己的假设很有信心，可能会重新设计实验，再次来过，直到得到自己满意的结果（但是如果对本就错误的观点坚持的话，可能会演变成Ⅰ类错误）。

当然这要从更多的维度和不同的情况来看，

例1:  
判定一个嫌疑人是不是犯了罪，原假设就是这个人没有犯罪，

那么犯一类错误就是认为罪犯有罪，而事实上没有犯罪，也就是被冤枉。犯二类错误就是把有罪的人判定成无罪。

到底那种对于社会的危害更大呢？这个很难说，如果你认为，我宁可错杀三千，绝不放过一个！那你就让第二类错误的概率尽可能小。政治清明的年代，司法应该尽可能减少冤假错案，即所谓疑罪从无和无罪推定的原则。也就是，如果没有足够的人说嫌疑人不是好人，那么司法就应该判定嫌疑人为好人。因为正常情况下，大部分人都是无罪的，原假设也认为嫌疑人是无罪的，而犯罪的人是少数，所以如果一类错误概率大的话，会讲很大一部分人无辜的牵连进来；也可以这样理解，就是无罪的人基数很大，即人数非常多，你稍微把一类错误的概率放大一点就会有很多的人被认定为有罪的。

例2:  
再比如说，我们检查一批灯泡的寿命，原假设认为灯泡寿命是合格的，但是我们抽查的时候恰好查到了寿命比较低的，这样就拒绝了原假设，认为这一批灯泡是不合格的。那么结果是什么呢？就需要把这一批灯泡全部返厂重新检测、返修，甚至是销毁。如果是因为犯了第一类错误，也就是本来这一批是合格的，但是因为检验正好检验到了不合格的才导致拒绝原假设的话，那么这个成本对于生产厂商来说是非常大的。

例3:  
我们再看一个例子，就是我们出门要不要带伞的问题。

正常来讲，原假设为天气为晴天，那么犯一类错误的情况就是晴天带伞出门，犯第二类错误的情况是下雨不带伞。

对于我们那一情况危害或者说坏处更大呢？因为毕竟下雨天是少数，如果你天天带伞出门的话固然是可以避免淋雨，但是你得天天带伞，要看你是不是方便，如果你方便那么一类错误对你来说影响不是很大；如果带伞不方便那么一类错误对你的影响就比较大了。

例4:  
这里并不是说不用避免犯第二类错误，第二类错误也是需要尽量避免的。只不过根据无罪推定原则和疑罪从无原则，我们应该控制的是尽可能别把没罪判为有罪，其次应该控制的才是尽可能减少让有罪的人继续逍遥法外。

而且我们对于一类、二类错误的控制上还要看具体情况，比如非典期间，我们为了尽量减少病原的传播，就不惜大量的精力来减少犯二来错误的概率，我们对所有人进行体温测量，只要发现发烧立即隔离，这里面我们很容易发现，这里面可定会有很多的不是携带病原体的人被认为是携带者，其实这里就是加大了犯一类错误的概率，而尽量减少二类错误。因为犯二类错误的成本太大，宁可错误的隔离3000，也不能放过一个携带者，因为放过一个就会造成非常严重的后果。

## 检验统计量和显著水平的方法：Z型/σ检验

上例中，争论的重点是100000个数的平均数而不是100个样本的数据，不过使用随机抽样的方式，可以认为100个样本代表了盒子，即100000的数据

为了验证上例中的假设**新税法提案不影响岁入**，即：新税法下的税收 - 旧税法下的税收 = 0  
则可以根据上例内容设置盒子模型：【盒中存在100000张卡片代表报税单，卡片表面写着次报税单在新旧税法下报税的差值】  
从盒中抽取100个卡片/样本，并计算这些样本/卡片上数据的合。如果样本之和为0，则说明假设验证成功。  

根据上述例中抽取的结果来看：抽得100张卡片得到的平均数为(-219),标准差为725  
则计算盒子模型中全部100次抽取的机会误差为 平方根(100) * 725 = 7250(基于平方根定律)  
故，100次单次抽取的平均误差则为72

根据抽取的概率直方图拟合正态曲线(抽取数量足够，可以拟合正态曲线)可知：假设中的新旧提案下的缴税差值，即：0，据当前抽取数据的距离为 (-219-0)/72 = -3 SD/SE  
根据正态表可知：-3SD位置的数据，占全部正态曲线的千分之1。故，可知：在抽样中，平均进行1000次抽样才可得到一个结果为0的样本

结论：  
备择假设无误，如果法案通过，则每个纳税单将平均少交219元

上例是一个***检验统计量***的标准案例：  
通过设立原假设，即认为新旧法案下缴税差异为0，并使用对应的备择假设（差异不为0）来设计盒子模型  
通过计算出的标准误差，计算出了**样本平均数的观察者和期望值之间相差了3个SE**

***检验统计量定义：检验统计量是用于假设检验计算的统计量。在原假设成立的情况下，这项统计量服从一个给定的概率分布，而这在另一种假设下则不然。从而若检验统计量的值落在上述分布的临界值之外，则可认为前述原假设未必正确。统计学中，用于检验假设量是否正确的量。常用的检验统计量有t统计量，Z统计量等***。

***上述使用的检验统计量的方法，被称之为Z/Z检验，是用来度量实际数据与假设之间的差值的  
检验统计量的公式为:(观察值-期望值)/SE，其中期望值的计算应使用盒子模型和原假设一同计算***。  

***Z值的量代表着原始分数和母体平均值之间的距离，是以标准差为单位计算。在原始分数低于平均值时Z则为负数，反之则为正数。Z表示观察值和期望值之间差多少个标准误差/SE  
因为抽取样本量够大，故可以使用正态曲线拟合数据(概率直方图)，而SE则可以用于求数据的概率，即P值  
期望值总是从原假设出发计算得到的。即：在原假设基础上。Z统一将统计量转化为了标准单位***

通俗解释z-value，即 z-score 是对某一原始分值进行转换，变成的一个标准分值，该标准分值可使得原来无法比较的数值变得可比。  

**Z检验的适用范围:  
正态分布  
总体标准差已知或者样本容量足够大(>30)**

当正态近似可以用于抽得平均数得概率直方图时，只要样本合理大就可以使用Z检验(针对小样本，则使用t-检验/t-test)

**Z检验的用途：  
检验一个样本平均数与一个己知的总体平均数的差异是否显著
检验来自两个的两组样本平均数的差异性，从而判断它们各自代表的总体的差异是否显著**

针对上例：-3SE可得出结论，要取得一个样本平均数小于期望值3倍**及其以上部分**的SE的概率为千分之一，这类机会被称为**观察到的显著水平**  
***观察得到的显著水平，是得到一个与观察值同样极端或更极端检验统计量的机会。即小于等于计算出的检验统计量的概率直方图的面积。  
机会是在原假设为真的基础上计算出来的。机会越小，则反对原假设的证据越强***

一个简单的例子，中国人小王身高 1.75 m，美国人 James 身高 1.85 m，日本人大郎身高1.75 m，排除国籍导致的差异，请问小王、James、大郎三个人谁更高？  
直接从数值上比，当然是 James 最高。但是这里要求排除国籍导致的差异，什么意思？就是说，日本人可能全国的人都相对矮一些（不严谨，仅做例子），那么日本的 1.7 m 可能相当于中国的 1.75 m 和美国的 1.85 m。所以不能直接比数字，而是要比每个人在各自国家国民身高背景下的一个“标准身高”。  
这里就可以引入 z-score了。

另一个简单的例子，小红英语考了 90 分，语文考了 60 分，请问小红英语和语文哪个考的好？  
同样的情况，如果直接比分数，当然是英语好。但是一种显然易见的可能情况是，两门课的难度不一样，也许语文更难，大家都不及格，只有小红及格了；而英语很简单大家都是100分，只有小红90分。这样看来，好像小红的语文要考的更好一些。这里我们用 z-score 可以直观的进行比较。

z-score 的计算定义如下：z =（x-μ）/σ这里的 x 为原始分值，z 为经过转换后的 z-score，μ 为总体样本空间的分值均值，σ 则为总体样本空间的标准差。

需要注意的是，上文所说的总体样本空间，即英文中的 population，指的是当前抽样样本

所在分布的空间内的所有样本。一般我们实际使用时，手头拿到的数据仅能代表抽样的部分样本，无法代表整个样本空间。所幸，我们可以使用当前抽样样本的均值和标准差来估计总体样本空间的情况。

在之前关于身高的例子中，我们可以将每个人的身高减去其祖国的平均身高，再除以对应国家的身高标准差，得到各自的身高 “标准分值”，然后再去比较。同样，语文成绩和英语成绩也是一样，各自减去全班或全校的平均分数，再除以对应的标准差，即可比较。如语文全班平均成绩 40 分，标准差为 10，英语全班成绩 98 分，标准差为 5 。那么小红的语文成绩 “标准分值” 就是 (60 – 40)/10 = 2 ，而英语成绩“标准分值”就是 (90-98)/5 = -1.6。这样一比，英语成绩是远低于语文成绩的，可见小红的语文还是学的相当好的。

在上面的例子中，转换后的 z-score 出现了负数，通过前面的公式定义，我们可以很容易的理解。如果原始分值低于样本集合中的平均分值，那么转换后的 z-score 则为负数，反正为正数。

需要注意的是，通过 z-score 转变后的分值，并没有被正态化。也就是说，原来是正态分布的，转为 z-score 之后仍为正太分布；原来不是正态分布的，转化为 z-score 之后并不会转换为正态分布。

最后，要防止 z-score 被误用。原始分值经过转变后的 z-score，是去除了之前数据所带有的观察信息的。  
对于拿 z-score 去做一些观察结果的判断，我们需要格外谨慎的。比如我们应该用 BMI 来衡量肥胖，而非某个阈值的 z-score，尤其在我们的抽样空间不够大、无法代表总体的情况下。

**Z检验得逻辑性：否定论证  
如果原假设为真，则得到一个荒谬的结论，因而必须拒绝原假设  
即：当观察值和期望值之间差多个SE时，原假设必须被拒绝**。

上例中，P值约为1/1000，即：假设原假设为真，调查人员为了验证结果，则需要1千的调查人员进行1次抽样，其中只有1个调查人员得到的检验统计量比当前得到的一样或更加极端。  
故观察到的显著水平越小，则越要拒绝原假设

***检验的P值并未给出原假设为真的机会，P值是在原假设的基础上计算而来的***  
无论抽取多少次，原假设要么为真，要么总是错的。

***上述假设检验被称之为单尾Z检验，此类检验一般用于大数据量下数据下检验统计量显著水平的方法。  
但是，往往当接收的数据不足的情况下，使用多个数据计算的标准误差并不准确。此时则可用使用t检验/t-test***

### 针对0-1盒子/定性盒子的假设检验：Z检验的相关应用

除了上例中使用Z检验对定量盒子中的数据进行检验，在使用定性/0-1盒子的情况下，也可用使用Z检验对数据进行检查

例：为了研究超感觉力/意念力(ESP)，科学家制作了一个机器进行实验，机器中存在一个随机发生器，将随机的抽取4个已有标识中的一个作为目标，但不指示出。  
参与者尝试使用意念力探知机器的选择后，通过选择4个标识对应的按钮做出选择。如果选择正确，即机器和参与者选择了同一个标识，则结果将被记录下来。

通过对15个自称存在意念力的受访者每人进行500次实验后，得到结果：7500次测试中(15 * 500)，存在2006次测试是正确的。根据常识可知，如果不使用意识力，则存在1/4的几率选到正确的结果。根据7500次抽取可知，应存在1875次正确的抽取。相对得到的2006次结果，其中多了131次(2006-1875)的正确抽取。问：此类抽取是否是因为机会误差的影响

使用Z检验时，首先假设产生的131个对象为机会误差所致。此时可以建立定性盒子模型【0，0，0，1】后，针对次盒进行7500次抽取；  
根据随机过程定律可知：此时单次抽取的期望值为1/4，则7500次抽取的期望值为1875  
根据当前盒子模型的情况可以算得：盒子中的SD为(1-0) * 平方根(0.25 * 0.75) = 0.43,故7500次抽取得到的结果为 平方根(7500) * 0.43 = 37，即7500次抽取下的平均误差为37

使用Z检验检验原假设：131/37 = 3.5 SE即拟合的正态曲线中2/1000的面积（根据正态表），对应P值为2%。，统计高度显著，即原假设可确认拒绝  
换句话说：此例中，相比期望值的1875个值，观察值的2006次正确抽取中，多出的131次正确抽取不是因为机会误差的影响。  
但是就上例来说，Z检验也只能得到这样的结论。这是因为，这多出的131个正确抽取仅能证实为不由机会误差引起，而无法证明其是因为意念力引起的。这些多出的正确抽取，可能是因为机器中的随机种子发生器中存在一定规律，或者系统随机抽取一个结果时，出现了一些声音/外形上的规律/暗示，引起了一定偏性

上述盒子模型使用的是0-1/定性盒子模型，且原假设针对的是7500次抽取后得到的结果进行。故**盒子模型中的SE并非单次抽取期望值的平均标准误差，而是7500次抽取的标准误差**  
故：***在进行数据假设检验之前，需要了解检验在观察什么：数据之和，平均数，计数或者百分位数。  
针对定量数据(求和/平均数的情况)，盒子模型中的标准差/SD一般是未知的(税法改革例子中的情况)，需要先通过现有数据(样本)拟合的求出盒子模型中的SD再进行计算。如果原假设给出了盒子的SD，则无需再进行计算；  
针对定性(计数/分类)相关的问题，需要使用0-1盒子模型，原假设常常指的是盒子中1所占的分数。可能直接通过原假设计算盒子中的SD，而不需要通过抽样结果将其估计出来***。

## t-检验/t-test

如同之前提到的，Z检验仅仅适用于大样本量的数据检验。针对小样本量的情况，因为仅有的几个样本无法完全拟合总体中的标准差/SD。  
故，针对小样本量的情况，可以使用t-检验/t-test对数据进行检查。

**为什么小样本用t检验？从抽样研究所得的样本均数特点来看，只要样本量>60，（无论总体是否服从正态分布）抽样研究的样本均数服从或者近似服从正态分布；  
而如果样本量较小（参考样本量<100）,抽样分布随着样本量的减小，与正态分布的差别越来越大。此时需要用小样本理论来解释样本均数的分布——而t分布就是小样本理论的代表。  
因此，小样本的检验需要用到t检验**。

**由于在实际工作中，往往σ(总体方差)是未知的，常用s（样本方差）作为σ的估计值，为了与Z变换区别，称为t变换，统计量T值的分布称为T分布**。

* 适用条件:

计量资料  
小样本（不是必须）  
独立性、正态性或近似正态、方差齐性（两小样本所对应的两总体方差相等,一般用F检验）  
当样本例数较小时，要求样本取自正态总体；（当样本数少于30时，需要检验满足正态分布，若数量较多，根据中心极限定律，样本会趋向正态分布）

* 用途

样本均数与群体均数的比较看差异是否显著；  
两样本均数的比较看差异是否显著。

具体来讲，T检验分为单样本T检验、配对样本T检验和双独立样本T检验  
单样本T检验：检测样本均值与总体均值之间的差异  
配对样本T检验：检验样本某个状况前后的均值有无差异  
双独立样本T检验：检测两组样本均值有无差异（需保证两组小样本的方差齐性）  

例:为了正确调试分光光度器，需要在使用次仪器之前对设备进行调试。具体的方法，就是使用仪器度量一个事先准备好的，已知度数的量标气体。此气体的度数应为70，故当仪器度数显示为70时，则仪器相对正常，否则需要重新调整设备。  
仪器的灵敏度为100PPM/100级，而一般情况下误差为10级。

假定，误差独立且遵循正态分布，某天在使用设备前，对量标气体进行了5次测试，结果为：78，83，68，72，88，问：  
通过这5个度数，可否确认设备存在未完全调整而产生的偏性(需要继续调整)，或者仅仅是因为机会误差的原因造成的结果。

根据题目可知，这次原假设应是设备收机会误差影响产生误差，即设备没有偏性。因为题目中缺少数据，且测试本身仅针对机会误差。故应该使用高斯模型检查仪器得机会误差。  
根据此模型，**每次测量一定数据时，等同于随机从盒中取出一个误差(机会误差) + 设备真值 + 偏性**。  
根据原假设可知：假设中不存在偏性，故设备测量值 = 机会误差 + 设备真值，即测量值 = 70 + 机会误差(平均期望值为70)

如果使用Z检测，则可以计算出5次测试得平均值和标准差，最后计算出标准误差/SE，再通过(观察值(5次测试平均数) - 期望值(70))/SE计算出结果  
但是因为：***测量值得SD仅仅为误差盒子中SD得一个估计，且测量数据量很小，针对SD得估计将不会精准***，即：**存在SD值测量精度低，且概率分布直方图未拟合正态曲线的问题**  

**针对测量样本量小，SD估计不准的问题**：  
如果存在大量得测量数据，可以通过测量数据产生得SD拟合误差盒子的SD。而针对抽取数量较少的情况，则可以使用较多一点的量来估计误差盒子，即在测量值SD的基础上乘上一个增量因子，这被称之为**SD+**：  
***SD+ = 平方根(测量值的个数/(测量值的个数-1)) * 测量值的SD***

**针对使用Z检测(计算P值)得到的数据不再符合正态曲线的问题**:  
一般情况下，得到标准化后的原假设和备择假设之间的差之后，如果抽取数量充足大，则可以使用正态曲线拟合数据。但是因为抽取量小，则在使用t-检验时不能直接拟合正态曲线。  
针对此问题，则可以拟合t-分布曲线/学生分布曲线，并根据已经计算完毕的t值表，计算面积/机会  
**t-分布曲线和正态分布曲线相似，只是在平均数点分布的数据并不像正态分布那么集中。  
如之前提到的，随着抽取的数据量不断提升，则得到的概率分布直方图将进一步贴近正态分布。换句话说，随着样本量的变化，t-分布的曲线也在一同变化，每个样本量将对应一个不同的t-分布曲线。  
这当中的样本量，就被称之为自由度。狭义的定义下，自由度 = 测定的个数 - 1;  
和正态表不同的，t-分布表中，不同自由度下的标准差/标准误差拟合的面积各不相同***。

针对上例中的数据，因仅仅涉及到抽取5次误差盒中的数据，故应该使用t检测验证原假设：  
计算中，误差盒子的SD可以根据抽取的5个例子进行拟合：  
抽取的5个样本的平均值为77.8，而标准差为:7.22  
因为使用的样本较小，需要使用增强SD，即SD+：平方根(5/(5-1)) * 7.22 = 8.07  
则标准误差应为 平方根(5) * 8.07 = 18.06;而平均数的SE(SD)则为18.06/5=3.61

故，最终使用Z检测得到的结果为 (77.8-70)/3.61 = 2.2 SE  
最后使用t分布表进行查看，结果约等于5%左右的面积，即：原假设为真的概率为5%，基本可以推翻原假设；即：抽样数据中存在机会误差之外的值，即偏性。

上例可以抽象为：  
使用随机有放回的方法从一个基本符合正态曲线，均值为0且SD未知的盒子中，抽取了少量票。  
每次抽取中，结果均将加上一个未知常数；原假设认为，未知常数为给定常数C，而备择假设认为，未知常数大于C；  
其中盒子的SD可以使用SD+的方式估算出，并算出SE。则检验统计量为：(抽取数据平均值-C)/SE  
观察得到的显著水平可由t-分布曲线，而不是正态曲线得到  
其中t-分布曲线的自由度使用:抽取数-1进行计算

### t-检测的使用范围

t-分布/学生曲线应应用在：  
1.数据为随机有放回的从盒子模型中所抽得的数  
2.盒子模型中的SD未知  
3.观察个数相对较小，且盒子的SD不能通过已知数据精确的估算出  
4.盒子的值未知，但是分布直方图和正态曲线不能相差太远

针对大量测量值(大于25次测量，最好大于120次测量)，通常可以拟合正态曲线。  
如果盒子的SD已知，且盒子中数据分布符合正态曲线，则可以使用正态曲线进行拟合，无论样本量为多少。

# 双因子/因素假设检验：两个因素差的平均数

之前提到的t-检验和Z检验均为单因素检验，即：**针对一个单一事件进行的假设验证**

而实际工作当中，往往会出现需要比较两个**独立**事件的情况，例如：一段时间内的两次考试的成绩。  
这种时候，就必须使用双因素假设检验进行

## 两个事件的差的期望值与标准误差

**针对两个独立事件，求其期望值的差的情况，两个独立事件的期望值可以相减，而两个独立事件的标准误差可以适用于平方根法则，即为：平方根(SE1^2 + SE2^2)  
其中SE1和SE2分别为事件1和事件2的标准误差**

注：此方法仅能应用于独立事件当中

例: 存在盒A，盒B两个盒子模型，2个盒内情况未知。其中盒A中平均值为110，且SD为60。而盒B中平均值为90，SD为40.  
针对两个盒子进行了不同次数的随机有放回的抽取，盒A进行了400次，而盒B中进行了100次。求：两个样本平均数之间的差的期望值和标准误差

首先，根据盒子模型可知：  
盒A中盒子的期望值为平均数110，盒A 400次抽取的标准误差为 平方根(400) * 60 = 1200，故盒A平均值的标准误差为：1200/400 = 3  
盒B中，盒子的期望值为平均数的90，盒B 100次抽取的平均误差为 平方根(100) * 40 = 400故盒B平均值的标准误差为：400/100 = 4

题目中的目的是：求两个事件平均数的差的期望值，及其标准误差，且根据题目可知：两个盒子均使用使用有放回的方式进行的随机抽取，即两个盒子/事件均为完全独立事件；  
故，两个事件之间差的期望值为两个事件的平均数的差，即：110-90 = 20。针对平均误差，则可以使用上述方法计算独立事件的标准误差：平方根(3^2 + 4^2) = 平方根(25) = 5  
故，两个事件期望值差的期望值为 20 +-5

例1：从盒C【1，2】中随机放回的抽取100此，再从盒D【3，4】中随机放回的抽取100次，问：从盒C中抽取到1的次数和从盒D中抽取到4的次数的差的期望值于标准误差。

根据题目内容可知：两个抽取事件之间互相独立且，两个抽取事件本身抽取也是独立的。故，可以使用平方根法则。  
另，根据题目中要求从盒中抽取指定对象，即可以将原盒转化为0-1/定性盒子进行抽取。即：从盒C【0，1】，盒D【0，1】分别抽取100次，求差的期望值及平均误差

针对两个相同成分的盒子，平均数/期望值是相同的：盒子平均数为(0+1)/2 = 0.5，故100次抽取后的期望值为100 * 0.5 = 50  
两个盒子的SD应为：(1-0) * 平方根(1/2 * 1/2) = 1/2，故两个盒子100次抽取下的标准误差均为 平方根(100) * 1/2 = 5  
根据上述定理计算：两个盒子的差的期望值为：50-50 = 0；而标准误差的期望值为 平方根(5^2 + 5^2) = 7  
故：上例中，两个盒子差的期望值为 0 +-7

例2：随机有放回的从盒【1，2，3，4，5】中抽取100次，问：抽得1的期望值和抽得的期望值的差是否可以使用平方根法则求得。

答无法使用上述方法求得：因为抽取1和抽取5的之前并不互相独立(例如：抽得1的前置条件/机会为抽得结果不为5)，故平方根法则不适用

## 比较两个事件的平均数：双样本/因子Z检测

***双样本的Z检测中，检验统计量应由一下项目共同计算得出：  
1.两个样本的容量  
2.两个样本的平均数  
3.两个样本的SD  
即:(观测值-期望值)/平方根(样本1SE^2+样本2SE^2)
此检验假设这是两个独立的简单随机样本***

例：针对一个学校，在1973年和1982年针对数学科目的考试进行了两次研究，73年的考试中，得分的平均数为55.0，标准差为17.2；而82年的考试中的得分的平均数为51.8，标准差为16.9；问：形成此问题的原因是因为及机会变异还是因为实际成绩的下降。

不同于之前的检验统计量方法(单因子/样本Z检测或t检测)，检验统计量中，作为分母的SE需要考虑到两个样本，而这两个样本均会受到机会误差的影响；  
因此上例中，故：在进行检测统计量的时候，可以参照平方根法则进行

为了对原假设(形成次问题的是机会变异，即：两个盒子的平均数相同，即两个样本的平均数的差的期望值为0)和备择假设(第二次测试结果的平均值缺少低于第一次测试结果的平均值)进行验证，需要设置一个盒子模型。为了简化模型，则假设两次测试均针对学校中17岁学生中进行1000次简单随机抽取的样本进行  
在基于上述假设，则应该建立2个盒子模型：1973年盒子模型和1982年盒子模型，每个盒子中卡片代表一个17岁的学生，而卡片上标识学生的考试成绩；盒中卡片数未知，但是抽取数是已知的：1000次

两个样本的检验统计量值-Z值等同于(观察值-期望值)/SE；其中：观察值为(51.8-55.0)=-3.2，而期望值为0；则分子部分为-3.2  
针对检验统计量使用的分母部分，即模型的SE，因为例中数据实际服从平方根法则（两个样本抽样时互相独立，且使用有放回随机抽取），故此例中，差的SE可以使用平方根法则，从两个盒子的标准误差中求出。

根据题目中的信息：盒A中1000次抽取的SE为：平方根(1000) * 17.2 = 544，则平均数的SE为 544/1000=0.544;  
而盒B中1000次抽取的SE为：平方根(1000) * 16.9 = 534，则平均数的SE为 534/1000=0.534;  
故，两个盒子差的标准误差为 平方根(0.544^2+0.534^2)=0.76  

根据Z检测求检验统计量，结果为：-3.2/0.76 = -4.2 SE。即：82年和73年之间的差低于期望值-4.2个SE。  
因为例中样本量相当大，故可以使用Z检测的方式检测  
故原假设(两个盒子平均数相同)将被拒绝，而保留备择假设。即：平均数上的差是客观存在的

双样本Z检测也可以用于检测两个百分数盒的差:

例3：一个规模较大的大学，分别进行了1次针对男学生和女学生的简单随机抽样。样本容量分别为200，300。抽样结果为：107个样本男生经常使用PC(53.5%)，而女生端为132(44.0%)。问：出现和性别相关的差异的原因，是机会误差还是确有不同。

此例中，原假设为：出现差异的原因是因为机会误差，即：男/女使用PC的百分比相同，男女百分比差异为0；而备择假设则认为：男女百分比存在差异，差不为0。  
针对假设，可以将整个学校的男/女学生**分别**作为盒子模型的建模对象，针对男学生使用PC的情况，可以将全部男生作为卡片放置到盒中，其中使用PC的学生的卡片上标为1，其余为0；女生同理。
故，测试就类似于从男性盒子中抽取200次，从女性盒子重抽取300次。

因为无论男/女盒子中，均由0-1组成，故：可以使用SD计算法，即：  
男盒：(1-0) * 平方根(0.535 * 0.465) = 0.499；200次抽取下盒子的SE为:平方根(200) * 0.499=7，SE所占的百分比为7/200=3.5%  
女盒：(1-0) * 平方根(0.440 * 0.560) = 0.496；300次抽取下盒子的SE为:平方根(300) * 0.496=9，SE所占的百分比为9/300=2.9%  
故，两个盒子的差的SE为 平方根(3.5%^2 + 2.9%^2)=4.5%(SE)  

针对上述条件：备择假设为53.5%-44.0%=9.5%，而原假设认为差为0，SE为4.5，则使用Z检测下的检验统计量为：  
(9.5%-0)/4.5% = 2.1，根据正态曲线可知：可能性<5%，故原假设将被拒绝，即:男女使用PC的百分比存在差异

## 实验中的双样本Z检测比较

在实验中，同样也可以使用双样本K检测的方式去验证实验中提出的假设

注意：**观察**和**实验**是不同的，在观察中，分组由对象自主进行；而实验中，分组则由第三方统筹进行。  
故，在使用Z检验进行数据统计时，情况将和一般的盒子模型有所不同：  
**通过条件筛选出的对象，将被认为分配给实验组或者对照组，这时实验组和对照组的对象实际并不互相独立，即：如果被选为实验组则不会被选为对照组。但是这种情况下，实际依然可以适用K检测**

***有一盒票，票上针对实验组和对照组标定了不同的数据，而两个数据仅有一个能被观察到（当票被分到指定组时）。  
当随机不放回的从中选取一些票以观察实验的反应，将留下的票作为第二样本对照组进行观察；此时，两个组间平均数的标准误差的计算可以保守估计为：  
1.随机放回基础上计算的两个组的各自的标准误差/SE  
2.像样本是相互独立那样将两个标准误差一同使用平方根法则计算差的标准误差***

例：针对为维生素C是否可以防治感冒的实验。实验共有200名实验对象，将随机的将实验对象*等分*为实验组(提供维生素C)和对照组(提供等量安慰剂)；  
实验结果可知：实验组中，得感冒的次数的平均值为2.3次，标准差为3.1次；而对照组中，得感冒得次数得平均数为2.6次，而标准差为2.9次。问：维生素C是否可以防治感冒。即：使用维生素C的组的平均值是否真正低于对照组，而不是因为机会变量引起。

上述例题中，原假设应定为：维生素C对感冒无效，而实验组和对照组的平均值应相同。而备择假设则为:两组之间的平均数不同。  
实验组的标准误差应为: 平方根(100) * 3.1 = 31，而抽得平均数得标准误差为 31/100 = 0.31；  
对照组得标准误差应为:平方根(100) * 2.6 = 26，而抽得平均数得标准误差为 23/100 = 0.26；  
故，根据上述结果可知：检验统计量得分子为 (2.3-2.6) - 0(原假设)  = -0.3；而分母SE则应为两个事件的SE，根据平方根法则应为: 平方根(0.31^2+0.26^2) = 0.42。  
故，此时的检验统计量计算应为: -0.3/0.42 = -0.7；原假设为真的机会较高；原因可能是存在大量容易患感冒的样本对象被分至对照组。

使用检验统计量之前，均会要求样本是**独立且随机有放回的**从盒子中取出。上例中的实际情况并不遵循这一要求。因为上例中，实验组和对照组实质上是通过随机无放回的被抽取的。因此，抽取是不放回的，而样本间实际上是相依的(针对一个易患感冒的对象，若被选为实验组则不会被选为对照组，而这会影响两个平均数)。但是，即便出现了此问题，依旧可以直接计算出SE，这和盒子模型的选取有关。  
盒子模型中的两个组，使用的是随机分配的形式构成，每个被分组的样本可以被视盒子中的票，而票上实质存在两个数，一个表示针对实验组，即针对维生素C的反应，而另外一个表示针对对照组的安慰剂的反应。  
这两个数字，只有一个可以观察到(因为实验组和对照组二者取其一)

从这些票中，随机不放回的抽取一些票，观察其对应实验组的数据，则这些票应被标识为实验组；之后随机不放回的抽取一些票，如果观察的是安慰剂相关的反应，则应被记为对照组。  
上例中，全部的200个样本，不是被抽取为实验组就是被抽取为对照组；故，第二个样本就可以被视为第一个样本抽取后盒子中剩余的票。

题中原假设认为：两种处理的平均反应相同，为了验证原假设，需要比较两组的平均值：实验组平均值-对照组平均值及其对应为多少个SE单位。可以存在的问题：  
**1.抽取是不放回的，但是两个SE应基于互相独立的样本进行计算，即又放回随机抽取  
2.两个组的平均数是相依的，但是计算SE时并未考虑此事项**

针对此问题:  
**若，抽取次数针对盒子中的票数是小的，则放回和无放回之前不存在差别，且平均数之间的相依性相对较小**  
这将相当于存在两个不同的盒子：**实验组盒子**与**对照组盒子**

而针对上例，则因为：**抽取次数相对较大，则错误本身是实质性的。例如上例中，半数对象均被分置实验组中。此时的修正银子将明显小于1。  
但是，因为SE实际因为不放回抽取的原因被计算偏大，而又因为平均数相依的原因被计算偏小，二者将互相抵消。  
即:当数据源于随机化实验时，无论抽取次数是大是小，则结果依据适用于检验统计量**。

### 定性实验中的双样本K检测

例：*合理性*一词，在经济学上被认为是依据某些正规的规则形成的，决策者应针对事实做出反应而不是针对提出事实的方式做出反应；而心理学则认为，合理性和提出事实的方式存在强相关。  
故，设计了实验检查同一信息以不同方式提出时，决策者是否会收到信息提供方式的影响

实验中，针对167名医生，信息以两种方式提出：  
形式A:每100个做外科手术的人中，10人将在手术中死亡，32人将在1年内死亡，66人将在5年内死亡；而每100名接收放疗的患者中，无人在治疗过程中死亡，1年内将有23人死亡，5年内将有78人死亡。  
形式B:每100个做外科手术的人中，90人将在手术中生还，68人将存活1年及以上，34人将存活5年或以上；而每100名接收放疗的患者中，所有人将在治疗中存货，1年内将有77人将存活1年及以上，22人将存活5年或以上  
上述两个形式，表达的数据是相同的；实验中，随机选择80人进行形式A的描述，另外87人则给予形式B的描述(随机无放回式抽取，以防两个形式信息造成的混淆)。  
这当中，接收形式A信息的80个样本中，其中40人选择手术(41/80)；而接受形式B描述的87个样本中，73人选择手术(73/87)。问：产生上述差异的原因，是否是因为提供信息形式不同造成的.  

此例中，原假设为：表述信息形式的不同不会影响对合理性的判断，即：两个形式数据下的平均数相同；而备择假设则为：表述信息形式不同会影响对合理性的判断。  
此例中，因为进行的是定性分析，则数据均在0-1盒子中。盒子中存在代表着167个样本对象的卡片，卡片上存在两个0/1组成的数据结果，表明样本对象对形式A和形式B的结果，而对此卡片结果的观察和分组保持一致。  
实验时，首先随机抽取80个卡片并观察其形式A下的结果，再对剩余的67个卡片观察其形式B下的结果。  
因为图中均为0-1盒子，故盒中SD为 (1-0) * 平方根(1/2 * 1/2) = 1/2

根据上述题目可推算出: 形式A组中的SE为 平方根(80) * 1/2 = 4.5；而形式A中平均值的标准误差/SE为 4.5/80 = 5.6%  
形式B组中SE为 平方根(80) * 1/2 = 4.6；而形式B中平均值的标准误差/SE为 4.6/87 = 3.9%  

此例使用检验统计量时，根据题目可知：原假设假定两个形式的平均值的差为0，而实际/备择假设结果则为(41/80-73/83) = 34%，而分母可使用平方根法则进行计算: 平方根(5.6%^2 + 3.9%^2) = 6.8%  
故，此时检验统计量计算为:(34%-0)/6.8%=5 SE;即原假设几乎完全不成立

# 卡方检验(x^2检验)

针对**模型对实际情况拟合的程度，可以使用卡方检验进行**

***卡方检验：卡方检验，是用途非常广的一种假设检验方法，它在分类资料统计推断中的应用，包括两个率或两个构成比比较的卡方检验（验证数据是基于特定机会模型产生这一假设）；多个率或多个构成比比较的卡方检验以及分类资料的相关分析等。  
卡方检验可以检验男性或者女性对线上买生鲜食品有没有区别；  
不同城市级别的消费者对买SUV车有没有什么区别***  

***卡方检验检验的是统计样本的实际观测值与理论推断值之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，如果卡方值越大，二者偏差程度越大；反之，二者偏差越小；若两个值完全相等时，卡方值就为0，表明理论值完全符合  
注意：卡方检验针对分类变量***。

***若关系到盒子的百分率组成时，使用方差分析；若仅设计盒子的平均数，则使用Z检测；  
方差检测回答数据是否和从一个盒子内容已知的盒子中随机抽取的结果一致；  
Z检测回答数据是否从一只平均数给定的盒子里随机抽取的数据一致。  
例如：从【1，2，3，4，5，6】中进行又放回的抽取，盒中不同类票的分布百分数未知，  
为检验每个票所占的比例是否为(16 * 2/3)%这个假设，则需要使用卡方分析(仅有一种可能)；  
若为检验盒子的平均数是否为3.5，则需使用Z检验(存在多种可能)***

***卡方检验最常见用于考察无序分类变量个水平在两组(多组)间 是否分布一致，但除此之外，还有以下用途：
　　1.检验某分类变量各类出现概率是否和指定概率相同;
　　2.检验某两个分类变量是不是相互独立;
　　3.检验某连续变量分布和理论分布是不是一致;
　　4.检验两种方法结果是不是一样;
　　5.检验控制某种因素作用后，另外两个分类变量是否相互独立***;

***卡方检查的检验统计量公式的结果被称为卡方值：每个分类变脸的，以期望频数表示观察频数和期望频数差的平方的和，即:  
Σ(观察频数(观察值) - 期望频数(期望值))^2 / 期望频数  
其中全部项目观察频数和期望频数只差的和为0***

***而P值则可以使用卡方分布曲线对应的卡方表得出  
和t-检验相似的，卡方检验也存在一条根据不同自由度进行定义的卡方分布曲线；但和t分布/学生分布曲线不同的是，卡方分布曲线实际是一条右偏长尾的正态分布曲线，当自由度增大时，曲线开始向右偏移。故：  
对应卡方检验，P值近似的等于卡方值统计量观察值右测适当自由度下的卡方曲线下面的面积，且当模型是完全指定时(没有参数需要估计)，盒子的自由度=盒子中的项数-1  
之所以P值得近似值是/只是卡方曲线右侧长尾部分得面积，这是因为卡方检测量最小为0，一般不会得到比0还小得值，故大部分情况下得到得数据均在曲线平均值右侧***

***当在完全指定的情况下：即模型中没有参数需要由估计得出，模型已经指定了盒子中的数据时，盒子的自由度=盒子中的项数-1  
一个式子中独立变量的个数称为这个式子的“自由度”,确定一个式子自由度的方法是：若式子包含有n个独立的随机变量,和由它们所构成的k个样本统计量,则这个表达式的自由度为n-k.比如中包含ξ1,ξ2,…,ξn这n个独立的随机变量,同时还有它们的平均数ξ这一统计量,因此自由度为n-1.  
证明：设k1ξ1+k2ξ2+…+knξn=0.这是一个含有n个相对独立变量的式子.则其中任意一个ξi=-1/ki[k1ξ1+k2ξ2+…+k(i-1)ξ(i-1)+k(i+1)ξ(i+1)+…+knξn],（1≤i≤n）.显然ξi由另外n-1个变量决定,所以自由度为n-1***

在卡方检测中，一般使用**期望频数**代替其余检测统计量中的**期望值**，期望频数指的期望时间的发生次数；  
以投骰子为例，如果认为一个骰子是公平的，则在60次投骰子的过程中，骰子每面出现的次数应均为10次。

针对仅存在两个类的0-1盒中，可以使用Z检验进行假设检验。但是如果一次事件中存在多个类的问题，就无法使用Z检验，例如:  
检查骰子是否公平，即：是否每一面均有1/6的机会被投中；此时，每用骰子投1此将存在6种完全独立的情况：即分别出现1，2，3，4，5，6点，6种情况  
如果希望证明骰子是否公平，则可以进行多次实验，最后使用卡方检验证明其是否符合**期望值/期望频数**

根据上例进行60次投骰子的结果（对原数据分类计数后）如下：  
原数据为60个投骰子得到的结果值(60个1-6之间的实数)，经过梳理后结果如下

|呈现值|观察频数|期望频数|
|:---|:---|:---|
|1|4|10|
|2|6|10|
|3|17|10|
|4|16|10|
|5|8|10|
|6|9|10|
|和|60|60|

通过上表可见，骰子结果为3时，偏离期望值的数量较高。  
因为每次投骰子均为独立事件，则以投得结果为3，建立0-1盒子，盒子结果为【0，0，0，0，0，1】  
而盒子得SD为(1-0) * 平方根(1/6 * 5/6) = 2.9，使用Z检验可知检验统计量结果为: (17-10)/2.9=2.4 SE  

实际上统计学家不会只取上表中的一行，得出结论，因为：  
1.除了结果为3得数字以外，结果为4的数据一样大幅偏离了期望值  
2.对于表里的许多行，有高概率表示它们中至少有一行存在可疑：即使模型是正确的。(类似俄罗斯赌轮，如果持续进行事件，则一定会输)  

故，为了使用全部对事件进行检测，则需要使用**卡方检测:将所有实际频数和期望频数的差，作为一个整体去和期望频数进行度量**  
***当观察频数和期望频数的偏差较大时，和中的对应项就较大；当二者接近时，和中的对应项就会减小；当二者完全相同时，和的结果为0  
卡方值越大，则观察频数偏离期望频数越大，反之则意味着观察频数接近期望频数。换言之，卡方值给出了观察频数和期望频数之间距离的一种度量***。

使用上述计算方差值得方法，得到的结果为:  
(4-10)^2/10+(6-10)^2/10+(17-10)^2/10+(16-10)^2/10+(8-10)^2/10+(9-10)^2/10=142/10 = 14.2

不过，从另一个角度说，一枚公正得骰子也有可能因为**机会误差**的原因，得到14.2的方差值。  
为了解释并验证一枚公正的骰子投掷60次得到方差值为14.2**或更大的机会**的概率(如果14.2已经很大了，则大于14.2是可以推翻假设的更好证据)，即P值。  
计算卡方分析中的P值，可以引入**方差分布曲线**对事件的概率分布直方图进行拟合。  

使用卡方曲线表可知：5个自由地下，14.2及以上的概率约为不到1%，故原假设(骰子是公正的)证明为伪

例2：使用卡方检验检测幸运轮盘(大转盘电视游戏的一种)，参赛者转动一个轮盘，轮盘上标注有1-100的号码，彩球落入哪个号码，则参与者将获得对应的奖金  
为了保证轮盘周正，轮盘被转动了800次，并且记录了落入每个号码的次数，并使用方差分析进行分析。最终发现：方差值为119，自由度为100-1=99，而对应的P值为8%，基本合格

针对测试中出现的69号落入的机会较多的情况进行了排查，发现69号后面存在金属配重附着物。  
去掉附着物后，结果恢复(需要定期上油)

## 卡方检验的结构与步骤

卡方检验由6个部分/步骤组成：

1. 基本数据：由一定数量的观察值组成，通常记作N。对应骰子例子，N = 60，即60次投骰子的结果；而针对幸运轮盘例子，则N = 800，即800次转动轮盘得到的结果。  
2. 机会模型：当前仅仅使用了一种机会模型，即随机有放回形式的盒子模型，而根据模型，数据就如同抽得数。对于骰子例子，盒子应为【1，2，3，4，5，6】；而对于轮盘例子，盒子中则为标有1-100的卡牌。  
3. 频数表：频数表由呈现值(盒子模型中卡牌值)，观察频数和期望频数组成。观察频数由基本数据聚合计数获得；而期望频数由N和机会模型获得。  
4. 卡方统计量：按照卡方统计量计算公式进行计算。针对骰子例子，卡方统计量为14.2；而针对轮盘例子，卡方统计量为119。  
5. 自由度：当盒子内容给定时，自由度等于盒子/卡方值项数-1；针对骰子例子，自由度为6-1=5；而针对赌轮例子，自由度为100-1=99；针对盒子中卡方值项目数不明的情况，或对于存在两个检验维度的情况(例如进行独立性检验，比如下例中的男/女管用手独立性检验)，则频数表应计为MxN的情况，其中M表示盒子中的项数(惯用手情况)，而N则表示检验维度(男/女)。此时，盒子的自由度应等于(M-1) * (N-1)  
6. 观察显著水平/计算P值：根据计算出的卡方统计量和自由度，通过比对适当卡方曲线下，卡方统计量值右侧的面积的近似值，计算显著水平。可以使用卡方表；针对骰子例子，显著量P值为1.4%；而针对轮盘例子，显著量则为8%。

对应得专门术语：  
1. 卡方检验：包含上述1-6得所有步骤  
2. 卡方检验统计量：根据卡方检验统计量公式计算出的结果  
3. 卡方曲线：由不同自由度曲线组成的卡方曲线  
4. 卡方表：通过不同自由度下。卡方分布曲线对应的面积计算求得，可以用于计算P值

**无论盒子中的内容是什么，只要N足够大，同样的卡方曲线和卡方曲线表，可以用来近似地求P值,  
对于其他类型的检验统计量，每个盒子则需要一条其他的/新的曲线。**

## 卡方检测的应用：以费舍尔检测孟德尔豌豆测试为例

针对孟德尔的豌豆实验，费舍尔使用卡方检验对其结果进行了验证，针对得到的结果，确认了孟德尔的测试中存在*某种偏性*，即实验结果过于完美，并未体现出机会误差的存在。

***如果需要的情况下，可以将多个独立事件的卡方检验统计量，及其自由度合并；作为一个大的事件，进行卡方检验***

对于孟德尔的每次实验，费舍尔均计算量其卡方检验统计量。因为孟德尔的每次实验均为相互独立的，故费舍尔**将不同实验的卡方检测统计量，及其对应的自由度互相相加，以证明实验的机会**。  
例如：对孟德尔的实验A进行卡方检验，得到卡方检验统计量5.8，自由度为8；而针对另外一个孟德尔进行的独立实验B进行卡方检验，其检验统计量为3.1，自由度为2。  
如果需要将二者合并为一个实验，进行卡方检验的验证，则可以将两个卡方检验统计量和自由度分别相加，形成一个新事件的卡方检验统计量，和自由度。  
如上例，新事件的卡方检验统计量为5.8+3.1=8.9；新事件的自由度为8+2=10；

而费舍尔针对孟德尔进行的全部豌豆实验得到的卡方检验统计量和自由度进行了合并，新事件下的卡方检验统计量为：42，而自由度为81。根据卡方分布曲线拟合可知，符合此要求的卡方曲线下的面积在平均数*左侧*，占总曲线面积的万分之4；即可证明，观察频数和期望频数之间一致性极好，自然条件下得到相同结构的概率为万分之4。

此处，费舍尔并非真正的检验孟德尔的机会模型，而是在检验两个假设(将模型看成真的，确定数据是是否捏造，使得观察频数等于期望频数，此时P值在卡方曲线左侧对应面积处)：  
原假设：孟德尔的实验数据是真实收集的  
备择假设：孟德尔的数据是捏造的，目的是使得实验结果的频数更接近于期望频数

这是为什么卡方检验统计量会在卡方曲线左侧的原因：  
小的卡方检验统计量，意味着观察频数比起机会变异所能允许的更接近于期望频数，并赞成备择假设；  
且由于小的卡方检验统计量实际会拒绝原假设，则P值将计算在曲线左侧。

## 利用卡方检验进行事件的独立性检验

例：惯用手和性别之间的关系，确切的说：25-34年龄段内，男性惯用手(左手，右手，双手)的分布和女性惯用手的分布是否相同。  
当然，针对此问题，如果可以得到全部样本的使用数据(例如全国范围内男性和女性惯用手的信息)，数据实际可用通过描述统计的方式计算求得(直接计算男/女性在惯用手为左/右/双手上的分布)。  
但是实际情况下，因主/客观原因，导致无法进行全国规模的普查。故，必须使用抽样结果数据进行代替。

针对全国25-34岁青年进行了2237次抽样，整理后的抽样结果表如下表所示：  

|项目|男性|女性|
|:---|:---|:---|
|惯用右手|934|1070|
|惯用左手|113|92|
|惯用双手|20|8|

就上图而言，数据中88%的男性善用右手，而女性中善用右手的比例为91%。经过上图可快速得出粗糙的结论：从数据表现上来说，女性比男性可能更习惯使用右手。  
作为一种解释，习惯用右手的人大脑的左半球更有优势。所以兴许是因为女人比男人更有理性造成。  
另一种解释：社会更加赞同使用使用右手，而使用左手被认为是怪异的。女性是否因为在更大的压力下，遵循用手习惯的社会规范？  
亦或者：产生此差异的原因，仅仅因为机会变异/机会误差(在机会变异/机会误差的影响下。即便总体中，使用手的习惯的分布相同，抽样中的结果也会存在不同；因为抽取时运气不佳，产生分布上的变化)  

为了男/女间惯用手分布不同的原因(差异实际存在/因为机会变异产生差异)，就需要使用卡方检验进行验证(如果不担心机会变异，则无需进行显著性测试)。

因为抽样过程实际并不遵循简单随机抽样，实质上数据不能直接使用卡方检验(抽样中的SE依赖于抽样方式的设计)。故，将题目简化为从一个整体中随机无放回的抽取2237个简单随机样本。  
故，盒子模型可用建立如下：将总体(25-34岁的美国人)每人对应一张卡片放入盒中，卡片上标明的字段根据实际情况从以下6个情况中选择：  
【
惯用手为右手的男人，惯用手为右手的女人，
惯用手为左手的男人，惯用手为左手的女人，
惯用手为双手的男人，惯用手为双手的女人】

实际的抽样过程，则为无放回的从盒中抽取2237个卡片，并统计出现上述6中情况的实际频数。因为盒子中，6个卡片标明情况的分布是未知的，所以模型中实际上存在6个参数/项目。  
居于问题和盒子的实际情况，可以设立原假设和备择假设：原假设认为：男性和女性的惯用手，在实际的3个用手习惯上，应**均不存在差异**，即：**男/女在对应的三个习惯上，总体分布的百分比应是相同的**(总体中，男性善用右手的分布百分比等同于女性中善用右手的百分比，左手和双手类似)；  
而备择假设实际相依于原假设：男/女在惯用手的上，实际存在差异；即：在三个惯用手的分布上，男/女用手的习惯不同于他们在百分比中的分布。

基于上述假设，期望频数的计算逻辑如下：  
抽样结果中，使用右手的人(不分男女)针对抽样数据总体的比例，和使用右手的男性/女性分别在对应性别分组样本总体中的比例相同(原假设认为，对应惯用手项目中，男性和女性针对占总体的比例相同)，使用左手/双手的比例依旧相同  
经过此逻辑，不同惯用手在男/女分组中的期望频率数据计算如下：  

|项目|男性|女性|总数|总数占比|
|:---|:---|:---|:---|:---|
|惯用右手|934|1070|2004|89.6%|
|惯用左手|113|92|205|9.2%|
|惯用双手|20|8|28|1.3%|
|总数|1067|1170|2237|-|

根据上表中的，每个惯用手在百分数中的占比，可以推断出男性/女性在对应惯用手数据上的占比。  
推断后的惯用手占比数据频数表如下:  

|项目|男性观察频数|女性观察频数|男性期望频数|女性期望频数|
|:---|:---|:---|:---|:---|
|惯用右手|934|1070|956|1048|
|惯用左手|113|92|98|107|
|惯用双手|20|8|13|15|

针对上述频数表，可以使用卡方检验统计量公式进行计算：  
(934-956)^2/956+(1070-1048)^2/1048+(113-98)^2/98+(92-107)^2/107+(20-13)^2/13+(8-15)^2/15 = 12  

针对自由度，因为数据中盒子中具体卡片分别/项目情况未知，故无法使用卡方项目-1的方法计算自由度  
如之前提到的，***针对对N个维度进行M个项目的检测的情况，卡方检测的自由度可以使用(M-1)x(N-1)求得***  
此例中，针对了男/女两个维度进行【惯用右手，惯用左手，惯用双手】三个项目的检测，故自由度的计算公式应为：(3-1)x(2-1)=2  

M和N的取值同时可以根据整理后的抽样结果表求得：整理后的抽样结果表中是一个交叉表，存在3行(对应三个检验项目)2列(对应两个检验维度)；表格则称为3x2表格  
故此时M=3且N=2，而自由度则为(3-1)x(2-1)=2

使用此方法的原因是因为：卡方检验统计量中，实际频数和期望频数的差实际有6项:  

|男|女|
|:---|:---|
|-22|22|
|15|-15|
|7|-7|

这6项按照水平方向和垂直方向相加计算，结果均为0。因此，知道其中两个值，整个表格就可以推算出来

根据得到的结果，即卡方检验统计量为12，而自由度为2；在卡方分布曲线及对应的卡方分布表中寻找可知：  
对应卡方分布曲线下的面积为整个曲线下面积的1%的0.2；即P值为1%的0.2：0.2%，小于5%。  
故可证明：原假设大概率为假。造成抽样中男/女不同抽样结果的惯用手不同的原因不是机会变异，而是实际上分布的差异。


# t分布曲线和正态分布，z分布，卡方分布和方差分析的f分布曲线的区别

（1）t分布

在概率论和统计学中，t-分布（t-distribution）用于根据小样本来估计呈正态分布且方差未知的总体的均值。如果总体方差已知（例如在样本数量足够多时），则应该用正态分布来估计总体均值。

（2）正态分布

若随机变量X服从一个数学期望为μ、方差为σ^2的正态分布，记为N(μ，σ^2)。其概率密度函数为正态分布的期望值μ决定了其位置，其标准差σ决定了分布的幅度。当μ = 0,σ = 1时的正态分布是标准正态分布。

（3）z分布

全称费歇耳（Fisher)Z分布，亦称费歇耳方差比分布

（4）卡方分布

若n个相互独立的随机变量ξ₁，ξ₂，...,ξn ，均服从标准正态分布（也称独立同分布于标准正态分布），则这n个服从标准正态分布的随机变量的平方和构成一新的随机变量，其分布规律称为卡方分布（chi-square distribution）

（5）F分布

1924年英国统计学家R.A.Fisher提出，并以其姓氏的第一个字母命名的。它是一种非对称分布，有两个自由度，且位置不可互换。

二、特征不同

（1）以0为中心，左右对称的单峰分布；t分布是一簇曲线，其形态变化与n（确切地说与自由度df）大小有关。自由度df越小，t分布曲线越低平；自由度df越大，t分布曲线越接近标准正态分布（u分布）曲线

（2）正态曲线呈钟型，两头低，中间高，左右对称因其曲线呈钟形，因此人们又经常称之为钟形曲线。

（3）分布在第一象限内，卡方值都是正值，呈正偏态（右偏态），随着参数  的增大，  分布趋近于正态分布；卡方分布密度曲线下的面积都是1。

（4）分布的均值与方差可以看出，随着自由度  的增大，χ2分布向正无穷方向延伸（因为均值  越来越大），分布曲线也越来越低阔（因为方差  越来越大）。

（5）不同的自由度决定不同的卡方分布，自由度越小，分布越偏斜。

三、用途不同

（1）学生t-分布可简称为t分布。其推导由威廉·戈塞于1908年首先发表，当时他还在都柏林的健力士酿酒厂工作。之后t检验以及相关理论经由罗纳德·费雪的工作发扬光大，而正是他将此分布称为学生分布。

（2） 分布在数理统计中具有重要意义。  分布是由阿贝(Abbe)于1863年首先提出的，后来由海尔墨特(Hermert)和现代统计学的奠基人之一的卡·皮尔逊(C K．Pearson)分别于1875年和1900年推导出来，是统计学中的一个非常有用的著名分布。

（3）正态分布概念是由德国的数学家和天文学家Moivre于1733年首次提出的，但由于德国数学家Gauss率先将其应用于天文学研究，故正态分布又叫高斯分布。

（4）高斯这项工作对后世的影响极大，他使正态分布同时有了“高斯分布”的名称，后世之所以多将最小二乘法的发明权归之于他，也是出于这一工作。

（5）F分布有着广泛的应用，如在方差分析、回归方程的显著性检验中都有着重要的地位。

扩展资料：

t分布数据：

1、首先要提一句u分布，正态分布（normal distribution）是许多统计方法的理论基础。正态分布的两个参数μ和σ决定了正态分布的位置和形态。

2、为了应用方便，常将一般的正态变量X通过u变换[(X-μ)/σ]转化成标准正态变量u，以使原来各种形态的正态分布都转换为μ=0，σ=1的标准正态分布（standard normaldistribution）,亦称u分布。

3、根据中心极限定理，通过抽样模拟试验表明，在正态分布总体中以固定 n 抽取若干个样本时，样本均数的分布仍服从正态分布，即N（μ，σ）。所以，对样本均数的分布进行u变换，也可变换为标准正态分布N (0,1)。

4、由于在实际工作中，往往σ(总体方差)是未知的，常用s（样本方差）作为σ的估计值，为了与u变换区别，称为t变换，统计量t 值的分布称为t分布。假设X服从标准正态分布N（0,1），Y服从（n）分布，那么Z=X/sqrt(Y/n)的分布称为自由度为n的t分布,记为 Z～t(n)

# 如何正确区分方差分析、T检验、卡方检验的使用

差异研究的目的在于比较两组数据或多组数据之间的差异，通常包括以下几类分析方法，分别是方差分析、T检验和卡方检验。

三个方法的区别:

|分析方法|功能|一句话说明|数据类型|
|:---|:---|:---|:---|
|交叉(卡方)|比较差异关系|不同性别(X)是否抽烟(Y)的差异/不同分布情况|X(定性)，Y(定性)|
|方差|比较差异关系|不同收入(X)群体的身高(Y)是否有差异/不同分布情况|X(定性)，Y(定量)|
|T-检验|比较差异关系|不同性别(X)群体的身高(Y)是否有差异/不同分布情况(X需仅有2类，比如男/女)|X(定性)，Y(定量)|

其实核心的区别在于：数据类型不一样。  
**如果是定类和定类，此时应该使用卡方分析；如果是定类和定量，此时应该使用方差或者T检验。  
方差和T检验的区别在于，对于T检验的X来讲，其只能为2个类别比如男和女。如果X为3个类别比如本科以下，本科，本科以上；此时只能使用方差分析**。

## 依据分析的因素进行细分

方差分析:单因素方差分析；多因素方差分析  
t-检验:独立样本T检验；配对样本T-检验；单样本T-检验  
卡方分析

1）方差分析

根据X的不同，方差分析又可以进行细分。X的个数为一个时，我们称之为单因素方差；X为2个时则为双因素方差；X为3个时则称作三因素方差，依次下去。当X超过1个时，统称为多因素方差。

单因素方差分析，用于分析定类数据与定量数据之间的关系情况。在使用单因素方差分析时，需要每个选项的样本量大于30，比如男性和女性样本量分别是100和120，如果出现某个选项样本量过少时应该首先进行组别合并处理，比如研究不同年龄组样本对于研究变量的差异性态度时，年龄小于20岁的样本量仅为20个，那么需要将小于20岁的选项与另外一组(比如20~25岁)的组别合并为一组，然后再进行单因素方差分析。

如果选项无法进行合并处理，比如研究不同专业样本对于变量的态度差异，研究样本的专业共分为市场营销、心理学、教育学和管理学四个专业，这四个专业之间为彼此独立无法进行合并组别，但是市场营销专业样本量仅为20并没有代表意义，因此可以考虑首先筛选出市场营销专业，即仅比较心理学，教育学和管理学这三个专业对某变量的差异性态度，当对比的组别超过三个，并且呈现出显著性差异时，可以考虑使用事后检验进一步对比具体两两组别间的差异情况。

双因素方差分析，用于分析定类数据(2个)与定量数据之间的关系情况，例如研究人员性别,学历对于网购满意度的差异性;以及男性或者女性时,不同学历是否有着网购满意度差异性;或者同一学历时,不同性别是否有着网购满意度差异性。

多因素方差分析，通常用于类实验式问卷研究。比如研究者测试某新药对于胆固醇水平是否有疗效；研究者共招募72名被试，男女分别为36名，以及男女分别再细分使用新药和普通药物；同时高血压患者对于新药可能有干扰，因而研究者将被试是否患高血压也纳入考虑范畴中。因而最终，X共分为三个，分别是药物(旧药和新药)、性别，是否患高血压；Y为胆固醇水平。因而需要进行三因素方差分析即多因素方差分析。

在方法选择上，问卷研究通常会使用方差分析，但某些专业，比如心理学、教育学或者师范类专业等涉及到实验研究时，更多会使用T检验进行分析，另外方差分析与T检验还有较多差异，在某些分析中只能使用其中一种。

 
2）T检验

T检验共分为三种方法，分别是独立样本T检验，配对样本T检验和单样本T检验。

独立样本T检验和单因素方差分析功能上基本一致，但是独立样本T检验只能比较两组选项的差异，比如男性和女性。相对来讲，独立样本T检验在实验比较时使用频率更高，尤其是生物、医学相关领域。针对问卷研究，如果比较的类别为两组，独立样本T检验和单因素方差分析均可实现，研究者自行选择使用即可。

独立样本T检验和配对样本T检验功能上都是比较差异，而且均是比较两个组别差异。但二者有着实质性区别，如果是比较不同性别，婚姻状况(已婚和未婚)样本对某变量的差异时，应该使用独立样本T检验。如果比较组别之间有配对关系时，只能使用配对样本T检验，配对关系是指类似实验组和对照组的这类关系。另外独立样本T检验两组样本个数可以不相等，而配对样本T检验的两组样本量需要完全相等。

T检验的第三种分析方法为单样本T检验。比如问卷某题项选项表示为1分代表非常不满意，2分代表比较不满意，3分代表一般，4分代表比较满意，5分代表非常满意，当想分析样本对此题项的态度是否有明显的倾向，比如明显高于3分或者明显低于3分时，即可以使用单样本T检验。单样本T检验是比较某个题项的平均得分是否与某数字(例子是与3进行对比)有着明显的差异，如果呈现出显著性差异，即说明明显该题项平均打分明显不等于3分。此分析方法在问卷研究中较少使用，平均得分是否明显不为3分可以很直观的看出，而不需要单独进行检验分析。

3）卡方分析

卡方检验用于分析定类数据与定类数据之间的关系情况。例如研究人员想知道两组学生对于手机品牌的偏好差异情况，则应该使用卡方分析。卡方是通过分析不同类别数据的相对选择频数和占比情况，进而进行差异判断，单选题或多选题均可以使用卡方分析进行对比差异分析。

# 针对显著性检验的更准确的考虑：如何做好显著性测试

## 结果是否真的显著

针对P值得取值，为了真正拒绝原假设，应该低于多少？一般情况下，这个值应该由*小概率事件*所定义，即0.01-0.05两个节点组成得三个结果。  
当P值结果小于0.05时，即意味着原假设得发生为小概率事件，从而可以拒绝原假设；若P值小于1%，则原假设大概率不会发生，且检验结果是高度显著的。  
但是实际上，这有点先射箭后画靶得意思，即：**在可能和不可能之间，缺乏明显的界限**

实际上，针对是否拒绝原假设给予的是*小概率事件*，而*小概率事件*的定义，则是由费舍尔依据其习惯定下的，实际没有理论支撑。  
且，实际上P值为5.1%时和4.9%时的意义几乎相同，但是因为此类判定的原因，检测的结果将可能大不相同。

故，为了使得听众更好的理解假设检验的过程和结果，则**调研人员应概括数据，说明使用了哪种检验统计量方法，并且提供P-值，而不是仅仅将P-值与5%与1%进行比较后，提供诸如"小概率事件"/"极小概率事件"等概括**

## 数据窥探/数据探查

假设检验/显著性检验的目的：**区分实际存在的差/差异和机会变异的可能性**。  
但是统计结果为显著的事件，其结果不能武断的认为，事件出现的原因不可能是因机会变异引起。因为机会的原因，抽得的结果也有可能高于盒子平均值2个SE。  
即:即便原假设被接收，其依旧存在5%的几率取到一个由检验称之为*统计显著*的差值数据；而同样的，原假设也存在1%的可能性取到一个被称之为*高度显著*的差值数据。  
针对此情况，如果进行100次检验，则可期待出现5次*统计显著*和1次*高度显著*的检验结果。而每次出现的结果均是侥幸。所以，很难界定出现的事件的差，到底是因为实际存在还是机会。

数据窥探/数据探查指的统计学家在对数据进行正式分析之前，通过一些统计手段(一般使用描述性统计，或通过对原数据进行抽样)了解数据总体的一种方法。**数据探查就是在总体数据中抽样**。  
一般情况下，数据假设/原假设是基于数据窥探得到的结果创建的，故实际上会有一些先射箭再画靶子的行为。  
因为所谓*统计显著*和*高度显著*可能随机出现，并且影响实际的验证结果的原因，**需要通过多次重复抽样/实验的方法，来验证统计的结论**。  

例:肝癌是一种罕见的癌症，常被认为是因为环境引起的。在一个10000个人组成的小镇上，某年存在2个及以上病例的概率为1%的1/2；一个整群肝癌病例(在同一镇中里存在的若干病例)的出现将帮助/促使探究出现肝癌的原因，譬如由于合成化合物引起的供水污染。

针对100个上述文中的小镇在10年内(100x10=1000个镇和年的组合)，可能会产生多个整群；针对整群发生的概率(1%的1/2)，这1000个镇/年组合中，会出现1000x0.005=5个整群。  
故，如果针对原假设(肝癌出现的原因为化合物引起的供水污染)进行不断的检验，则迟早会得到1个显著的差。

### 数据窥探/数据探查与单尾/双尾假设检验

在进行数据窥探时，有时也可以决定假设检验时是否应该使用双尾检测。  

***实际检验时，使用单尾还是双尾数据，将基于统计学家预设的原假设和备择假设  
它关系到要看哪些Z值，比起数据计算出的Z值，更有利的赞成了备择假设。  
一般情况下，单尾检验适用于备择假设称盒子的平均值大于某个值；而双尾检验则适用于备择假设称盒子的平均数不等于(大于或小于)给定值***。

***实际上，使用单尾还是双尾检验，对结果的影响并不大，而重要的是了解当前情况下实际使用的检验。毕竟，假设检验大多是是针对原假设进行的。  
针对一个单尾的假设检验，其P值只要乘以2，即可得到双尾假设检验的P值，反之也是成立的  
这是因为，双尾检验实际上是在求检验统计量得到的结果，在曲线两端的面积的占比。对于一个符合正态分布的曲线，在检验统计量右端的面积和在左段的面积是相同的。  
故针对P值，双尾检验下的P值等同于单尾P值x2***

例：验证硬币是否公平，正面和背面是否均有50%的概率出现。  
抛1枚硬币100次，得到61次正面。而如果硬币是公正的，则理想情况下应该可以得到头像50次。  

**为了证明61和50之间所差的原因是因为机会误差，即硬币是公平的(原假设)；  
而备择假设则认为：硬币不是公正得，且偏向正面；即出现正面得比例大于1/2**；  

这时可以使用Z-检验检验数据。  

针对上述条件，可以设置一个盒子机会模型：将投到硬币正面记为1，而投到硬币硬币背面记为0，则模型的组成应为【0，1】  
此时盒子中0和1卡片的数量未知，故无法使用卡方分析

针对上例，则相当于对盒子进行了有放回的随机抽取100次，根据已知的盒子SD:1/2[(1-0) * 平方根(1/2x1/2)]，则100次抽取下，盒子的SE为平方根(100)x1/2  
此例中，原假设为盒子100次抽取结果的和为50，而备择假设的结果为61，则根据Z-检验的检验统计量计算公式应为:(61-50)/5=2.2 SE  
当对上述备择假设进行验证时，大的正Z值赞成备择假设，而负Z值不赞成备择假设。因此大于2.2得正Z值比观察值更加赞成备择假设。  
故此时，P值得选取应该为一个单尾得分布，即：正态曲线2.2个标准单位外部分所占整体得面积，约占不到5%，约等于1.4%。即：原假设发生得概率为1.4%。

**但是，如果针对同一模型提出不同得备择假设时，可能就需要使用双尾Z检验进行假设检验:  
针对上例，如果提出得备择假设为：出现头像的概率在任意方向均不为50%，即：盒子中1的占比不为/大于或小于50%；  
此时，一个大的正Z值和一个大的负Z值均可以赞成备择假设；  
上例中，如果原假设被正面不为50%，即50的期望值以上2.2个SE；则对于备择假设是有利的，而对原假设不利。而如果在50期望值一下2.2个SE，对于备择假设也同样有利，而对原假设不利。  
此时，应使用双尾Z检验，即需要得到大于+2.2SE及小于-2.2SE的曲线下的面积，根据正态表计算可知为:2.8%

**单尾双尾使用条件**：

多数情况用双尾，比方说只想看一下A，B间是否右差异，而不具体关注A大于B，还是B大于A，这种情况用双尾

而当你有十足证据表明加了某种处理以后，使得A大于B（或A小于B），那么这给时候用单尾

总结一下，单尾检验是带有方向性的，即A大于B或是B大于A，而双尾检验是没有方向性的，往往只想看A，B之间是否有差异（A等于B还是A不等于B）

1.双尾检验，属于比较性检验，没有具体方向性，只是比较与一个设定值的是否相同，无关乎大小；

2.单尾检验，属于方向性检验，在科研实验或者干扰实验中比较多，给定一个处理，有一个预期结果：相对对照组大或小，已经预设了一个大小的方向关系。

例:

* 适合单尾检验的案例：一位治疗专家设计了一种新的干预方法来治疗某症，他认为新的方法比目前使用的方法费用更低、效果更好；对被试冥想前和后的血压进行比较，看看其血压是否显著下降。

* 适合双尾检验的案例：某心理学家对男女性进行比较，想知道他们在过去的一年里与异性冲突的平均次数是否有差异；比较在嘻哈和爵士两种音乐背景下老鼠的活动水平。

* 判断大耳白兔与青紫蓝兔的血糖含量是否有差异，这时就要用双尾检验，只需判断两者是否相等即可

* 若问大耳白兔的血糖含量是否比青紫蓝低，这时就要用到单尾检验，需判断两者血糖含量大小问题

例2：针对胆固醇药品在降低血清胆固醇和防止心脏病方面的随机双盲测试，实验挑选了3806个处于心脏病突发风险的男性。  
使用随机不放回的方法抽取其中1906人至实验组，另外1900人至对照组。实验时间为7年。

根据实验结果可知：实验组中样本对象平均降低了8%的胆固醇，且实验组中存在155例心脏病突发案例，而对照组中则存在187例子。  
针对上述情况，为了正面胆固醇和心脏病之间的的逻辑，则可以使用Z-检验。  
此时设定的原假设为：胆固醇对心脏病没有关系，而实验组和对照组中突发心脏病的比例变化是因为机会变异引起的。  
而备择假设则可以设定为：胆固醇降低，降低了心脏病发现的比例。  

根据上述例子，可以将3806个对象作为盒子中的内容/卡片放置到盒子里。每个卡片上标有针对胆固醇药物和安慰剂的心脏病发病次数，而只能观察到其中的一个。  
根据分类可知：其中抽得的1906个实验组中的和的结果为155，比例为8.1%；而1900个对照组中，和的结果为87，比例为9.8%。  
而此时的实验组SE为 平方根(1906)x1/2=21.8，占比为0.011，而对照组中的SE为平方根(1900)x1/2=21.7；则方差/SE为0.011，而Z假设检验统计量为 ((8.1%-9.8%)-0)/0.011 = -1.84。P约为3.2%  
故原假设被拒绝，即：实验组和对照组在心脏病突发数上的差值是确实存在的。

而如果将备择假设改为：胆固醇存在对心脏病的影响(包括增加/减少心脏病)，则此时P值为3.2%x2=6.4%

## 假设检验的结果

**显著不意味着重要，统计显著和实际显著是两个不同的概念。  
如果希望验证样本中产生的差异是否重要，则可以假装其适用于整个总体，再在实际环境中了解差异存在的含义，这杯称之为：真实显著性测试**。

例如:比较大城市和农村孩子词汇量等级得分，分别从城市/农村取(随机)2500个样本进行词汇量考试。其中城市组平均得分26分，方差为10分；农村组平均得分25分而方差为10分。  
在一个双因素/样本Z测试下，Z检验统计量为(25-26)/平方根((平方根（2500）x10/2500)^2 + (平方根（2500）x10/2500)^2)=1/0.3=3.3，即P为万分之5  

城市-农村儿童间的差异高度显著，而农村儿童在语言开发方面急需提高。

**双样本Z检验的结果告诉我们：样本平均数间1分的差距不太可能解释为机会误差  
再者说，假设通过对全国进行调查，调查结果如同上面例子，则显著性检验将无特别帮助  
故，显著性检验的主旨，是找出差的含义**

但是根据定性分析可知：城市-乡村间平均数上1分的差，仅仅对应40道考题中的1个。这也证明了：城市-农村间的识字水平相同。

在大样本量情况下，则样本的SE相对较小。但因为Z检验是通过差值和SE进行比较，故：对于大样本，即便差值很小，也能得到很大的Z检验统计量。  
即:**Z检验对大样本检验相对过于敏感，故需要结果定性分析去解读得到的检验结果**

***检验的P值实际依赖样本容量，对于大的样本，即使小的差也有可能被认为是统计显著的；这很难用抽取的运气解释。  
相反，如果样本太小，一个重要的差则会显得不显著***。

## 假设检验是否可以证明论点

**一般情况下，假设检验/显著性检验，用于确定原假设期望值和实际观察值/备择假设值之间的差的产生原因，是否大概率由机会变异产生  
即排除差出现的原因是因为机会变异造成的解释  
研究人员一般收集数据以证明具体论点。如果证明数据差产生的原因为机会变异，则无法证明任何东西。  
因此，研究人员通过显著性检验证明差是客观存在的**。

但是，**有时，即便使用显著性测试证明差是实际存在的，但是依旧无法证明论点，这是因为：  
显著性检验仅能证明原假设和备择假设之间的差异并非机会误差产生，但是无法回答/证明"是什么原因/什么东西引起了双方的差"。

例：研究使用ESP改变骰子结果的实验。实验中，要求一个拥有“使得骰子可以投出更多6点”能力的实验人员，对一粒骰子进行720次抛掷，并计算出得到了143次六点。  
这就相当于：使用0-1盒子模型【0，0，0，0，0，1】进行720次随机抽取，结果的和为143。  
因为骰子存在1/6的机会产生被投中，则实际期望值应为720x1/6=120。

当原假设为：产生情况由机会误差产生，实际值应为120。  
则Z检验统计量应为(142-120)/(平方根(720)x平方根(1/6x5/6))=2.3，故P=1%。  
即原假设被拒绝，观察值和期望值之间得差是实际存在得。

那么回到实验当中，使用显著性测试得到得结论是：观察值和期望值之间确实存在差距，即：骰子确实存在更偏向出现6点得情况；  
但是这个差的存在，并不能证明实际实验者存在ESP。

如果更换实验者进行实验(声称无ESP)，或者同一个实验者尝试施加ESP，增加5点出现的频率，而投掷的结果依旧出现投掷到6点数量过多的问题，  
则**不能说明ESP存在，而可说明：骰子存在偏性**

检验中，原假设被设定为：是否存在太多的六，以致于机会中多余的机会无法使用机会变异进行解释。而得到的结果为：**多了一点**  
但是检验中存在的机会/假设/先决条件，指的是：**抛一枚公正的骰子**  
这个假设被用于计算Z检验的期望值和SE。而**使用显著性检验之前，必须了解检验本身是在针对哪张机会进行的**

***显著性测试/假设检验是定量的而非定性。即显著性测试一般仅能反映差是实际存在的，而无法反映差存在的原因。  
所以，假设检验可能仅仅是实验的一个步骤/一个检验之一。需要配合其他的定性/定量检验进行。  
而一个设计良好的实验，可以通过实际存在的差对实验人员的论点进行验证。  
但是，如果实验设计存在问题，即实验本身的结论无法证明希望证明的东西，则即使实验结果显著，而无法说明任何问题***

***显著性检验不检验研究/实验的设计***

例2：针对之前进行的ESP检测设备宝瓶座的例子，即：机器中存在一个随机发生器，将随机的抽取4个已有标识中的一个作为目标，但不指示出。  
参与者尝试使用意念力探知机器的选择后，通过选择4个标识对应的按钮做出选择。如果选择正确，即机器和参与者选择了同一个标识，则结果将被记录下来。

在7500次测试中，猜中结果的次数为2006次相对于期望值7500x1/4=1875次，差为：2006-1875=131，而Z检验统计量为3.5；P为2/10000(单尾)  
故：根据结果可以判断，原假设可以拒绝，即观察值和期望值的差可以很难解释为机会变异。但是，出现差的原因并不能被直接解释为是ESP在起作用。  
这时，为了排除可能的原因，则需要针对实验/研究的设计本身进行定性的检测。

经过检查发现：随机数发生器中，存在一定缺陷：*很少在一排里两次中挑中一个目标*。而如果实验对象注意到此问题/缺陷，则可以通过排除法改善他们的机会。  
而在修改设备后，再次重复实验，则结果开始符合机会变异。

## 定义机会：假设检验/显著性检验中，模型的作用

**无模型，不检验。在假设检验过程当中，看似并未使用机会模型。检验过程似乎直接通过数据分身计算机会(P值)。  
但是因为假设检验/显著性测试的目的是：了解出现的差异是否是因为机会；而对“机会”一词进行定性的，即是机会模型/盒子模型(测试中的机会/分布是什么样的)。  
故：如果想要假设检验有作用，则需要使用盒子模型**。

具体来说：***盒子模型定义了机会，而假设检验则用于验证和比对机会***   
在使用上述假设检验时，期望值和标准误差的计算中，实际已经假定***实际得到的数据就像从盒子中抽取的数据那样，即：简单随机有放回的从盒子中抽取***  
不同假设下形成的曲线，正态表/分布表计算的先决条件也是基于此。而如果一旦偏离这个假设，则所有的计算均是没有意义的。

### 例：针对整体的假设检验计算

***如果显著性检验是基于整体，而非样本数据的。则实际无需进行任何假设计算，直接对结果进行计算即可。  
这是因为：显著性测试仅用于抽样条件下的假设，而此类假设的先决条件/原因就是无法彻底收集到总体的所有数据。  
故，如果当前已经得到了总体的全部数据，则不应使用假设检验进行计算，而是使用描述性统计针对统计目的进行计算。  
当然，大部分情况下，与i那位一些主观/客观的原因，当前接收到的数据均为样本数据***。

例：根据普查结果，国内1970年有2亿3百万人，而其中9.8% >= 65岁。而当1980年进行同样测试时发现，当前有2亿2千7百万人，而>=65岁的人口站11.3%，问：百分数只差的统计是否显著。

此例中，实质上可以使用0-1/定性盒子的Z值/Z检验统计量进行定性计算，即：计算盒子平均数的误差所占的百分比。但是，结果是无意义的。因为题中不存在样本，而是仅仅存总体的相关数据。因为没有机会误差的影响，则如果通过比较得到两个数据间存在差距，而显著性概念不适用，此差距定是实际机会的差距。即：人口的老化是实际发生的。

### 例：基于“方便样本”的假设检验计算

“方便样本”，指的杂乱的，是包含了全部收集到的信息的样本，或者是根据最优结果(获得数据成本最低)为导向获得的数据；  
和通过随机抽样得到的数据相对。

***如果假设检验/显著性测试是基于一个方便样本进行时，则得出的结果会是模糊的，难以解释的。  
因为数据中包含了大量不同情况的样本对象，会对结果造成一定影响***。

例：针对大学录取率和性别的研究发现，某年某专业的男性申请人为825，录取率为61.7%；女性申请人为108，而录取率为82.4%。问：男/女录取率之间的差是否显著。

此例依旧可以使用双样本Z检验，针对一个0-1/定性盒子进行。但是，因为难以界定参与的总体，即难以识别全部可能的申请者总体；同时因为实际申请者也非随机从总体中进行抽取，且每个系也非随机抽取申请者为录取者，故无法设置盒子模型。

对于方便样本而言，机会的感念变得非常难以捉摸，“样本的差源于机会”这句话也变得难以解释，P值也是如此

例2：天才培训机会Follow Through计划，指的是将一群天才少数裔学生送进一个单独的培养机构进行培养的计划。为了搞清通过此类方法培训的学生和普通学生是否有所不同，调查人员法满了一种文件，并针对20个分布在5个城市的天才课堂，和同样对照的普通课堂做对比。天才课堂得分如下：

|城市|分数|
|:---|:---|
|Berkeley|73,79,76,72|
|Duluth|76,84,81,80|
|Lebanon|82,76,84,81|
|Salt Lake City|81,86,76,80|
|Tacoma|78,72,78,71|

这20个课堂得分的平均数为78，SD为4.2；而对于对照组的课堂，得分为60。

使用Z检验时，先求得SE为平方根(20)x4.2=19;故平均数的SE为 19/20=1  
故最终Z检验值为 (78-60)/1=18SE，则P值约等于0。则判断，天才班项目和普通班之间确实存在不同。

上述计算方法存在问题：  
1. 未创建机会模型：题中其实未为此例子创建机会模型，且因为范围过广无法创建  
2. 抽样未依据简单随机抽样：此例中，用作实验组的20个天才班对象，均为方便样本，即未使用任何复杂概率方法抽取的样本  
3. 所谓差的机会中存在其他偏性：如果按照高斯误差盒的理论，数据中的差异应仅仅来自误差，而例子中存在其他偏性，例如因为城市/课堂/教师/学生/年份产生的偏性；如果误差盒随着城市/课堂不同而不同，则误差实质相依

此例中，把从外界看来，可以用显著性检验比较平均数，不管他是从哪里来的，当成了不言而喻的。证明项目课堂不同于对照组的整个实验均依仗于此检验，而检验本身却缺乏足够的依据。  
检验本身仅仅存在20个数据，但是20个数据并未使用简单随机方法抽取，也没有关于同一个量的20此度量。  
这些数含有机会成分，但是却不知道机会成分产生的机制。

故，此类检验注定是无用的。

## 结论

进行假设检验时，应该遵循：集中于需要检验的问题，根据需要检验的问题进行定性/定量上的，或者业务==>数学上的转换；并且时刻留意当前的情况/问题是否可以真正解决需要检验的问题。  
假设检验/显著性检验只会回答一个问题：基于机会变异，解释实际观察到的数据和基于原假设的期望值数据之间的差是否容易。  
而机会变异本身则由盒子模型定义，模型本身则有调查人员自行指定。  

检验本事不会核实模型是否是恰当的，或是否是有可能的。检验也不检测一个差的大小，原因，或者重要性；  
因此检验只能回答特点的问题，这常常是一个要问及的错误问题。  
因此这个问题不应由检验来解答，而是应该有由估计来解答：包括构造数据的机会模型，用以定义根据模型估计到的参数；并使用数据估计它，并给估计赋予标准误差。