# 统计学学习

***统计学不研究统计，它研究的是不确定性***


统计的基本思想: ***从随机性中寻找规律性***

统计思想的基本方法：***从样本性质推断总体性质***

推断的两大支柱就是：***概率和误差***，并贯穿于整个统计学的几乎所有关键点。

统计学最终归结到两个核心理念:***允许误差下的概率保证;允许误差下的统计推断***。

统计思维模式主要包括：  
均值模式  
变异模式  
估计模式  
相关模式  
拟合模式  
检验模式  
归纳模式  
比较模式  

均值模式：均值是对所要研究对象的简明而重要的代表。均值模式要求从总体上看问题，观察事物一般的发展趋势，避免个别偶然现象的干扰，体现了总体观、数量观和推断观。

变异模式：均值也代表了某种变异，否则无从谈起。统计研究对象中的个体必须存在差异。统计方法就是要认识事物数量方面的差异。在统计学中，用来反映变异的概念是方差，表示离散程度。平均与变异都是对具有同类个体的总体特征的抽象和宏观度量。

估计模式：估计模式是应用某种合理的方法，通过对有限量的样本的分析，对未知事物或者未发生事物进行估计推测的思想，由一个事物的特点和规律来推测其他事物，对其进行认识。使用估计方法有一个前提条件，那就是获取的样本应与总体具有类似的性质。在某种条件下，样本才能代表总体。在估计过程中，要保持逻辑的严谨性。

相关模式：并不是所有的事物之间都存在着严格的因果关系。在某些统计样本的变化过程中，经常会出现一些其它事物相随共变或相随共现的情况。我们把这种非确定性关系的相随共变叫做统计相关性。它们之间不存在确定的函数关系，也会有奇异值出现。

拟合模式：在统计世界中，个体显随机性，群体显规律性。拟合是对群体规律性的抽象，即公式化或模型化。一旦事物的变化被模型化，我们就找到了解决问题的方法，知道了变化趋势。

归纳模式：由某类事物中部分对象的特征,推断出该类事物的全部对象的特征,或者由个别事实概括出一般结论的推理叫做归纳推理。归纳推理是由部分到整体,由个别到一般的推理。推断性统计的由随机抽样样本性质推断总体性质的方法就是归纳的方法。有时归纳法得出的结论未必真实，因此还需要用实际样本资料对结论进行检验。

检验模式：推断性统计的依据就是归纳法。归纳法得出的结论永远是概率性质的。为了保证基于局部特征和规律所推断出来的对整体的判断的可信度，我们需要增加一道检验过程，就是利用实际样本资料来检验事先对总体某些数量特征的假设是否正确。

比较模式：统计的比较模式是依照比较的思维逻辑将比较对象与比较标准进行比较对照，计算出现象数量上的差别和变化，进而对比较对象做出评价和判断的一种统计思维方式。它包含比较的标准、比较的方式和比较的原则等具体内容。统计的比较模式在相对指标、变异指标、时间数列分析、指数、抽样推断和相关分析中都得到了有效的运用。


## 1. 统计学实验设计，及背后的知识

***设计实验的原则，是尽可能的控制实验中出现的变量，如果需要，则可以使用分组的方式处理那些无法通过主观行动影响的实验***

### 1) 对照实验

对照实验，即通过控制实验中的变量，对实验过程和结果进行**比较**。 对照实验是常用的实验方式，可以用于检验药物的有效性等。  
对照实验的关键在于分组：比如检验药品的有效性当中，可以通过认为的设置**处理组（提供药品）** 和 **对照组（提供安慰剂）**  

为了保证实验结果，实验过程需要保证随机：实验分组随机，过程双盲（实验者和实验者在均不知情的情况进行实验于统计）

同时，统计学上，为了避免**偏性**,需要进一步的控制对照组和处理组间的变量，防止出现因其他变量对实验结果进行**混淆**，这需要使得除了处理/实验这点之外，两组尽可能的相似  
以药物实验为例，为了避免因家庭条件（富裕家庭比贫穷家庭营养更好导致抵抗力更强）引起的偏性，则需要在对照组和处理组内部再增加一个家庭环境的分组，以进行对比。

在分组开始前，需要对参与实验的对象进行检查，保证他们均符合条件，例如：参与新冠疫苗实验的实验对象，不能患有新冠

整体实验中，两个分组的绝对数量不是关键，只要保证在同一数量级即可，因为最终判断结果数据时，可以使用比率而非绝对数据进行判断。

### 2) 历史对照实验

历史对照组，即将使用新方法的实验对象作为实验组，将之前使用老方法的实验对象设置未对照组，通过比较实验组和对照组确定结果。

例如：确定新药的有效性：将使用新药和老药的实验对象进行比较。

对于历史对照实验来说，需要控制历史对照组和实验组之间的差异，以避免可能出现的偏性。

## 总结

1. 统计学家使用比较的办法，试图搞清处理(接种疫苗)对反应(感染新冠)的效应。为了找到这两者的关系，他们把处理组和对照组中同分组的反应/结果之间进行对比
2. 在保证处理组和对照组仅仅在实验上出现区别，其他点上没有区别的情况下(避免混淆)，这两个组对比的结果就应该是实验的效果
3. 在使用随机对照实验的情况下，为了保证处理组和对照组条件相同，应尽量使用随机抽取的方式从实验对象中选择处理组和对照组
4. 对照组使用的安慰剂，应是中性的但是近似处理组使用的试剂
5. 随机实验应遵循双盲实验原则，即实验对象不清楚自身是在处理组还是在对照组，而研究人员也同样不知道这点，以免人事行为及之后评估过程中产生偏性

### 2) 观察研究

观察研究和对照实验不同，对照实验中，研究者决定对照组，而观察实验当中的分组是自然形成的，研究人员仅仅是客观的观察整体结果

***相对对照实验，观察研究中分组流程中，很有可能存在一定的偏性（例如吸烟的人群和不吸烟的人群进行比较，吸烟的人群的收入可能更低，因此影响了两个组的寿命）。为此，观察实验中，首先应该理清对照组和处理组之间的关系，以避免混淆***

针对对照组和处理组之间的混淆问题，最好的解决办法是通过创建子分组的方式控制变量。

控制变量的方法，可以用于针对较小且较均匀的分组进行偏性处理。例如：比较吸烟者和不吸烟者健康情况，以判断吸烟是否真正影响健康的实验中，因为吸烟者客观下以男性居多，且年龄偏大，故从整体上看会收到性别影响

为了排除这些影响，则应该针对**不同年龄层**的**男性吸烟者和男性非吸烟者/女性吸烟者和女性非吸烟者**进行观察实验。通过这种控制行为，可以事实上的避免性别和年龄分布不均的原则，对对照组和处理组返回的结果产生的影响。

***相关性并不等同于因果关系***

糙皮病案例：  
糙皮病（一种皮肤病）在18世纪被欧洲贫困地区的医生首次观察到，因为和某种吸血苍蝇的地理活动区域相同，一直被认为是由此类苍蝇传染的。但在20世纪，糙皮病被发现是因为缺乏烟酸(P-P因子)造成的，烟酸天然存在肉/蛋/奶/部分蔬菜和谷物当中，但是不存在于玉米(穷人的主要食物)当中。饮食上的限制才是糙皮病的主要病因，而苍蝇只是贫穷的标志，不是病的起因。

***针对通过观察研究中存在的混淆问题，可以通过设置更多较小的/均匀的子组进行调整这被称为：控制混杂因素***

例: 加州大学入学性别分析：  
从宏观角度上，加州大学以性别划分的入学率当中，男性占比44%，相比女性占比35%来说，确实存在一定入学歧视，得出这种判断潜在的假设是:  
1. 男女申请资质相同
2. 每个专业对招收男/女的倾向大体相同
通过对100个系中，占据30%比例的6个系的男/女录取率进行分析，可以发现：
1. 从录取率上来看：6个系中男/女的录取率相近，没有显著区别
2. 从绝对值上看，男/女在6个系的总数上没有太大差距，但是在分布上出现了较大差异：女性申请人更多集中在6个系中的4个系当中，而男性申请人则更多的集中在6个系当中的前两个系当中
根据之后调查的结果发现：6个系的申请难度并不相同，前两个系相对易于申请，而前两个系恰恰是男性集中申请的系，而其他四个系相对难以申请，但是集中了大部分的女性申请人

故，可以得出结论：表面上的申请差异是由男/女申请人申请系的分布引起的，底层原因则是因为每个系的申请难度不同，即：男性申请容易录取的专业，而女性则多申请录取难度高的专业

|专业|申请人数（男）|录取百分比（男）|申请人数（女）|录取百分比（女）|申请总数|
|:--|:--|:--|:---|:---|:---|
|A|825|62|108|82|933|
|B|560|63|25|68|585|
|C|325|37|593|34|918|
|D|417|33|375|35|792|
|E|191|28|393|24|584|
|F|373|6|341|7|714|

为了便于进行混淆控制，可以引入加权平均数的方式对申请率进行计算，此处的加权数即为申请总数：

男性加权平均入学率：  

    (62%x933 + 63%x585 + 37%x918 + 33%x792 + 28%x584 + 6%x714) / sum(933,585,918,792,584,714) 

39%

女性加权平均入学率：  

    (82%x933 + 68%x585 + 34%x918 + 35%x792 + 24%x584 + 7%x714) / sum(933,585,918,792,584,714)  

43%

最终得到结论：男/女申请人加权平均录取率相同，无性别歧视


# 描述性统计

针对于大部分统计数据，因为样本量较多，均需要使用描述性统计的方法对全部数据进行概括

## 1. 变量

变量，指的是研究中*因调查对象不同*而*产生差异*的*特性*。  
变量可以分为定性变量（婚姻情况，就业情况）与定量变量（年龄，收入）。  
变量可以是连续的或离散的：离散变量中，不同对象提供的变量间的差距应是固定且仅在一定范围内的（家庭规模）。而连续变量间的差距则是不固定的（年龄，一年、一个月、一天）  
在研究中，定性数据是由定性变量收集的

### 变量控制

在一般的实验当中，不会仅仅针对一项变量进行试验。  
例如：针对药物的实验中，会有血压，效果等多项变量。针对每个变量都要做好变量的控制工作：针对**血压**这个变量的测量工作中，也需要考虑到年龄的分组控制
这种情况下，可以使用交叉表列出实验组和对照组，所有年龄段下，不同血压的人数的比例

## 2. 平均数与标准差

在统计学中，**平均数**和**中位数**都用于寻找数据的中心（算数中心和实际中心），而**方差/标准差**用于度量平均数的散步程度（散步约大，方差/标准差越大），**四分位数间距**则是数据散步的另一种测度。

### 平均数中位数与方差

***一个数列的平均数，等于他们的和除以他们的个数的总数。***  
***一个数列的中位数，等于数列从小到大排列，此时数组最中间部分的标量数字就是中位数，如果数组为偶数，则为中间两个数的平均值***

平均数是一个用于*概括数据*的强有力的办法，但是这种浓缩仅仅通过*消除数据个体间的差异*而得到。有些差异则会被平均数掩盖掉。  
理想情况下，数据的分布应该是均匀的，所以平均数应该等于中位数。但是实际情况下，两个数据往往存在差异，而此时平均数两端的数据分布并非50%对50%。而中位数的两边数据分布均为50%对50%，即在直方图中，中位数左/右两边面积相等

为了统计平均数(算数中心)和中位数(实际中心)之间的差距，可以使用方差进行度量。  
方差是在概率论和统计方差*衡量随机变量或一组数据时离散程度的度量*，方差用来计算*每一个变量（观察值）与总体均数之间的差异*。  
方差的计算公式：SUM((数组中项目-数组平均值)^2)/len(数组)

### 剖面/纵向调查

剖面调查指的是：不同的研究对象，在*同一时间点*与其他实验对象*相互*进行比较  
纵向调查指的是：实验对象在整个实验中被持续跟踪，且和*自身*在*不同时间点*的记录进行比较

### 均方根与标准差

标准差/Standard Division（SD）用于计算数列中*同时出现了正/负两种数据*的情况下，*数据的分布*，即一个数列关于其平均数的散布。  
方差度量了数组偏离平均数的大小，这是一类平均偏差。标准差表示了数列中的数离散于它们的平均值有多远。大多数情况下，数列中的数项离开平均数一个SD单位，极少数数项偏离了2个及3个以上的SD。  
粗略的说，数组中三分之二的数项（68%）在离平均数+-1SD范围内，其余32%离的较远；20分之19的数项（95%）在距离平均数+-2SD的范围内，而5%则远之；此规则适用于大部分数列。这也是置信区间设置为95%的原因。  

均方根是一种*降低偏性*时常用的计算方法，在数据统计分析中，**将所有值平方求和，求其均值，再开平方，就得到均方根值**。在物理学中，我们常用均方根值来分析噪声。

均方根计算指的是：(SUM(((数组中项目)^2))/len(数组))再开根号，均方根计算了去除符号后，数列的项有多大；标准差计算的是偏离平均数（平均数偏差）的均方根。

标准差计算指的是：(SUM(((数组中数项目-平均数)^2))/len(数组))再开根号  
另一种计算方法：((项数)^2的平均数-(数项平均数)^2)再开根号

# 正态分布

### 正态曲线

因为相像，直方图可以近似划为一条曲线/正态曲线（正态近似），正态曲线用于代替统计数据常用的直方图，方便进行数据比较工作。

正态曲线公式：100% / 根号(2Π) * e^-(x^2/2)，其中e=2.71812

正态曲线关于0点对称，故数据0点即为平均值点，又为中位数点，且曲线下面积等于100%，标准的正态曲线数据应服从：  
+-1标准差单位间的正态曲线面积为68%，+-2标准差单位间的正态曲线面积为95%，位于曲线首/尾两个部分约占数据的十万分之六。

***标准单位个数是指的一个数值在平均数之上/之下多少个SD***

正态曲线内部表面积的求法：依据已知的+-1SD 面积为68%，和+-2SD为95%（这被称之为正态表），且正态曲线依据0点完全对称来推算面积

***一列数，如果遵循正态分布，落在一个给定区间项的百分数可以通过将区间转换为标准差单位(SD)，然后求正态分布曲线下相应的面积而估值。这个过程被称之为正态近似***

正态近似的求值：首先将区间转化成标准差单位(SD)，其次求正态曲线下相应的面积，最后将两步合在一起，

### 百分位数和四分位数

平均数和标准差单位(SD)仅能用于概括服从正态分布的数据，**但是一般情况下，数据不会完美的服从正态分布，而会从在长尾/左偏/右偏等情况**。  
为了概括这种数据，可以使用*百分位数*，即按照数据大小从小到大排列后，依据相同间隔（百分比）将数据分割成多个区间；当中，**第50百分位应正好是数据的中位数**。  
针对常见的几个由百分位数的取值点，可以推出**四分位数，即将数据从小到大排列后进行四等分，每个数据间隔为25%，并观察位于数据0%，25%，50%，75%和100%的几个点的数据。**  
四分位间距，在当**SD因数据分布不遵循正态分布而导致对曲线尾部面积进行了过多关注时**，用于**测量数据散布**，***所有曲线/直方图,无论是否遵循正态分布，均可以使用百分位数对数据进行概括***。

而当数据分布直方图遵循正态分布时，可以根据曲线的 **平均数** 和 **标准差单位(SD)** 对数据本身进行重构，这种情况下，平均数和SD是好的概括统计量。

例:  
数学SAT考试平均分为535，SD为100，求95百分位数。  
正态表中，以0点为准的占据+-2SD部分占据了全部数据的95%，但是此时说的95百分位数，则是说*数据从最小点，到数组的第95百分位*，即故原来的正态分布表中标定的数据在此时将不能使用。但是可以借用**正态近似**的思想，通过曲线面积求解：根据正态表，在服从正态分布的数据中，可以使用SD来表示数据的离散。第95百分数所在的点以在正态分布直方图中对应的点为5%数据所在的点。现在要求的是，5百分位至95百分位之间的面积，且5百分位至95百分位两点的SD值。5百分位和95百分位点中，占据了整个曲线的90%（100%-5%-5%，100%的面积减去了5百分位左边的5%的面积，和95百分位右边5%的面积），想在的问题是：90%阴影面积下的SD值是多少。通过+-2SD占据95%的情况可知，此位置应在2SD之内，约为1.65个SD，即为100 * 1.65 = 165分。故，95百分位则为535+165 = 700分

# 误差与测量误差

***每次单独测量值 = 精确值 + 机会误差***

误差无处不在，理想状况下，如果数据经过多次测量，每次测量的到的结果应该完全相同。但是实际情况下，因为**机会误差**存在的原因，数据每次测量得到的结果一定存在不同。  
机会误差的来源很难搞清，在一般的称量情况中，可能出现机会误差的原因包括但不限于：砝码/测量仪器的磨损，测量时的气温/气压，测量地点的重力等  
一般情况下，测量/处理机会误差的方法，是**经过多次测量后取所有结果的平均值**，这样的话机会误差将会平分给多个结果，这样就能进一步减小机会误差了，这被称之为**中心极限理论**。

***中心极限理论：设想我们重复称量一枚实际重量为5g的砝码。即使我们没有任何的操作失误，结果仍然会是 5.01g, 4.98g, 5.03g, .... ，不停徘徊，但大都处于真实值附近。这些变化来源于无法避免的随机误差。高斯则实际推导出了，这些随机误差应该服从正态分布。经过拉普拉斯，高尔顿等人的发展，我们最终得到了“中心极限定理”。简要一点可以这么说，当样本量趋于无限大的时候，样本均值减去理论均值渐近服从中心为0的正态分布。***

无论怎么测量，测量值都可能不同于真实值，如果重复一次，将显示一次的不同。为了得到一个值得信赖的值，则需要多次重复实验，通过得到的数据进行判断。  
机会误差使得每次单独测量值偏离精确值，偏离大小随着不同测量而变化，**在标准情况下，重复误差的变化性可以代表机会误差的变化性**。
***一系列重复测量值的标准差(SD)是单次测量中的机会误差可能大小的估计***

## 离群点

在正常的测量过程中，必定存在部分数据大幅偏离/远离大部分的测算数据，这些数据被称为**离群点**。  
在计算描述性统计，和拟合正态曲线的过程中，离群点的存在会成为干扰。当研究者看到一个离群点时，需要决定**是否因为接受此点数据而影响到数据的正态曲线的拟合**，**亦或者决定放弃此点**。

如果决定是否放弃离群点：如果数据量相对有限，且希望**坚持数据的客观性**以**避免任何人为的主观筛选过程**，则应该保留离群点。（离群点客观存在且不是因为流程错误所引起，为使得数据和正态曲线拟合而人为且主观的对数据进行筛选，数据将无法很好的表现当前的客观现实情况）如果修改少量离群点即可使得原始数据拟合正态曲线，则可以酌情去掉离群点。

## 偏性/系统误差

在数据测量当中，**偏性以相同的方式影响每个测量值，将它们推向同一个方向**；而**机会误差则随着不同的测量变化而变化，时上时下。**

例如：在卖菜的菜贩子秤砣上的吸铁石：引起秤砣重力变化使得每次测量得出的数据均偏大/小。

***理想情况下，通过统计多次重复实验，机会误差应会被抵消，重复测量值的平均数将给出测量物体的精确值（理想条件下机会误差也应符合正态分布）***  
但因为偏性存在的原因，测量的平均数将大于/小于精确值；偏性会使得每次测量得到的结果偏离真正的值：***单独测量值 = 精确值 + 偏性 + 误差 ***

通过对测量数据的观察无法客观发现偏性，一般会通过和客观标准比对(1千克秤砣和标准千克比较)或者和理论进行比较发现。

# 点和线

线由无数个点组成，在笛卡尔平面直角坐标系中，一个点的坐标可以写为(x,y)

### 线的斜率和截距

在一条线上，从一点A沿直线移动至点B，那么因为A点和B点移动所产生的x轴上的数据增长/减小（负增长）/变化被称之为**前移**，而Y轴上的数据增长/减小（负增长）/变化则被称之为**上升**。  
在一条直线中，无论取哪两个点，上升一定是前移的一半，**上升和前移的比率被称之为斜率：斜率 = 上升 / 前移；斜率是沿直线随X增加Y的比率/形成的夹角的陡峭程度***。  
***斜率为正则直线是上升的，为负则直线是下降的***。

直线的截距是指：***X = 0时 Y的值/高***

***斜率的实质：y变化一个单位和x变化一个单位的比，即：在同一直线上的两点(x1,y1) 和 (x2,y2)中，y变化一个单位(y2-y1) / x变化一个单位(x2-x1)***

### 由点和斜率确定直线/直线的函数

当直线经过点(2,1) 且斜率为1/2，求直线:

函数计算法:  
由直线经过点(2,1)，斜率为1/2可知：
    x = 2,y = 1，且y / x = 1/2，故可得到如下函数：y = 1/2 * x

画图法：  
画出点(2,1)后，向前前移3，根据斜率公式可得出，此时一点应为 1/2 * 3 = 1.5。由此得到两点(2,1)和(3,1.5)后，通过两点确定/施划直线。

***方程 y = mx + b 为一条直线，且斜率为m,截距为b***

# 相关

相关及相关性是统计学研究的重要组成部分。涉及到相关的知识时，一般情况研究的是**两个及两个以上变量之间的关系**。例如父亲身高和儿子身高之间的关系。  
通过绘制父亲身高与儿子身高之间的散点图（没对实验对象中，父亲身高值为x，儿子身高值为y），可以对父亲身高和儿子身高这两个变量进行分析。  
通过判断绘制出的散点图的倾向：整体向右上则x/y为正相关（随着x的增长y同时进行增长），通过观察可知：儿子身高父亲身高有关且呈正相关。但是通过散点图中点的散步可知：如果散步相对集中在一条线上(y=+-x)则可说明两个变量之间相关性强，反之如果散点图中点相对分散，则相关性若。如果相关性较强，则已知一个变量对预测另一个变量存在帮助，反之则无帮助。

通常情况下，仅在自身产生变化的变量被称之为**自变量**，因为自变量变化影响下变化的量为**因变量**。例中，希望了解儿子的身高是否受到父亲身高的影响，则父亲身高为自变量而儿子身高为因变量。

## 相关系数

针对普通的单变量数据，一般可以使用平均数/标准差等描述性统计指标对数据进行概括。针对两个变量的数据，因为存在两个变量/二维的原因，无法使用原先的指标。  
针对二维以上的数据，可以以下指标对数据进行描述:

**平均数点**:变量x和变量y各自的平均数组成的点，即散点图散步的中心点  
**水平/垂直散步度**：在理想情况下，x轴和y轴数据也应该符合正态分布，故可以使用x轴数据的标准差值（SD）和y轴数据的标准差值（SD）计算出水平SD和垂直SD。依据正态曲线表可知，大部分的数据都会集中在+-2SD中，故可以使用**x轴数据+-2SD的值**和**y轴数据+-2SD**的值来描述**水平/垂直散步**。  
**相关系数**：相关系数缩写为r，用于描述x和y两个变量之间的关系。相关系数是线性相关或围绕直线群集程度的一种度量。


### 相关系数的计算

***将每个变量都转化为标准单位(SD)时，乘积的平均数即为相关系数***

将自变量记为x，因变量记为y，相关系数记为r，则：  
***r = mean([(使用SD表示X)x(使用SD表示y)])***  
***mean(x = [(x数项-平均值)/SD] * y = [(y数项-平均值)/SD])***

计算过程：  
1.将x/y值转化为标准单位(SD)
2.求对应x/y值标准单位的乘积
3.求出平均值


例:  
x = [1,3,4,5,7]  
y = [5,9,7,1,13]  

求相关性系数  

首先将x/y对应数项转为SD值：  
x = [(1-4)/2 = -1.5, (3-4)/2 = -0.5, (4-4) /2 =0, (5-4)/2 = 0.5. (7-4)/2 = 1.5]  
y = [-0.5,0.5,0,-1.5,1.5]  
x平均数：4  
y平均数：0

其次求x/ySD表现下的乘积:  
 x * y = [0.75 , -0.25, 0.00, -0.75, 2.25]

最终通过计算x * y得到值的平均数，得到相关性系数：  
sum(0.75 , -0.25, 0.00, -0.75, 2.25) / 5 = 0.40

r值原理:  
通过x项y项平均值点引出垂线，并在平均数点相交，可以将散点图划分为四个象限。左下角和右上角x/y之积均为正数；而左上角/右下加x/y之积均为负，乘积之和为相关性系数。换言之，相关性系数是同时通过测算x 和 y两个单独变量在各自轴上的分布位置，判断两个变量是否都在相似的分布位置(平均数上/下)。如果x/y值分布均为正/负（均在平均数以上/以下），，即x/y分布位置相同，则两个正象限占主导地位;反之则相反。


相关系数（r）应该在+-1之间  
相关系数越大线性关系越强，当相关系数为1时被称为**完全相关**，即y=+-x的状态，所有点均位于一条直线（SD线）上，因此变量间存在**完全线性关系**。正常情况下，两个变量不会出现完全线性关系的情况。

相关系数仅仅是一个常数而不代表数据分布，即0.80相关性，即不代表有80%的点靠在线上，也不意味着其线性程度是0.40时候的二倍。  
相关系数分级：1.0-0.7强相关 0.7-0.3 部分相关 小于0.3被认为不相关

***相关性系数分布在+-1之间，且为+-1范围内的任意值。当正相关时散点总体方向为斜上，即自变量x增加时因变量y也会一同增加;负相关时则向斜下，即即自变量x增加时因变量y相对减小;***

### 相关系数的特点

1. 相关性系数只是一个纯粹计算出的指标/数字，因此并不会带有任何原始变量下的单位。同时，因为计算相关性系数时使用了标准差单位(SD)对x轴/y轴上的原始数据进行了拟合/转化。x轴/y轴上的数据同时乘或加一个标量数据并不会引起相关性系数的变化。（例如，x/y轴数据同时乘以3，则平均数，离平均数的偏差和方差均增加三倍；在计算方差时此倍数将会被消去；x/y轴同时增加一个标量时，平均数增加7，但是离平均数的偏差不变，方差也不变）
2. 根据相关性系数的计算方法可知，互换变量（x/y和y/x）相关性系数是完全相同的(x * y == y * x)
3. 当出现大量离群点，亦或者数据分布不成线性相关的情况下，相关系数无法完美的描述散点图：离群点的存在会很大程度上拉低相关性系数，甚至使其降至0。而非线性相关的情况下(随着x增加，y值先增后降，类似成年人体重和年龄之间的相关性)，此种情况下，即便两个变量相关，则相关系数亦是0.故，只要可能，则应该通过观察散点图检查/确定离群点和非线性相关：相关系数r仅适用于线性相关情况，而不是一般意义下的相关。

## SD线

相关性数据当中，用于拟合且表示散点图趋势的线被称作**SD线**。SD线穿过对于x/y两个变量的来说平均数的差都为SD的倍数的所有点。该线穿过平均数点，以美横向增加1SD，竖向增加1SD的比例上升。例如坚持人身高和体重的关系，若身高比平均身高多1SD且体重比平均体重多1SD，则此点落在SD线上，而若身高增加1SD而体重增加0.5SD，则不在线上

SD线的斜率是: 上升（+-Y的1SD值） / 前移（X的1SD值）

### 改变SD

散点图中，点形成的形状和点的密集程度均由标准差单位(SD)来决定：两个相关性系数完全相同的数据，因为SD大小的不同，而在散点图中显示的分布不同，SD越小越密集且离SD线越近；反之则相反。这是因为r的计算考察的不是按照绝对值度量集群程度，而是按照相对SD的值而决定。

***相关系数度量点围绕直线的集群的程度，但这只是针对SD而言的***

### 相关系数与距SD线的间距

***如果相关性系数r靠近1，则一个代表点在SD线之上/之下的仅为纵向SD的一小部分地方。如果相关系数r接近0，则一个代表点位于SD线之上/之下一定的量，在大小上大致与纵向SD是可以比较的。横向SD也是相同的***

## 相关性和因果性

***因果性不意味着相关性：相关性系数度量的是变量之间的相互关系，但是相互关系不等于因果关系。计算相关性系数不能帮助理清第三因素的影响***

例如：经检查，学校中儿童识字率和鞋尺寸的大小之间存在相关性，但这不意味着学习新词汇会引起鞋尺寸的变化，而是因为当中存在第三个自变量**年龄**，因为儿童成长学会了更多单词，且需要使用更大尺寸的鞋。

故，在实验中，仅能通过增加内部分组的方式，防止第三因素对相关性系数的影响。

## 和自然/生态话题下的相关性系数

***生态相关往往是基于比率或者平均数的，它们通常用于政治，科学和社会领域，它们更多的倾向夸大相关程度。因为在社会/生态等方面下存在大量的样本，往往宏观下的系数因为在偏性/误差及其他因素的影响下，往往和宏观数据不相符***

例子：通过研究吸烟率（按照人员计算）和肺癌死亡率这两个指标并绘制散点图，可以发现吸烟率（按照人员计算）和肺癌死亡率之间呈现正相关。最终发现吸烟率和肺癌死亡率两个数据呈现正相关，且相关性为0.70。

此类案例中，因为数据检查的人的吸烟率烟率/肺癌死亡率而非国家的吸烟率/肺癌死亡率，故应使用各个国内人员的吸烟率和肺癌死亡率，而非国家级别的吸烟率/肺癌死亡率和相关性系数进行比较。

例2：美国人口调查：受教育程度和收入的相关性：

在统计如此大范围内的数据时，应使用个人的受教育程度和死亡率进行分析：通过收集地理划分下的9个区域中的男性的受教育程度和收入水平的平均数，然后计算9对平均数据之间的相关性。如果仅仅使用每个区域的相关性系数去估计个人维度的相关性系数，则因为区域数据中存在大量数据散步和离群点，必须使用平均数将此部分*脏数据*排除在外。

# 回归

***回归方法描述的是一个变量如何地依赖另一个变量***

***回归线：回归线之于散点图，等同于平均数之于数据变。y关于x的回归线估计了相应于每个x值的y的平均数；在回归线上，平均而言，自变量以平均数为基点，每增加一个SD单位的数据，相应的y则增加 相关系数r * y轴SD个数据的值，这种通过相关系数估算每个x值对应的y的平均数的方法叫做回归方法***

即：y = y_mean + r * x(SD单位值) * y_SD

回归方法中涉及到自变量和因变量双方的SD值：  
x轴/自变量的SD值用于测量x的变动范围，而y轴/因变量的SD值则用于测量Y的变动范围。

## 回归方法与个体数据推断

根据上述定理，当仅仅知道自变量或因变量的时候，一方推断出另外一方；通常，研究人员通过研究求出回归估计，再对数据进行外推，并将回归估计应用于推算新的对象。

例：大学学生SAT数学分数（200-800）和第一年GAP（0-4.0）之间的关系，自变量（SAT数学分数）和因变量（GAP）数据之间的差距：  
SAT_mean = 550,  
SAT_SD = 80  
GAP_mean = 2.6
GAP_SD = 0.6
r = 0.4

若一学生SAT分数为650，求其GAP分数:  
SAT(标准单位下) = (650 - 550) / 80 = 1.25SD  
GAP相对平均数增加的单位 = 0.4 * 1.25SD = 0.5SD,即在SAT现有的数据下，GAP数据应偏离了平均数 0.5个GAP_SD单位  
当SAT分数为650，则其GAP分数应是：2.6 + 0.5 * 0.6 = 2.9

此定理在大多数情况下有效，但是无法用于正确预测离群点下的数据。而且，此类推断得到的数据仅能代表当下状态下数据的结果，适用范围很广。（例中推断的数据仅能用于当前案例，即仅能适用于当前学校内学生，对于外校学生无法进行估计，因为数据差异会很大）

## 使用回归方法预测百分位数

回归方法也可以用于推断/预测百分位数排序：如果通过预测得到百分位数为90%，则说明超过了90%的数据。

回归方法预测百分位时，主要需要在自变量和因变量均服从正态分布的情况下，依据正态分布面积/SD单位换算进行。

例：已知SAT分数及GAP分数均为正态分布，相关性系数r为0.4，当某个学生SAT分数排名为90%，求其GAP分数的百分位数

首先需要确定SAT 百分位数为90%时的所在的标准单位（SD）；通过题目可知，该学生SAT排名(百分数数)为90%。设定90百分数位置标准单位为Z，90%位置据100%位置相差了10%，根据正态分布可知+-Z位置数据占全部数据位置的80%（100%- 10% - 10%）;根据正态表可知，占据80%面积的标准差单位（SD）为+- 1.3SD，即可知x所在位置为1.3SD。通过回归方法可知Y所在位置为0.4*1.3SD，即0.5SD。根据正态表可知+-0.5SD所占面积，最终得到百分位数69%

***此类计算中，SD仅仅用于表示x/y点所在的位置，并未直接参与计算；而相关性系数r值才是计算的关键，百分位排序以正态规则的方式给出标准单位***

***在缺乏任何数据支持的情况下，正常情况下应预测数据为中位数。但是在得到部分具体数据的情况下，可以预测在中位数数据上/下进行浮动（预测一个物理很好的学生的数学成绩 v.s 制陶课程很好的学生的数学成绩）***


## 平均数图

平均数图：将每个自变量中对应的因变量的平均值使用点标出（x,y），并标注出该点所含的样本量的图表被称之为平均数图。

***回归线图是平均数图的光滑形式，如果回归数图正好是一条直线，则回归线和平均数图必然和为一条直线。***

当变量间存在非线性相关的情况时，不应使用回归线而是使用平均数图。

## 回归谬论与均值回归效应

***在所有考试/再考试的情形中，都存在一种现象：第一次考试成绩比较低的对象在第二次考试中分数均会平均提高，而第一次考试成绩较好的学生则会在第二次考试中平均下降。这被称之为回归效应***

1886年英国遗传学家Francis Galton在研究人类身高的时候，发现一个有趣的现象：父母平均身高高于人群平均值的时候，他们孩子的身高会比父母低一点，而父母平均身高低于人群平均值的时候，他们孩子的身高会比父母高一点。也就是说，下一代的身高会向均值“回归”。 Galton称之为“回归平庸”现象。

### 均值回归效应

均值回归效应出现的原因，是因为两此比较测试中测试对象/样本对象得到的分数不尽相同，这有可能是因为试卷中出题的知识点不同，考生当时的状态变化，运气等原因造成的。故从整个样本群体的角度去诠释数据时，数据总会向平均值进行集中，因为最终数据等于：考试观察到的分数 = 实际水平分数 + 机会误差。

从统计学上简单的解释，如果组变量X和Y不是互相独立的，也不是完全线性相关（即相关系数不等于1或-1），且X是自变量，Y是因变量，那么一定有X与其均值距离较远（标准差大），Y与其均值距离较近（标准差小）。所以说，均值回归现象是普遍存在的，距离均值越远，偏差越大，均值回归越明显。另外要说明的是这是一个统计规律，**只适用于群体，不适用于任何特定个体**。

故，根据上述推论可知：样本数据在SD线周围分布并不均匀（不会均匀的分布在SD线的上/下部分），在SD线下部（以X轴为单位），数据分布大量分布在SD线上方；在SD线上部，则存在大量数据分布在SD线下方。而针对回归线，样本数据则会大量分布在回归线的上方和下方。即：从总体数据来看，第一次考试成绩低的数据第二次考试成绩将上升，第一次考试成绩高的，第二次考试成绩将下降。

***回归谬论认为，回归效应出现的原因是因为某些重要的因素引起（未考虑统计学上随机起落的回归现象，造成不恰当的因果推论），而不仅仅是因为围绕直线散布所致***

***那么如何避免均值回归导致的误判呢，首先要认识到这个问题的存在，然后是对于某些指标，可以重复多次测量，取变化的平均值，从统计上尽量消除均值回归的影响。***

## 两条回归线

***回归线和相关性系数的求值方法的不同，导致了针对自变量/因变量的回归线可以画出两条回归线，这两条平均线将分别穿过自变量和因变量的中心***

# 均方根误差

如之前提到，在回归方法中可以使用自变量推算因变量；然而推算出的数据和实际数据间往往存在差距。这双方的差距被称之为**残差**。而经过计算的整个数组的残差，被称之为**均方根误差**。

## 残差

***残差：残差指的是实际因变量和回归线之间的差/上下的垂直距离。残差是使用回归方法进行预测的预测误差的图形表示。在散点图中，每个点都有一个残差，用于表示回归方法带来的误差。***

***残差 = 实际值 - 预测值***

通过对数据组中全部的残差进行均方根计算后得到的简约值，被称之为**回归直线的均方根误差（将所有残差值平方求和，求其均值，再开平方，就得到均方根值）**。

## 均方根误差

***均方根误差指的是：通过回归推算出的Y值/因变量值和实际因变量值之间的差值的平均情况；均方根误差以绝对数，度量了点沿回归线散布的情况；而相关性系数则度量了点沿SD线的散布情况***

均方根误差能提供：一个代表点距回归线的有多远。

***散点图中的点，按照与均方根误差大小相似的残差偏离回归直线（上/下），均方根误差与回归直线之间的关系，相当于标准差于平均数之间的关系***

数据的残差，实质上也**服从正态分布**，即：***68%的点实际分布在回归直线+- 1 均方根误差的范围内，而95%的点分布在回归直线 +- 2 均方根误差的范围内；大部分的数据都适用于此规律***

## 均方根误差的计算

关于自变量x和因变量y的回归直线的均方根误差的计算公式:**(1-r^2)开根号 * y_SD**  
**算式中应使用待预测变量/因变量的SD进行计算**；**因为计算均方根误差时使用了标准单位/SD，故均方根误差存在单位，单位和因变量的单位相同**

通过均方根误差计算可知：如果在r值相对较小的情况下，均方根误差值会相对增大，甚至可能接近/超过标准单位值。故可以论证：当相关性系数相对较小时，数据拟合较差，因为均方根误差较高。另一方面，通过均方根误差也可以了解到回归数据的拟合情况。

## 均方根误差计算的实质

均方根误差计算，实质上将相关性系数和因变量的标准单位两个数据联系在了一起。

**因变量Y的SD度量的是一个代表点在Y轴平均数点延长线之上/之下的距离**。即：如果不考虑自变量x仅用y的总平均数预测y值，则SD实际度量了误差的大致大小。而均方根误差代表了点在平均数之上/之下的距离，均方根误差小一些，因为回归直线更加接近散点。而均方根误差比SD小的精确因子则为 **(1-r^2)开根号** 个单位（即均方根误差是y_SD的(1-r^2)开根号倍）。

当r = +-1 和 r = 0 这三个极端情况下，可以确认均方根精确因子的正确性：  
当 r = +-1 时，自变量x和因变量y完全拟合，且SD线和回归线完全拟合，均向左上/右上延申。在此类情况下，回归线将穿过散点图中全部点且残差为0，且根据均方根误差因子计算公式(1-(+-1)^2)开跟号可推算，此时的均方根误差值为0，符合实际情况。  
当r = 0时，则证明自变量和因变量完全无关，即双方无线性关系。同时此时均方根误差等同于SD。

## 残差图

残差图类似于平均数图，即：保持自变量x位置数据不变，计算并显示x位置对应y值的残差（y值在回归线上下的+-距离）。

**残差图中，残差的平均数为0，且残差图的平均线是水平的（所有向上/向下的趋势都已经从残差中剔除，且表现在回归数当中了）**。

***在多元线性回归中，残差图可以更加灵敏的检查数据是否线性相关：当残差图中大部分数据趋向y轴为0时，残差数量最小，证明数据线性相关，反之则不符合线性相关。***

## 对纵向条形的考察

纵向条形图：在散点图中，根据单位在x轴中选取两个端点(一般为四舍五入为箱中心点的数据，即3.5，4，4.5)制成的条形图，用于确定条形图中含有的点的关系（因为X轴数据可以四舍五入为一个的原因，被设为一个箱）。

***当散点图中，所有纵向条具有相似的散布时，这个散点图会被称之为等方差的***

一般来说，等方差的散点图的残差图，是椭圆形的。检测等方差性的的最好办法，是检测残差图。  
当散点图等方差时，整个回归直线上任意一点的预测误差值相近。

***异方差性：当自变量上升时，因变量值上升，且数据散布同时上升。即无法通过自变量精确推送因变量***  
当散点图为异方差时，散点图的不同地方的回归方法偏离不同的量。  
在此种情况下，回归线的均方根误差仅仅是提供了一些平均误差--对于所有不同的X值。

**假定散点图是等方差的，且残差中没有一定格式，取一窄纵向条形图当中的点，他们的Y值与回归线上的偏差在大小上与均方根误差相近**。

## 纵向条中正态曲线的应用

当纵向条形图是等方差的，且数据厚厚密集于图的中部，而在两边相对稀疏，则可以使用*正态近似*对纵向条进行研究。

***考虑一个橄榄球型散点图中一个窄纵向条形图中的所有点，它的y值是一个新的数据集，新数据集的平均数使用回归方法估计，新SD约等于回归直线的均方根误差。正态近似可以像通常那样，但是需要使用新的平均数和方差***

例:LAST考试分数和第一年成绩之间的关系：  
LAST考试成绩平均数：32，SD：6  
第一学年平均成绩：68，SD：10，r = 0.60

求：当LAST考试成绩等于35分时，第一学年成绩在75分之上的学生占比

题目中在LAST考试为35分的数据部分形成了一个纵向条，为了求出纵向条部分数据中，因变量（第一学年平均成绩）75分以上的数据占比，则需要线算出纵向条选中区域的新平均数和方差后，利用正态近似的方法，求出该点Y值所在SD，并最终换算出Y值所在面积，最后求出Y值之外的面积。

1.计算纵向条区域内y的平均数：  
使用回归方法估计，即通过回归方法算出的该点的Y值，即为此纵向条中Y值数据的平均数：先通过x轴偏离平均数的sd判断Y数据偏离平均数的SD。(35-32)/6 = 0.5SD,x偏移平局数0.5SD，r * SD = 0.6 * 0.5 = 0.3SD，68 + 0.3 * 10 = 71，即新区间Y轴平均值为71。  

2.计算新区间范围的SD:  
新区见的SD值，可以使用均方根误差来代替：(1-0.6^2)开根号 * 10 = 8（通过LAST成绩求第一学年平均成绩，平均成绩为因变量，此处SD选8），即新SD为8。

3.使用新平均数和新SD。计算Y轴上的正态近似以计算百分位数  
(75-71) / 8 = 0.5，即Z = 0.5。由此结合正态表可以推出：+- Z所占总面积的38%，而75分以上面积占31%。

# 回归直线与多元回归

## 回归线的斜率和截距

任何直线都可以用**斜率**和**截距**进行表示，通过计算直线的斜率和截距，可以计算出直线的**直线方程式：y = 斜率 * x + 截距，即：y=mx+b**，回归直线也是直线，故可知：回归直线也可以使用直线方程式进行表示。

对于回归线而言，**斜率**意味着**x每增加一个单位SD，Y相应的平均变化的大小**；根据回归方法可知：自变量增加1个SD，因变量增加r个SD，y = r * x(SD表示) * y_SD + y_mean，故可知回归线的斜率计算为：**斜率 = (r * y_SD) / x_SD**

对于回归线而言，**截距则为X=0时的y预测值**

回归直线中的方程被称之为**回归方程 = (r * y_SD) / x_SD + 截距**

***回归方程是使用自变量x推算因变量y的另外一种方法，但是通过回归方程，研究人员可以通过小样本数据计算一次回归方程后，将数据直接带入到此方程中进行计算，最后得到预测值。***

例：通过受教育水平（年），计算平均收入，求回归公式，和 8/12/16年教育水平下的收入：
平均受教育水平：12年，SD：3.5年  
平均收入：11600美元，SD：10500美元，r = 0.40

1.求回归方程：  

根据回归方程公式可知：y = 斜率 * x + 截距，回归线中斜率等于(r * y_SD) / x_SD = (0.40 * 10500) / 3.5 = 1200美元 / 年，即每增加/减少1年教育收入将增加/减少1200美元。  
已知：截距等于x = 0 时 y的预估量，即受教育水平为0时的平均收入，根据斜率可知：每减少一年教育年限则减少1200美元收入。故，相对平均年龄的12年，当x=0时收入应减少 12 * 1200 = 14400美元；故，当受教育平均市场为0时，收入为 平均收入 - 14400美元 = -2800美元。（或可使用回归方法对数据进行估计，即：(0-12)/3.5 * 0.40 * 10500 + 11600 = -2800）

根据上述计算，回归方程为：y = 1200 * x + (-2800)

2.计算8/12/16年教育水平下的收入

将教育年龄带入回归方程中可得：  
8年教育水平下收入：1200 * 8 + (-2800) = 6800美元  
12年教育水平下收入：1200 * 12 + (-2800) = 11600美元  
16年教育水平下收入：1200 * 16 + (-2800) = 16400美元  

在回归方程的范围内，我们仅仅知道自变量和因变量之间存在**相应的关系**，而不是绝对相关。以上例为例，通过回归方程计算，我们仅仅可以知道受教育水平增加1年，相应的收入增加1200美元。但是针对收入的差异是否是受教育时间影响所产生这一议题，回归方程则无法解释；因为数据中可能混杂了其他原因，例如个人的智力，家庭情况等。这些因素和自变量因素实际混杂在一起，形成了回归方程中的斜率，最终影响了因变量。

针对上述情况，可以通过增加内部观察组的方法进行解决，或者可以通过进行**多元回归**的方法进行计算。

总而言之**在观察研究中，回归直线的斜率和截距都仅是描述性统计量，只能说明观察统计中一个变量的平均数如何与另一个变量的值进行相联系；如果研究者改变了X，则Y不一定/不能使用斜率来预测Y值的对应变化**。

## 最小二乘法

有时，散点图中的点沿着一条直线进行延申（线性关系较高，相关性较强），为了拟合此种情况下的散点图，可以寻找一条直线，保证散点图中的*点到此直线的距离相同(移动这条线将使得直线到散点图中某些点的距离增加，故找到和散点图中全部点距离相同的位置，即是拟合最好的位置)*。这时此直线即为*回归线*。  
为寻找到适合的位置，需要满足两个要求：1.定义一个直线到所有点的平均距离；2.在平均距离附件移动直线，直至平均距离尽可能的小。

针对第一个问题：  
因为此直线将作为回归线，用于使用自变量来推算因变量；故针对因变量/y值来说，点到此线的垂直距离，就是点到线的距离，即是回归方法中的**残差**；**统计学中，定义平均距离一般使用均方根进行**，这些点到回归线的平均距离则可以被视作**均方根误差**。

针对第二个问题：  
为在此点附近移动直线，使得均方根误差最小，**在所有直线中，由x预测y的均方根误差最小的那条直线，被称为回归直线**。  
而回归直线也被称之为**最小二乘直线：将误差平方以计算均方根误差，回归直线使得均方根误差尽可能的小**。

例：列文虎克计算弹簧的长度和负重关系：  
列文虎克通过在一个弹簧上加挂不同重量的砝码，计算出弹簧的长度和负重之间呈线性关系。  
假定弹簧在无负重时长度为b，悬挂x千克重物后长度为y，弹簧本身的材料系数为m。则可知弹簧长度和负重的关系为 y = m * x + b。  
此类实验中，m和b的值均需要使用实验得出，根据实验结果可知：

|重量(千克)|长度(厘米)|
|:---|:---|
|0|439.00|
|2|439.12|
|4|439.21|
|6|439.31|
|8|439.40|
|10|439.50|

因为这些点并未在一条直线上(相关系数为0.99)，穿过这些点的线可以有很多，但最适合的线中，**m和b将使得均方根误差为最小，这被称作最小二乘法，此时的y = m * x + b公式则为回归线**。  
此时数据的m为回归直线的斜率，b为回归直线的截距，这被称作**最小二乘估计**。**最小二乘估计，可以估计回归线的斜率和截距**。

相对于使用描述性统计方法（回归方法）拟合的数据，**使用最小二乘法拟合的数据会更加精准**，因为在正常实验和观察中，总会出现机会误差，导致使用一般拟合方法时存在误差。**使用最小二乘法拟合数据时，会使用到散点图中全部的点进行拟合；且因为取均方根误差最小的数据，则可以将随机误差降到最低**，得到的拟合回归线则会更加精准。

**最小二乘法和回归方法相似，但使用时机不同**。最小二乘法的使用时机则根据计算的实际情况而定。如果数据间相关性较强，可以使用最小二乘法进一步对数据进行更精准的拟合，如果相关性较弱，最小二乘法带来的好处相对较弱，则可直接使用回归方法。

## 回归是否有意义

回归直线可以在任何散点图中进行绘制，但是在计算回归线之前，需要了解：  

1. 变量间的关系是否为非线性关系，如果为非线性关系，则计算回归线会误导研究者。
2. 回归是否有意义：这应该基于数据产生的方式和逻辑进行判断，即因变量是否由自变量产生而产生，或者双方的内在关系。如果因变量和自变量之间没有完全的直接关系，而仅仅是间接关系。则计算回归线/回归方程仅仅会误导研究者，即便在相关性系数相对较强的情况下也是如此（毕竟相关性不同于因果性）

而针对多个影响因素共同影响数据的情况，则可以使用**多元回归**的方式*控制其他变量*。  
在拟合受教育年限和收入时，可以添加E：受教育水平，s：父母地位度量，相关公式则为 y = a + b * E + c * s

# 概率与机会

***统计：小范围样本推理总体；  
概率：通过总体推断下一次出现的小范围样本及其概率***

***机会的频数论，大多可以直接用于能够独立地在同样条件下一次又一次重复的机会过程***

***当某一个基本过程，在相同条件下独立地一次又一次的进行时，某事件的机会给出期望该事件发生的百分数***

例如扔硬币扔出1点的概率一直为六分之一。

机会的两个基本事实：  

1. 机会在0%至100%之间。如果某件事不可能发生，则机会为0%，反之某件事一定发生则机会为100%，一切机会则分布在这两个端点之间。
2. 对某件事的机会等于100%减去其对立时间的机会。如有45%的概率赢，则可推出55%的机会输。

## 终久论点

在随机情况下（保证每次测试均独立/互不影响，即实验对象外形/重量匀称，且每次实验后均将对象归位且打乱顺序），每个实验对象被抽取到的概率时相同的，即每个实验对象被抽取到1次的概率时相同的。无论是哪个分组的实验对象。

例：盒中装有若干外形/重量/手感完全相同，仅颜色（红色/蓝色）不同的塑料球，拿到红球得1分而蓝球不得分，以下哪种情况得分概率最高：  
* 盒中红旗3个蓝球2个  
* 盒中红球30个蓝球20个

两种方案下得分大体相同，因为两个方案中取到红球的概率相同，概率的计算均为：红球数 / 总球数，而不受蓝球/红球客观数量的限制  
这是因为在大量实验的情况下，两个方案抽取到红球的时间相同。第一个方案中，每个球同时被取到1次时，红球在3/5的时候出现，即取出数据的概率为3/5  
在第二个方案中，50个球的情况下，需要大约50次抽取后每个球被抽到1次，而红球将在30/50即3/5的时候被抽取到

***一件事发生机会的大小，将依据一件事发生的机会数 与一件事发生和不发生的机会数之比，即：发生概率 = 发生机会数 / 发生不发生的全部机会数。表示发生和不发生的概率的和为1，因为设想下两个概率的分子之和等同于公共分母***

在计算此类问题的概率时要注意，抽取实验对象后需要归位，保证每次抽取时样本对象完全相同。即取出球并记录后需要将球放回箱中并摇匀。

## 条件概率

***在求多次事件发生的概率中，给定第一次事件发生的条件，且第二次事件发生的概率被设置/基于第一次事件的结果，这种情况被称之为条件概率***

例：在一套52张扑克牌中抽取两张牌，如果第二张牌为红桃A，则得分，问：1.得分概率；2.翻开第一张牌为梅花7，求得分概率

1. 得分概率为 1/52，因为红桃A必定存在在当前牌中，一共存在52个可能的位置，故第二张牌抽取到红桃A的概率为1/52（红桃A出现在第一张牌中出现等同于未抽中）
2. 得分概率为 1/51，因为已确认了第一张牌的花色（并且在第二张牌抽牌时并未将第一张牌放回），即可以推断出在剩余的51张牌中（50张牌+第二张牌）中一定有1张红桃A，故第二张牌为红桃A的概率为1/51

上述例中，问题2中的概率1/51就被称之为**条件概率**，因为问题中被给定了第一次事件的条件，即：第一次为梅花7。统计时可以讨论：**如果**第一次为梅花7**且**第二次为红桃A的概率。  
同时，问题1中1/52则被称之为无条件概率，即没有限定第一次发生事件的概率。

***第二次为红心的概率可用数学公式P(第二次为红心)代替，P为概率/"Probability"缩写；已知第一次抽牌为梅花7，求第二次抽牌为红桃的概率可写为P(第二次抽牌为红桃|第一次抽牌为梅花7)，中间的直线表示"已知"***

## 乘法规则

***乘法规则用于求两个事件同时发生的机会，即两件事一起发生的机会等同于第一次发生的机会乘以已知第一次事件发生情况下第二件事件发生的概率***

例：盒子中存有三个分别印有"R","W","B"字样的卡片。首先从盒中取出一张卡片，之后再取出一张卡片（第一次取出卡片不放回），求第一次取出"R"而第二次取出"W"卡片的概率：

依据乘法规则第一次取出"R"字样卡片的概率为1/3，而第二次取出"W"字样卡片的概率为1/2，两者同时发生的概率为 1/3 * 1/2，即1/6。  
相关理解如下：第一次取出"R"牌的概率为1/3，这1/3的人中再进行一次取牌操作，取到"W"牌的人占1/3概率人中的1/2。  
或可以理解为：600人同时进行操作，其中200人取得了"R"牌，200人再次取牌后仅有100人取得"W"牌，这100人占全部取牌的600人的1/6。

## 独立性

***如果两件事被认定为互相独立，则如果给定第一件事，无论结果如何，第二件事发生的机会不变/不受影响；反之则证明两件事之间不独立***

比较标准的互相独立的事件是**抛硬币**：  
抛一枚硬币两次，两次抛出行为之间就是完全独立的：  
第一次抛出结果为正面不会影响第二次抛出的结果，即：第一次抛出正面的概率为1/2；第二次抛出背面的结果也为1/2；第一次抛出正面而第二次抛出负面的结果，根据乘法规则，则应计为1/2 * 1/2 = 1/4

例：盒中存在标识为"1","2","3"的黑色和"1","2","3"白色卡片各一套，从盒中随机抽取一张票时：  
1.抽取时发现票为黑色，则取出票面编号为"2"的概率为1/3  
2.抽取时发现票面为白色，则取出票面编号为"2"的概率同为1/3  
3.卡片颜色维度和卡片编号两个条件相互独立，因为：取出卡片的颜色不会改变卡片号码，故颜色和号码是相互独立的。

例2：盒中存在标识为"1","2","2"的黑色和"1","1","2"白色卡片各一套，从盒中随机抽取一张票时：  
1.抽取时发现票为黑色，则取出票面编号为"2"的机会变为2/3  
2.抽取时发现票面为白色，则取出票面编号为"2"的概率同为1/3  
3.卡片颜色和编号两个维度不独立，因为：取出卡片的颜色和编号出现的机会有关，即取出票的颜色不同，编号出现的机会也是不同的。

***随机有放回抽取时，各次抽取之间是独立的。不放回抽取时，各次抽取之间是不独立的***

***如果两个事件是独立的，那么两个事件同时发生的机会等同于各自无条件概率的乘积***

例：盒子中放置了5个卡片："1","1","2","2","3"；现在保持**有放回的方式抽取**，出现以下事件的机会为：  
1.第一次抽取为"1",第二次抽取为"2"的机会：2/5 * 2/5  
2.第一次抽取为"2",第二次抽取为"2"的机会：2/5 * 2/5  

当条件变为**无放回抽取**时则：  
1.第一次抽取为"1",第二次抽取为"2"的机会：2/5 * 2/4  
2.第一次抽取为"2",第二次抽取为"2"的机会：2/5 * 1/4

乘法规则这样的概率运算是为了处理机会游戏而创造的，在游戏中，可以在有限条件下进行多次重复的独立事件，但是现实生活中不存在如此完美的条件。  
***机会的数学理论适用于某些场合（条件/误差控制较强的场合）,而在另外一种场合中则会引起谬误***

## 枚举法/列举状态法

***在演算一个事件的机会时，有时枚举出/列出机会过程可能出现的全部状态是十分有用的；如果列出全部状态十分困难，则可以列出部分典型示例***。

例1：投掷*1枚*骰子，出现一个偶数的机会有多高  
使用枚举法时，可以列出全部可能出现的机会过程，此例中，任意投掷一枚筛子得到的机会过程为："1"，"2"，"3"，"4"，"5"，"6"六个点数；其中点数为偶数的机会过程为"2"，"4"，"6"三种。  
故,出现偶数的概率为3/6,即 50%。

例2：投掷*2枚*骰子，出现点数之和为2的情况即机会有多高  
使用枚举法列出所有可能：两个筛子的点数之间出现了笛卡尔积：  
筛子1:1,1,1,1,1,1,2,2,2,2,2,2......  
筛子2:1,2,3,4,5,6,1,2,3,4,5,6......  
最终根据乘法规则，第一此投骰子会有6种机会而第二次投骰子同样存在6种机会（1-6点），这两个骰子事件一起的机会一共有6 * 6 = 36个。  

    1，2，3，4，5，6  (第一次骰子结果)
    1
    2
    3
    4
    5
    6
    (第二次骰子结果)

而，投掷两枚骰子时，出现点数之和为2的情况只有一种，即"1","1"  
故，可知，出现两次骰子点数之和为2的情况的机会为1/36；  
**也可以通过计算乘法规则的方法求出此值，即：第一次投骰子得到1点的机会为1/6，而第二次投出骰子得到1点的机会也为1/6，两次机会相互独立，故两次投掷骰子结果为"1","1"的概率为 1/6 * 1/6 = 1/36***

如果引入第三个骰子，则情况还会再变化，即匹配得到的结果应为6 * 6 * 6= 216

## 加法规则

***加法规则：求两件指定事件中至少有一件发生的机会，先检查是否互斥/互不相容/不可能同时发生(检查是否会重复计算相容部分)，如互斥/互不相容，则可以将两次的机会相加***

### 互不相容事件

***两件指定事件中至少有一件发生的机会：或第一件发生，或第二件发生或两件都发生。其中两件事是否可能同时发生，由事件本身决定：如果两件事的发生互斥，即一件事发生会制止另一件事发生，则两件事不会同时发生***

从洗好的牌中抽出一张牌，这张牌*不可能即是红心又是黑桃*。  
如果为两个骰子投出得到"1","1"的结果这个事件，则不互斥：因为第一个骰子和第二个骰子结果之间相互独立。

例1：在52张扑克牌中，抽取1张牌，抽到红桃的概率是1/4,抽到黑桃的概率是1/4，问：收到红桃或黑桃的概率  
因为抽牌行为中，抽到红桃和抽到黑桃两个事件互斥（不可能同时发生），故相关概率为：1/4+1/4=1/2

例2：在投掷*2个*骰子时，得到*至少*一个1点的概率:  
因为投掷骰子这个事件中，每个骰子事件之间相互独立且互不影响，故无法使用加法规则(两个骰子皆投中1点的可能性会被重复计算)  
根据笛卡尔积可知：第一个骰子投中1点的事件为6，第二个骰子投中1点的事件数为6，而双方都投中1点的事件被重复计算了1次，故最终概率为(6+6-1)/(6 * 6) == 11/36；  
**或直接减去1次重复计算的双方皆为1的概率**：6/36 + 6/36 - 1/36 == 11/36

***何时使用加法规则而何时使用乘法规则，取决于：  
1、将机会过程简化为例1，例2两种情况；  
2、确定需要求出机会的事件  
随后试图将当前事件和已知机会的简单时间相联系，并计算简单事件中发生一次，或全部发生的概率  
当两个事件互斥时，如果想求至少一次发生的机会，则使用加法规则将两个事件的机会加起来  
如果想求全部发生的机会时，使用乘法规则***。

***通俗解释：  
加法法则应用于并列关系的事件  
乘法法则应用于不相干关系的事件  
如果把概率看成某些事件在样本空间中的占比，并规定数字1被分配到这些占比——也就是概率，则每一个概率都是一个小于等于1的实数。  
那么概率的乘法就是“一些事件在样本空间的占比”的乘法，由于所有占比（概率）都小于等于1，  
所以概率乘法是乘得越多其结果越小，这同时意味着某些事件的占比就越来越小了，换言之，它越不可能出现。  
比如：P(AB)=P(A)P(B|A) ，P(AB)实在太小了，小到比P(A)和P(B|A)都要小。如果有人先给出P(A)，要求你把它凑出P(AB)，那么你必须想办法把P(A)“压缩”至P(AB)为止，如此就给P(A)乘以一个小于1的权重让它变小至P(AB)吧。那么这个权重究竟是多少呢？对比P(AB)和P(A)，前者占比之所以比后者小是因为它要求事件A和B同时发生。因此你只需要找出一个占比让A缩至A∩B。现在考察P(B|A)，如果把P(B|A)看成事件B在样本空间A中的占比的话，那么很显然为了找出A与B的重合部分A∩B，你只需要将P(B|A)这一占比乘到P(A)上去。于是有P(AB)=P(A)P(B|A)P(AB)和P(B|A)之所以不一样是因为他们的样本空间不一样(前者是Ω，后者是A)，彼此的占比完全不是一回事。  
至于概率的加法，互斥的事件在样本空间中不重合，所以它们的占比之和可以直接作为几个互斥事件在样本空间的占比***。

***有时通过直接计算难以计算出机会的情况下，可以转换思路，即通过赢的机会 = 100%-输的机会，这一个定律入手，通过计算出每次输的机会/对立的机会再用乘法规则相乘，之后用100%减去结果，即是成功机会***

注意：实验以及计算过程中，所有条件均为理想条件，即骰子完全对称，每次投掷力道相同，且骰子没有灌铅。反之结果机会会有很大不同。

# 二项系数

***二项系数主要用于计算多次相互独立的事件中，某一个特殊事件出现的机会。例如：  
投一枚骰子10次，恰好得到3个1点的机会***

例：盒中存在1红球及9黑球，进行**随机放回**形式的抽取5次后，求恰好有两次取到红球的机会：  
使用枚举法可知，满足条件的形式可为：RRBBB形式，出现此类形式的机会为：1/10 * 1/10 * 9/10 * 9/10 * 9/10，即为(1/10)^2 * (9/10)^3。  
满足条件的另一个形式为BRBRB，出现此形式的机会为：9/10 * 1/10 * 9/10 * 1/10 * 9/10，同样可以被计为(1/10)^2 * (9/10)^3。  
经过实验发现，RRBBB形式和BRBRB形式机会完全相同，实际上每个恰好抽取到2个红球和3个黑球的形式下的机会都是相同的，这是因为抽取到2个红球的RR形式贡献了(1/10)^2的机会，而3个黑球BBB的形式贡献了(9/10)^3的机会，再根据乘法规则，两个形式组之间需要使用乘法连接。故，所有形式机会之和应等同于 *形式的个数 * 公告的机会*。  
而计算每一个2R3B形式的数量，得到的就是形式的个数。  

***二项系数可以计算多次独立事件中，一个固定形式出现的全部次数**  

***一个互相独立的事件中，一个固定形式出现的全部机会 = 二项系数求出的固定形式出现次数 * 成功时的机会^成功事件次数 * 失败时的机会^失败事件次数***

就上例而言，相关等式为 (5*4*3*2*1)/((2*1)*(3*2*1) = 10，即2R3B的格式会有10种搭配，最后等式为 10 * (1/10)^2 * (9/10)^3 = 7%

为了保证总结出的二项系数数据不会特别凌乱，数学家在一个数字前使用 **!表示阶乘/连乘，即这个数字与它前面的所有正整数一起相乘的结果**  
例：4！ = 4 * 3 * 2 * 1 = 24，读作*4阶乘等于24*，其中数学约定 0! = 1  

故，上例公式可以改为 5! /((2!)*(3!)) ，这是将 2R3B排列成一行的所有组合；分子种的5是分母中2和3的和。

例2：4R1B的排列方式组合个数：5！/(4！*1！)

## 二项系数公式

***一个事件在n次中恰好发生k次的机会由以下公式计算n!/(k! * (n-k)!) * P^k * (1-P)^(n-k)  
其中：n为实验次数，k为事件发生的次数，P为任何一次特定的实验时，k事件发生的次数  
使用二项式系数公式的条件为：  
1、n的值必须事先规定  
2、P的值必须对每次实验都是相同的  
3、实验必须是互相独立的***

例：一个骰子掷10次，得到两1点的概率：  
根据条件，每次骰子事件均为独立事件，且规定了总实验的次数，故可以使用二项系数公式：  
n=10,k=2,P=1/6；则二项公式为：10！/(2!*8!) * 1/6^2 * 5/6^(10-2) == 29%  

例2：投一枚骰子，直到出现6点为止，求出现2个1点的概率：  
因未规定事件次数，故无法使用二项系数求解。如果实验次数仅为1次，则实质是求投一次骰子结果为6的机会，以此类推

例3：随机放回的从装有1，1，2，3，4，5六个卡片的何种抽取10次，最后一次抽取前拿掉盒中的5号卡片：  
无法使用二项系数，此实验中实验次数给定，但最后一次实验前要拿掉卡片5，则最后一次抽取的概率将变为1/5而不是之前的1/6，故不能使用二项系数。

# 平均数率

作为互相**独立**的实验，一枚硬币**每次投掷时有50%的概率投出正面，且无论上次实验的结果是什么，故不会出现之前几次/上次投掷的硬币为正面，则下次投掷一定为背面的情况**。  
**补偿对于平均数律不起作用。举例而言，抛了10次硬币之后获得了10次正面，但平均数律并没有对第11次抛掷获得反面的概率进行补偿，它依然是50%**。  
经过大量测试之后，**投到正面的数量理论上等于投到背面的数量**。但实际情况下，因为机会误差出现的原因，**正面数=抛次数的一半+机会误差**；故从结果上看，**抛到正面的次数和期望数（总抛次数的一半）不会相等，且之间数量差距较大，但是和抛的次数的比值/比率差距很小**；这是因为，机会误差随着抛硬币的次数不断积累，故绝对数量会相当的大。而，随着抛硬币的次数进一步增加，则机会误差和总实验次数的比值/比率会相对**变小**。故最终可知：**相对硬币实验的初始部分，随着实验的进行，硬币抛到正面的次数和期望数（总抛次数的一半）的差值将上升，而比率将越发接近期望比率（50%）**

每次投掷硬币，抽到 正面 和 背面 的概率分别是 50%。所以10000次投掷后，我们期望获得5000**左右**的 证明 和5000**左右**的 背面，二者之和等于10000。这就是平均数律，它告诉人们***机会过程的结果是一个随机变量，但它不会偏离平均值太远**8。

**平均数率一般以百分数为措辞重述，尽管数据投出正面的百分率不会刚好是50%，但是在大量实验的基础下，将会尽量向50%的机会靠近**

## 机会过程

***机会过程是指一系列独立重复的随机试验，并且机会过程可以被抽象为盒子模型***。

通过上述实验数据可知，*因为机会误差出现的原因，事件数量会收到机会误差的影响，使其不再完全等同于预期数量*，这被称之为**机会变异**。故，计算机会误差造成的差距数量则至关重要，即计算*机会过程中确定的数据的误差*。在实际生活中，因为出现得机会变异，每次抽样得到得数据结果将不尽相同，有时这将影响到实验得结果；

例1：轮盘赌中输或赢的金额，或者说轮盘赌博本身即是一个机会过程，而赢或输的金额依赖于结果，且互相独立：轮盘再次旋转后，之前的赢家有可能变为输家。  
例2：通过抽样调查的方式，抽取部分选票，选票中民主党人所在的比率；此例中，抽取流程即为随机过程。所以，样本中民主党人的数量由运气绝对，且每个样本中的比率不同，另一个样本中，民主党人所在的比率很有可能出现微量不同。

机会过程控制的主要原则：***盒子模型***  
在所研究的过程（例如抽取选票）与从盒中随机抽取数之间的相似处  
把研究事件中的变异（民主党选民的估计），与从一只盒子中抽取的数之和的机会变异/机会误差之间建立联系。

***机会过程不是随机过程，因为机会过程的试验之间不具有时间相关性。举例而言，在一个盒子中有放回地抽取100次与同时在100个相同的盒子中抽取一次没有任何区别***。

***盒子模型：一个机会过程与从一盒中做抽取，这两者间的类似被称之为盒子模型；这是因为，如果将机会过程事件抽象为从盒中抽取数字之和的机会变异在数学上更加容易分析，许多负责的过程/事件都可以通过这种方法抽象并进行分析处理***。

机会过程和使用二项系数公式计算的数据不相同：**使用二项式系数计算数据时，已经给定了结果，仅仅在求结果出现的机会**。机会过程则在研究**指定条件和次数下出现的结果，和不同结果出现的机会**

## ‍机会变异（机会误差）‍

***机会过程的结果相对于平均值的偏移称为机会误差***。

机会误差可以是绝对误差：  
10000次抛硬币试验获得的头像总数 - 5000

也可以是相对误差：  

    absolute（10000次抛硬币试验获得的头像总数 - 5000）/ 5000

***机会变异告诉我们：  
当抛的次数增加时，头像数与抛的次数的一半之间的差变得较大，但是头像的百分比与50%之间的差异却变得较小。
也即，随着试验次数增加，绝对误差有增大的趋势，而相对误差有减小的趋势。***

## 盒子模型‍

每次抛硬币可以类比成从一个盒子中有放回地抽卡片，这个盒子里只有两张卡片，上面分别写着 0 和 1。

如果用卡片 1 代表头像，则10000次抽取后，所有取得的卡片数字的总和就等于在抛硬币10000次后获得的头像数。
从一个盒子中*有放回地抽取*标有数字的卡片就是一个*机会过程*，而我们关注的随机变量是卡片上数字的和大概有多大。

### 抽得数之和：盒子模型的基本形态

例子：盒子中存在6张卡片【1，2，3，4，5，6】，随机从盒中抽取一些票，求抽取得票总数之和。抽取事件基于**随机放回**步骤：抽取前摇动盒子混匀卡片，抽取时随机取出卡片并记录，抽取后将卡片放回盒子中并摇匀，准备下一次得抽取。  
**有放回**规定了每个抽取事件均为独立事件，即确定了每个抽取事件基于同样调剂，存在相同概率。  

如果，随机有放回得抽取两次，每次抽取1张卡片，求两次抽取卡片得总数之和(第一次3，第二次5，总数为8；第一次3，第二次3，总数为6)存在多种可能，**因此2次抽样数据得到数据加和后得值受机会误差得影响：如果抽取得到得数据为1种情况，则它们得和为一种情况；如果抽样的状态不同，则得到的和也不同**。  
问：从盒中抽取25次，结果之和大概有多大。  
因为每次抽取的卡片不同，而卡片之和也不仅相同，故重复25次抽取的事件10次，最后得到的结果也不尽相同；  
通过计算机重复进行实验可知，数据结果为88，84，80，90，83，78，95，80，89。值的范围从最小的78到最大的95，出现了肉眼可见的分布变化。  
原则上来说，值得变化范围可为25 * 1 直至 25 * 6；而实验中数据的分布范围为75-100。而随机过程则在研究：随着实验次数的继续增加  
1.数据的趋势是否会保持不变  
2.和所在75-100区间的机会为多少  

上例即为大富翁类游戏中常见的一种规则：投一对骰子，根据两个骰子得到的结果之和确定在游戏中前进的步数。掷骰子即可抽象为从盒中取卡片。

### 建立盒子模型

***盒子模型构建的目的，是为了分析机会变异，在构建盒子模型时，有三个基本问题需要先考虑：  
1.什么数字进入盒中  
2.每一种数字有多少张  
3.抽取的次数有多少***

盒子模型的使用：以Nevada赌轮为例：  
Nevada赌轮中存在38个球袋（38个选项）00,0,range(1-36)，除了0，00两个涂有绿色的球袋，其余36个球袋交替涂有红色/黑色两种颜色。旋转转盘并将球放置到盘中，让其落入到38个球袋中，根据打赌的游戏规则确定输赢；  

规则1：猜花色，如果落入红色球袋赢（本金 * 2），落入黑色或绿色球袋则输（失去全部赌注），每次押注1元；  
针对此类问题可以使用盒子模型：  
1.针对盒子内数据：因为模型仅涉及到挣钱和亏钱，则盒中票需标注+-1元  
2.每一类卡片的数量：例子中，18个红色球袋落入1个就算赢，18个黑色球袋和2个绿色球袋落入1个就算输，故应该准备38个卡片，其中18个标注了+1元，20张-1元，即：【18张1元，20张-1元】

就涉及到的机会来说，把1元押在红色球袋就相当于从上述盒子中抽取1张卡片。  

***盒子模型的最大好处，就是可以撇去研究事件中所有不相干的细节，仅仅表示/突出最重要的信息***，例如此例中的赌场，轮盘，荷官等。

求问题：每次押注红色，进行10次，求净利润：  
回到盒子模型中，进行10次赌博相当于有放回在盒子中随机抽取10次（两者均为独立事件且机会均等）。净利润则是这10次抽取的标数之合。  
作为可能的结果，10次抽取结果可为：R,R,R,B,G;R,R,B,B,R（R:Red；B:Black；G:Green）；结果及净利计算如下：

|赌博状态|R|R|R|B|G|R|R|B|B|R|
|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|输/赢钱数|1|1|1|-1|-1|1|1|-1|-1|1|
|净利|1|2|3|2|1|2|3|2|1|2|

根据上述规则：净利润根据抽得卡片标注的金额总额进行计算，得到红色净利润+1，得到绿色合黑色净利润-1；故净利润为2。

规则2：押1元至Nevada轮盘中任意数字，数字出现时赢35元，出现其他数字时输掉押入的1元（这被称之为打1赔35），如果进行100次实验，且每次都花费1元押在数字17上，净利润应是随机放回式的从盒中抽取多少次得到数据之和。  
解析：设定盒子规则：规则中赢得到35元而输得到-1元，故牌面中仅为+35及-1两种；根据规则，只有从38个球袋数字中取到指定的1个数字就算赢，反之37个取到事件被算做输，故牌中存在1个+35牌及37个-1牌：【1张35，37张-1】  
抽取的次数需要合进行实验的次数相同，即为100次，且每次抽取之后需要放回，从而不改变每次实验的机会。

***盒中标明在单次下注中能赢/输的各种不同的金额；  
从盒中抽取的任何一个特定数字的机会必须等于单次下注时赢得那一金额的机会（此处为数学上的赢，赢得一个负金额等价于赌博中输掉这个金额）  
抽取的次数等同于下注参赌的次数  
净利润等于所有卡片标明数据之和***

# 期望值与标准误差

***随机过程中产生的数围绕着数据的期望值进行变化，变化的幅度基本上遵循标准差。  
如果机会过程仅仅产生了一个数据，则此数据将会在期望值和周围大概相差了一个标准误的某处***。

## (机会过程中的)期望值‍

例：从盒【1,1,1,5】中*有放回的随机抽取*100次，求抽得的卡片总数。  
题中使用有放回且随机的方式抽取卡片。故每次抽取卡片的过程均为随机。其中卡片总数为4，包含1个5号及4个1号卡，故单次抽取到1号卡的机会为3/4，而抽取到5号卡的机会为1/4；  
故，100次抽取后，应获得100 * 3/4 = 75张1号卡和 100 * 1/4 = 25张5号卡。故最终分数之和为：25 * 5 + 75 * 1 = 200。  
此时的"200"即是期望值。

***当每次随机有放回的从盒中抽取卡牌时，每次抽取都将抽取一个大约等于盒子中卡片号平均数的量***

故，总结可知：  
***随机放回地从盒子中抽取所得数之和的期望值等于（抽取次数）×（盒平均）  
盒平均数，即单次的平均期望值 = (盒中全部卡片点数之和) / (盒中全部卡牌数)***

上例中，盒平均数 = （1+1+1+5）/4 = 2；故最终，此例中期望值应为：2 * 100 = 200

例2:假如有这样一个盒子：  
【1，1，3，5】

它的盒平均是：  
（1+1+3+5）/ 4 = 2.5

如果做100次抽取，我们期望卡片和为：  
100 × 2.5 = 250 左右。

***机会过程的期望值其实就是之前提到的平均值***。

例3：游玩Keno游戏时，规则上押1元钱有1/4的机会赢且获得2元回报（并收回本金），输一次则失掉本金，求进行100次游戏后的利润。

根据上述规则可建立盒子模型：【-1，-1，-1，+2】，盒平均为：（-1-1-1+2）/4 = -1/4，即每次游玩期望值为-0.25，而100次游玩后应为-25元。

## （机会过程的）‍标准误差/SE‍与平方根法则

***在实际情况下，盒子模型的期望值和实际值并不相等，这是因为存在机会误差的原因，实际盒子模型的最终值应等于 期望值 + 机会误差***。

***‍‍平均数律与‍机会变异定性地描述了机会误差与试验次数之间的关系。而标准误差可以定量地衡量机会误差。  
一个和可能在它的期望值附近，但是偏离一个其大小与标准误差相似的机会误差  
最终值的机会误差和抽取总结果相关***。

为了计算一个抽取中的机会误差，可以使用**平方根公式/平方根法则**:  
***如果随机变量之间是独立的，那么随机变量和的方差等于随机变量方差之和，即: 方差(X+Y) = 方差(X)+方差(Y)  
因为一般情况下，我们使用的都是标准差而非方差，则使用标准差的方式表示上述公式为: 平方根(X+Y) = 平方根(X) + 平方根(Y)***
***而在从装有标上数字的卡片的盒中作随机有放回的抽取时，抽得数之和的标准误差是***：

                平方根(开根号)/SquareRoot ( 抽取次数 ) ×（盒子的SD）

公式由两个部分组成：*抽取次数的平方根* 和 *盒子的SD*；  
这里的机会误差是绝对误差，SD是盒子中卡片数字的标准差，此时的SD用于测量盒子中所有值的散布，显示了数字的离散程度。  
可以看：**出机会误差随着抽取次数的增加而增加，但是增加的速度慢于抽取次数（抽取次数越多，结果更加无法预料，但因为平方根的存在，抽取造成的误差增加速度相对较缓慢）；盒子中卡片的数字差异（SD）越大，机会误差就越大**    
后者不难理解：  
【5，5】，【1，9】  
这两个盒子具有相同的盒平均（等于5），左边的盒子SD=0，无论抽取多少次都没有机会误差。右边盒子SD>0，它具有机会变异的可能。

***平方根法则的原理是互相抵消：每当抽到高于平均数的值时，抽到低于平均数的值的情况也即将发生；  
故，最终误差将被抵消到一定程度，故抽到的数之和相对接近于期望值***。

【标准差SD】 和 【标准误差SE】 不同。前者衡量**一系列数字的离散程度**，后者衡量**机会过程中的机会变异**。


例：针对盒子【0，2，3，4，6】  
有3种抽取方案，分别是抽取25次、100次和500次，每种方案执行100次

盒平均 = （0+2+3+4+6）/ 5 = 3
卡片标准差 = 2

所以三个方案的期望分别是：3*25=75,  3*100=300,  3*500=1500  
所以三个方案的标准误差分别是：squareRoot(25)*2=10,  squareRoot(100)*2=20,  squareRoot(500)*2=44.72

最后分别求出了3种方案平均机会误差的绝对值和相对值。

从结果可看出: ***随着试验次数的增加，机会误差发生变异，变异的趋势是：  
绝对误差增大，相对误差减小。  
并且绝对误差在标准误差附近  
原则上来说，机会过程最后的结果的绝对误差可以为0，而最大可为25 * 6；但大多数情况下不会超过2SE - 3SE***。

## 正态曲线与机会过程

***当实验/事件的次数达到一定程度(充分大)时，可以利用正态曲线计算机会过程之和落在一定范围内的概率***。  
可以发现：***随机过程得到的数据之和符合正态分布，即因每次抽得总数之和的机会误差，数据分布在期望值左右。此时期望值可被视为正态曲线的平均数，而标准误差则充当正态分布中的标准单位的角色***。

根据上述定理可知：***正态分布曲线下的面积即为随机过程数据之和落在指定数据（正态曲线面积的两个端点）下的机会***；  
上述方法一般用于计算**随机过程数据之和在某个指定范围之内的机会，具体步骤为：  
1.基于实际情况设置盒子模型  
2.基于盒子模型中的卡片及面值计算期望值和标准误差  
3.基于期望值和标准误差及范围数据拟合正态曲线，标准单位  
4.基于标准单位拟合正态曲线下的面积，最终计算出在指定范围内的机会**。

例1：针对盒子【0，2，3，4，6】  
抽取25次，求数据在50-100之间的机会。

上例中：  
单次期望值 = (0+2+3+4+6)/5 = 3  
整体期望值 = 3 * 25 = 75
标准差 = 平方根(((0-3)^2 + (2-3)^2 + (3-3)^2 + (4-3)^2 + (6-3)^2)/5) = 2  
标准误差 = 平方根(25) * 2 = 10  
根据提供的要求（50-100范围内的机会）可知，此范围的左右端点为50和100，根据上方计算可知：  
50所在位置的标准单位为(50-75)/10 = -2.5 SD；100所在位置的标准单位为：(100-75)/10 = 2.5 SD；  
根据正态表中数据，+-2.5SD所在正态曲线中面积为99%，即可得出结论:上述例子中的情况，连续进行25次事件的数据和，在50-100范围内的数据应占99%。

***对于标准正态分布，随机变量落在 [-SD, +SD] 范围内的概率是68%，[-2SD, +2SD] 范围内的概率是95%***。

例2：针对盒子【0，2，3，4，6】  
有3种抽取方案，分别是抽取25次、100次和500次，每种方案执行100次

类比上面的第二个方案，期望值是300，标准误差是20，对应的1个标准误差范围是 [280, 320]，2个标准误差范围是 [260, 340]。经过统计，落在 [280, 320] 内的方案执行数是72个，接近68%的比例；落在 [260, 340] 内的方案执行数是96个，接近95%的比例。

例3：Nevada赌轮下，赌徒每次仅将1元押在红色部分上(38个球袋中占据18个球袋)，进行10000赌博，求*庄家*净利润超过250美元的概率。  
根据之前的条件可知：押颜色游戏中，压1元时赢得1元(本金返还)，输时本金不返还；故，根据上述全部规则，盒子模型可为：  
【20个1，18个-1】（**根据上述规则，此时计算得是庄家得净利润，因为庄家和赌徒在此模型内为对头，故庄家赢时赌徒输，故代表得18个黑色和2个白色为赢时得颜色**），  
单次期望值：(1 * 20 - 1 * 18) / 38 = 0.05元，即每次赌博庄家平均赢0.05元  
10000次时间后得期望值：0.05 * 10000 = 500 元  
标准差：1元
标准误差：平方根(10000) * 1 = 100元
利润超过250美元所在得标准单位：(250 - 500)/100 = -2.5 SD  
根据正态表可知：+-2.5所在位置占全部曲线得99%，故之外得位置共占1%左右，而一边占0.5%；故-2.5起始至百分位数100%，共占正态曲线得99.5%。

上例说明了为什么十赌九输的原因：***因为在期望值的净利润为负的情况下，一切赌博的事件的最终净利润都会是负数***。唯一给赌徒的救赎，就是标准误差。

## 输赢仅有两种面值的情况下，计算标准单位/标准差得方法

***当盒中仅有两个面值的卡片（输和赢两种情况下的卡片）时，可以使用一条更加简便的方式计算标准单位/标准差：标准单位/标准差 = (卡较大面值数 - 卡较小面值数) * 平方根(较大面值卡占比 * 较小面值卡占比)***。

例：针对盒【1，1，1，5】，求标准差：  
因盒中票的面值仅有5和1两种，故可以使用次方法求SD：(5-1) * 平方根(1/4 * 3/4) = 1.73

例2：赌徒在赌Nevada赌轮时，每次均花1元押10号球袋上，已知当前规矩为打1赔35（押1元，赢时得35元；输时输掉本金。），求100次游玩后得期望值和误差  
根据上例可建立盒子模型：【1张卡+35元，37张卡-1元】  
故，单次平均期望值：(35 * 1 - 37 * 1)/38 = -0.05元，即平均每次时间赌徒将赢-0.05元（输掉0.05元）  
100次游玩得整体期望值为：100 * (-0.05) = - 5元，即100次游玩后，赌徒将赢得-5元  
因例中盒子模型仅存在两个面值得卡片，故可以使用快捷方法求标准差：(5-1) * 平方根(1/38 * 37/38) = 5.76  
故标准误差应为：平方根(100) * 5.76 = 58元，故赌徒进行100次随机过程后，净利润应为-5 +- 58 元（**大SE给予赌徒赢得更多钱得诱惑，但是也有可能输的更惨**）

## 分组与计数

使用平方根，可以**计算某些随机过程中的数量及其标准误差**，前提条件是需要正确的建立盒子模型。  
***根据需要进行的随机过程中的新条件（针对特定牌面值的计数），应通过修改并建立新的盒子模型的方式模拟新的情况***。

例：投骰子60次，求：1、骰子总数的范围和标准误差；2、6点出现的个数和标准误差；  
根据上例可建立盒子模型：【1，2，3，4，5，6】，  
故平均单次期望值为：(1+2+3+4+5+6)/6 = 3.5  
故60次投掷的期望值为 60  * 3.5 = 210  
经过计算可知：盒中面值标准差/SD为 = 1.71  
故标准误差为：平方根(60) * 1.71 = 13  
故，第一题中，60次掷骰子总数在210上下13左右

针对第二题，应修改之前的盒子模型：题中希望得到骰子投出"6"的次数，根据新的条件可知：一个骰子中仅有一个"6"，而仅有投中"6"可被设置为赢(为了计数，投中"6"可计为1，未投中则投中"6"的次数应不变，即为0)；  
故：新的盒子模型可以修改为：【0，0，0，0，0，1】，即投中1时投中"6"的次数加1，反投中"6"的次数不增加  
此时，单次平均期望值为：(0+0+0+0+0+1)/6 = 1/6，即投6次中会有一次投中"6"点，和投中"6"点的机会相同  
经过60次投掷后的期望值为：60 * 1/6 = 10，即投60次骰子中，会有10次投中"6"点。
此时，因牌面中仅有【1，0】，故可使用快捷方式计算标准差/SD：(1-0) * 平方根(1/6 * 5/6) = 0.37  
故，标准误差为：平方根(60) * 0.37 = 3  
最终可知：投60次骰子中，投中"6"点的次数为10次左右+-3。

**尽管很多机会过程相关的问题看似不同，但是可以使用相同的方法进行解答**：  
就上例而言，问题被分为了2类：  
1.随机从盒中抽取部分票，对抽取到的数据实施运算，并要求返回给定区间内的机会（例：从盒【1，2，3，4，5，6】中随机抽取60次，求总和在200至225之间的机会）  
  **此时抽取一般作为定量数据的来处理，一般可以相加，且对抽取所实施的运算为加法（此次抽取的点数是多少，并加总到总和数量上）**。
2.随机从盒中抽取了若干数量的卡片，求某一个标号卡片出现的次数，及在给定范围内出现的机会（例：从盒【1，2，3，4，5，6】中抽取60次，其中抽得"6"的次数在10-20之间的机会）  
  **此时的抽取是作为定性数据来处理的，对抽取到的数据实施的是分类和计数（每次计算时，在求得是：此次抽取中得到得结果是否为"6"，随后增加抽取"6"的次数）**  
故，***针对相似的问题，可以使用定量/定性；加法/分类计数两个方法，但是从根本上，仅仅需要通过改变盒子模型就可以实现不同方向的计算***。  

***如果必须对抽得的数据进行分类和计数，则可以改变盒子模型；将盒中卡片计为0/1两个类别，其中需要进行计数的卡片计为1而其他卡片计为0***

例：针对抛硬币得到正面的计数：抛硬币100次，1、求得到正面的次数范围；2、和次数在40-60之间的机会。  
根据例题可知，抛硬币共有两个可能结果：正面(赢)和背面(输)，故可设置盒子模型为【1，0】  
根据盒子模型可知：单次抽取到到正面的期望值为(1+0)/2 = 0.5，即每次投硬币，得到正面的次数是0.5次，  
故根据题中100次投掷要求下，得到正面的期望值为：100 * 0.5 = 50，即投掷100次硬币应得到50次正面；  
因盒子模型中仅有【1，0】两个卡面，故次模型可以使用*平方根法则*计算标准差/SD：(1-0) * 平方根(1/2 * 1/2) = 1/2  
故，此模型下的标准误差/SE应为：平方根(100) * 1/2 = 5；  
故综合上述条件可知：投掷100次硬币可得到50次左右+-5的正面；  

同时，根据上述条件可知：40-60次数在此随机过程中形成的正态曲线所在的标准单位为：40：(40-50)/2 = -2SD；60：(60-40)/2 = 2SD；  
根据正态表可知：+-2SD所占正态曲线的面积为95%；故可知：投掷正面次数在140-60的机会为95%；

## 平方根法则与平均数率

***假设抛一枚硬币大量的次数，根据平均数率可知：正面数 = 抛出正面的期望值 + 机会误差；  
根据平方根法则，抛硬币事件中的机会误差 = 平方根(抛硬币次数) * 1/2(抛到正面的SD)  
标准误差随着抛硬币的次数而增加，例如在抛10000次硬币时，标准误差为平方根(10000) * 1/2 = 50；  
当抛硬币的次数增加至1000000时，标准误差同样增加。不过因为计算时使用了平方根的原因，在1000000次抛硬币下，标准误差为 500。  
即：当抛硬币的次数增加时，标准误差/SE的绝对值将越发上涨，但是相对于抛硬币的次数而言，因为进行了平方根计算的原因，标准误差相对减小；  
这就是随着抛硬币次数的增加，抛到正面的比率相对增加且接近期望值50%的原因；平方根法则就是平均数率的数学解释***

# 概率直方图的正态近似

按照平均数率，一枚硬币在被投掷充足的次数后，正面出现的比率应接近50%。此实验是基于以下假设进行的：每次抛硬币都是独立的，且每次抛硬币的结果，即出现正面/背面的机会是均等的。  
基于平均数率可知，在抛出5次硬币时，正面和背面互相存在 2^5=32 个不同的组合，在这32个组合中有20个组合抛到正面的机会接近一半（5次事件中存在2或3次正面）；

根据之前的发现，平均过程可以使用正态曲线进行拟合；而实际上，平均过程拟合正态曲线的过程使用的是平均过程**概率直方图**拟合而成的。通过拟合后的正态曲线，可以计算任意投中正面的情况的机会。

## 概率直方图

如之前所说，直方图存在的意义便是使用面积表示各个分组的占比。概率直方图也不例外。  
***概率直方图表示的是指定箱(Bin)下的总体机会，而不再是绝对值数据***

类似于其他类型的直方图，**概率直方图用面积表示实验中指定组出现的次数占总实验次数的百分比**；  
例：投两个骰子10000次，求每次的点数之和；  
针对前100次投骰子得到的结果，其中投得点数之和为7的次数为20次，占全部100次投骰子的20%；  
故，在针对前100次投骰子事件的概率直方图中，点数7所在的直方图的面积应占20%。  

在经过100次，1000次及10000次事件之后，随着事件次数的上升，每次观察时的经验直方图（由实验观察到的结果绘制的直方图）将逐步收敛成为理想的概率直方图，即在大概率上拟合了对应的正态曲线的概率直方图。

***概率直方图使用面积表示机会，直方图由矩形组成，对于抽得数之和，每一个矩形的底以可能值得中心（例如上例中，可能值为7，则图形底为6.5-7.5的位置），矩形得面积为获得该值得机会，直方图得总面积为100%***。

一般情况下，概率直方图中，每个可能的值为一个单独的箱(Bin)，而每个箱都存在一个指定的占比，即是Y轴对应数据。

## 概率直方图与正态曲线

概率直方图和正态曲线的绘制方法中存在一定不同：根据上方经验可知：概率直方图跟进每个单独的箱和箱对应的占比进行绘制；通过概率直方图及原事件提供的数据可绘制正态曲线，而正态曲线则使用标准单位为底，且Y轴单位为针对每个标准单位所占的百分比形成对象的面积绘制而成（可以使用标准单位/标准误差换算关系搞清每个标准单位下所占的面积）。

通过绘制100次，400次及900次抛硬币得到正面的次数的概率直方图可以发现：直方图和正态曲线的拟合越来越好，从之前的略有锯齿至之后的完全曲线拟合；  
这也正面了平均数率的存在：随着实验次数的上升，数据分布逐渐收敛

## 正态近似：正态曲线推算出现次数机会的逻辑原理

例：1枚硬币抛100次，求正面数：  
1.在45-55之间（含端点）  
2.在45-55之间（不含端点）  
3.恰好为50

针对之前得到的数据可知：  
此例中，100次抛硬币得到头像期望值为50  
此例中标准差为1/2  
此列中标准误差为5

使用概率直方图求解时，问题1：  
问题1可化解为概率直方图中，底数为45-55的箱的面积之和；因为概率直方图和正态曲线之间拟合度很高，则实质等同于求至此段正态曲线的面积。  
而在概率直方图中，箱的面积为底数四舍五入的值（45：44.5-45.5）  
故，此问题所求结果为概率直方图中，底数在44.5至55.5之间的面积  
44.5和55.5，通过转化为标准单位后，数据为-1.1 和 1.1  
故，实质上是在求标准单位-1.1 - 1.1 之间正态曲线的面积  
根据正态表可知,-1.1 - 1.1之间的面积占正态曲线的72.8%，  
故题1结果为72.8%

问题2：不含端点时的45-55之间的（不含端点）机会，等同于概率直方图中46-54之间的直方图的面积；  
即45.5-53.5之间的面积  
等同于+-0.9个标准单位之间的面积  
根据正态表可知，+-0.9个标准单位之间的面积可约等为68%，故题2中机会为63.19%

问题3：正好在点50（期望值）位置的机会，等同于概率直方图中底数为50所在的箱的面积；  
即49.5-50.5之间的面积，换算为标准单位为+-0.1SD  
根据正态表可知，此处面积占7.97%；故最终得数为50时的几率为7.97%

***正态近似，是在计算概率直方图的面积之前，使用正态曲线替换实际概率直方图进行计算的方法；这种替换仅能在概率直方图符合正态曲线时才合理。  
近似的意思是：概率直方图的面积常常难以计算，而正态曲线下的面积则可以使用正态表进行查询***。

**通常情况下，如果问题仅仅要求回答两个点之间的机会，且没有规定端点，则可以直接将机会之和换算成，标准单位后进行正态曲线面积的计算，计算端点得到的机会结果固然精准，但如果矩形面积不大，或没有特意对端点/精度进行要求，则可以使用此种方法近似的得出机会**。

## 正态近似的范围

***针对从盒中抽取的情况，盒中诸数的直方图偏离正态曲越大，则在取近似之前每次事件需要的抽取数就需要越多***

例如【9个0，1个1】，此盒的概率直方图向0倾斜较大，而抽得数据之和的概率直方图也会向0倾斜。  

***当事件重复次数大时，经验直方图可以收敛为概率直方图（抛硬币实验）；当抽取次数大时，和的概率直方图更加接近正态曲线（盒中抽取实验）；因此，当事件的重复次数和抽取次数都大时，和的经验直方图将更加接近正态曲线***。

正态曲线一般与抽取数据之和有关，针对抽取数据之乘积的情况，正态曲线将非常不同；这是因为计算结果成绩的原因，曲线将更加离散，即一些质数将不会包含在曲线当中。而随着事件数量的增加，数据本身的分布将更加极端。

***当使用随机放回的方式在一个盒子模型中进行抽取时，即使盒子所装的票子面值并不遵循正态，但是抽得数据之和的概率直方图必将遵循正态曲线。  
在计算中，直方图必须换算成标准单位，且抽取的次数必须适当大（直到概率直方图完美拟合正态曲线）***  

一般来说，抽取的数量很少有一个确实的**适合大**的标准，因为抽取的数量依赖于盒子中卡片牌面的面值分布。但一般100次抽取得到的概率直方图已经可以很好的拟合对应的正态曲线了。

当概率直方图拟合正态曲线时，正态曲线可以使用期望值（代平均值）和标准误差/SE（代替标准单位/标准差）对曲线进行刻画，因为概率直方图可以完美拟合正态曲线：  
***期望值将概率直方图的中心定在水平轴的指定位置上，而标准误差则确定了概率直方图的散布***。  
而根据之前所知：***使用平方根法则时，期望值和标准误差可以使用以下数据求出：  
抽取次数  
盒平均数/单次抽取平均期望值  
盒SD***
因此，这三个值确定了抽牌结果之和的的行为，即为何盒子的SD成为其散布程度的一个重要度量的理由。

# 抽样调查

调查人员常常需要归纳整个一个个体，这被称之为*总体*。但是针对一个总体的全部进行研究不切实际（内部样本数量太多，消耗太大等）；故，一般情况下，仅仅研究*总体中有代表性的一部分*，这部分就被称之为**样本**。  
而研究人员，根据样本对整体进行归纳，即根据样本对总体进行**推断**。

在调查研究中，通常存在部分关于总体的数值特征，这被称之为**参数**；一般情况下，总体的参数是无法被精确测量的，仅能依据样本进行估计。参数一般由统计量，或者根据样本计算的某些数值进行估计  
只有样本充分代表了总体的时候，根据样本估计参数才是合理的。这可以通过比对样本和总体在某些方面的一致性进行。  
例如，在对美国大选结果预测的研究当中，存在两个参数：  
1.全体合法选民的平均年龄  
2.当前登记投票的全部合法选民的百分数

简单随机抽样/有放回随机抽取的实质：**通过简单随机抽样方法对样本进行抽取，抽取得到的样本中各参数/特性的占比和总体中相同；故可以认为：研究抽取的样本就是研究总体本身**。

## 抽样调查原则

***抽样的程序应该合理，以公平的方式选择样本，以获得具有代表性的横剖面；  
如果在抽样样本阶段，抽样程序将单一/多个类型的样本组合排除在抽样样本之外，则这种系统性的倾向被称之为选择偏性***

例：1936年美国大选，之前屡次正确预测出大选结果的《文学摘要》杂志在此次大选的预测中，出现失误（预测兰登大比例战胜罗斯福，而事实正好相反）  
这是因为《文学摘要》在选取样本时，使用了黄页/俱乐部的电话簿中的地址邮寄了问卷，这样导致穷人/不属于俱乐部的人员被排除在了样本组外，产生了相当大的选择偏性。

故：***当样本的选择存在选择偏性时，抽取一个大的样本对估计总体的情况并无帮助。它只不过会在较大规模下持续重复基本错误***。

同时，针对寄送了问卷的样本对象，也存在***不回答偏性，即存在大量未回答问卷的样本对象；在统计样本数据时，这些人将无法被统计，但是他们实际代表了总体的一个倾向；  
故，不回答者可能和回答者大不相同，当出现高不回答率时，谨防不回答偏倚***。

总体而言，某些样本确实很差，若想了解一个样本是否可取，需要检查获得样本的原因，是否存在选择/不回答偏倚。

***定额抽样：调查人员常常对需要抽取的样本对象赋予固定定额（根据总量中的相关分布），这样样本可以更好的代表总体数据针对研究内容的倾向/特征。  
但是定额抽样会存在一定的无意的偏倚：针对抽样样本的定额划分仅仅基于调查已知的方面进行的划分，但调查中还存在若干之前无法了解到的影响因素（甚至包括调查目的本身分布的影响）  
同时，因为针对定额抽样中，每个定额下的实际样本由抽样人员主管选择，故容易产生偏性（某些特定调查中，调查目样本相对更易接触到，比如大选中，共和党支持者相对富裕，有固定住所/电话）***。

## 使用概率/机会方法抽样

***概率方法设计时，一般针对总体中的每个个体都有相同的概率被抽中进入样本***

在使用机会方法抽样后，使用的样本量和精度（误差）均有了相当的下降，在之前的抽样逻辑中，针对选取的样本进行判断被认为是需要的（例如，定额抽样保证样本中男士的百分比），但随后证明，添加了判断针对预测精度的提升很小，还会产生较大的偏性（抽样人员针对样本的挑选等）；这是因为选择和判断中一般都潜藏有偏性，而机会则不带有任何偏性。故：  
***为了极小化偏性，应使用不带有偏袒性且客观的概率方法选取样本***

### 简单随机抽样

***简单随机抽样：针对总量对象进行 多次(总计划抽样次) 无放回（防止重复抽取）的抽取；在每次抽取时，总量中的全部对象均有相同的概率被抽中  
此种方法可以最大现多的减小抽样中的偏性，且每个对象有相同的概率入选样本，根据平均数率，如果抽取次数充足，则抽取到的投票分布等同于实际总体中的百分比***

简单随机抽样固然可以最大限度的减小偏性，但是针对范围(物理/跨度)较广的事件中（如美国大选），实际难以实施：  
首先需要一份拥有投票权的全部公民名单，其次需要根据抽样的结果加派调查人员实际赴现场进行调查

故，针对某些调查，简单抽样不符合实际情况，而可以使用***多阶段分群抽样***的方法进行调查（结合了定额抽样和简单随机抽样）：***以某些重要的影响因素为划分（大选进行的物理区域），开展多个独立的调查研究，在调查区域中再进行分组，针对分组进行抽样；针对抽样得到的分组再依据调查目的进行分组（大选中的选区），再针对分组进行抽样；再针对抽样结果内的对象进行随机抽样调查***  
使用此类办法，可以在**避免访问人员主管偏性的同时，使用明确且包含随机机会方法**进行抽样

### 多阶段分群抽样的问题及解决办法

即便使用了**多阶段分群抽样**的方法，最大限度的在有判断抽样和无判断随机抽样当中进行了平衡，但是抽样过程中终究会产生一些偏性。  

***不参与活动/不投票者偏性***：在进行抽样/问卷调查时，部分抽样过程中抽得的样本对象不愿参与活动，但是他们可能正常的填写了问卷（例如明知不会参加总统大选投票，但是依旧正常的填写了问卷。因为不参加此类活动，或许对样本对象来说是一种耻辱/丢人/离群）因为实际参与投票的人和未参与投票的人的倾斜可能不同，故针对此类对象，可使用问卷中的一个/多个问题对此类样本对象进行筛选。（类似：是否知晓投票点，上次是否投票）

***未决定者***：在抽样过程中，部分被抽到的对象尚未做出决定。这时，可在问卷中询问做出决定的倾向，而非直接询问最终的决定。还可以使用预先做好的非记名投票材料，在不影响样本对象的情况下（不进行施压）得到正确的结果

***回答偏性***：问卷内的行文方式及抽样调查员本身的态度/语气等外部问题同样可能会影响样本对象的选择（过于晦涩/复杂的问题）。故需要标准化问卷及访问流程，尽量使用不记名问卷/投票的方式进行。且要注意/简化描述/用词/问卷布置方式

***不回答偏性***：并非所有被抽中的样本对象都原因作答，而他们恰恰可能一样会参与活动。故，针对可以访问到但是难于得到回答的对象需要加大权限。

***家庭/群组偏性***：在抽样时，最小样本单位往往不一定是个人，而有可能是某个群体（例如家庭）。而一个群体的内个体的数量往往不相同。故需要对不同群体/家庭的对象设置不同的权重。

***检验数据***:因为某些客观存在的情况（受教育程度和投票倾向），因针对此类问题的权重进行倾斜，即：使用**比估计**方法，客观的为不同群组的样本对象赋予不同的权重。

***针对抽样调查员的控制***:为了证明抽样调查员是否依据流程进行了抽样，可以通过增添一个关于抽样流程的问卷，对此问题进行评估

## 电话调查与网络调查

从客观角度讲，随着电话及互联网的的普及程度的增加，可以使用此类新渠道对进行抽样；且因为不会直接接触抽样人员，也可以避免因抽样人员引起的偏性。  
网络/电话调查同样基于多阶段分群抽样的方式：首先抽取区域（依据电话中区域字段），再从抽得的区域中抽取对象。

要避免在不方便的事件和样本对象进行沟通：吃饭时间等，可以集中在傍晚及周末进行联系。若无人接听，可以重复联系

# 抽样调查中的机会误差

简单抽样调查可以被视作从盒中随机有放回的抽取部分卡片（***标有1/0，代指参数***）。故一样可以视作机会过程。故，一样也存在机会过程中存在的机会误差。  
***样本仅为总体的一部分，故样本的百分比组成成分和总体的百分比组成成分存在稍许不同***  
故对事件参数进行调查可以被视为：盒中抽取到1的百分比 = 盒中1的百分数 + 机会误差 + 事件偏性（在更复杂的情况下）。  
***故，概率样本中的机会误差的大小也一样由标准误差得出***

故，作为机会误差，一般会存在一下三个问题：  
1.机会误差的大小是多少  
2.针对样本大小及总体的依赖程度  
3.为了控制机会误差，样本容量该是多少

***针对一个已知成分的总体进行随机抽样，机会误差所占的百分比依赖于样本容量，而不是总体大小***

## 抽样调查中的随机误差及其百分比

***为计算一个标准误差/SE的百分数占比，则可以先计算出标准误差的绝对值，再换算成样本容量的百分比***

针对一个简单随机抽样模型，可以先尝试将模型抽象成为盒子模型

例:从6672名参与者（3091男，3581女）中抽取100名参与者，求男性人数标准误差的占样本总量的百分比：  
首先建立盒子模型，因目标为男性计数，则抽到男性时+1而抽到女性时男性样本数量不变，故盒子模型应为：【3091个1，3581个0】  
由此可知，单次平均期望值为0.46  
100此抽取后总体的期望值约为46  
有因为盒中仅有两种情况，故可以使用平方根法则求SD，(1-0) * 平方根(0.46 * 0.51) = 0.5
故，100次实验中，会有 平方根(100) * 0.5 = +-5次的标准误差，标准误差量占样本总量的5%

根据平方根定律可知：如果增大抽样/实验次数，则误差出现的次数上升，但是相对误差占比减小：  
接上例，如果抽样次数升为400次，标准误差为 平方根(400) * 0.5 = 2.5%，  
即：**样本容量上升4被，而百分数SE除以 平方根(4) = 2***

***样本容量乘以某一个因子，百分数SE则除以这个因子的平方根（样本总量乘以4，而百分数SE则除以平方根(400)），这个规律对放回抽样是精确的。  
即使针对不放回抽样，只要抽取票子的张数与盒子中票子的总张数相比少的多，则也是个近似值***

***样本中的数据为定量数据，而问题求得的是定性数据时，需要在两者之间进行转换***  
只要将随机抽样当中的实际情况转化为盒子模型，即可使用随机过程对实际抽样实验进行模拟

例：电话公司存在100000个客户，其中仅有20%的客户年收入在五万元以上，问：抽取400此得到收入五万元以上客户的数量，及可能误差的百分比；和抽取样本中18%至20%的为五万以上收入的机会  
首先建立盒子模型，根据要求可知，需要求得抽取的五万以上收入客户的*数量*，故可知，此类问题为计数问题。故盒子模型情况如下：【20000个1，180000个0】  
根据随机过程可知：单次平均期望值为：20000/100000 = 0.2  
根据平方根法则可知，此模型SD为：(1-0) * 平方根(0.2 * 0.8) = 0.4，标准误差为：平方根(400) * 0.4 = 8，即400此抽取的2%  
而400次抽取的最终期望值为 0.2 * 400 = 80。  
故，最终此类问题结果如下：抽取400个客户，应存在80个收入5万之上的客户，误差为+-8个客户，即抽取数量的2%

问题二中，求18% 至 20%为 五万元之上收入的机会  
根据使用的机会过程制作的机会直方图拟合回归曲线可知，  
此回归曲线中，平均值为期望值80，即400个样本中占20%，而标准误差为8，即样本总量的2%  
故题中18%-20%区间即为回归曲线内+-1SD的位置，故，随机至此范围的机会为68%

上例中，通过将全部总体的收入，这个条件转化为*是否大于5万*这个判断条件，成功的将原本的定量数据转化为了定性数据。在建立了定性盒子模型，最终得到了结果。

***使用定量/定性盒子模型的时机：  
使用定性盒子模型时，一般用于将样本值求平均数；  
分类计数后求百分率  
等情况***

## 修正因子

***估计百分数时，决定精度的是样本的决定容量，而不是样本相对总体的比例/大小。这在样本仅占总体很小一部分的情况下依旧正确***。

例：美国大选中，新墨西哥州存在120万合法选民，而德克萨斯州存在1250万合法选民，从两个州各抽取2500名选民作为样本研究投民主党的比例，问两个测试中，**哪个测试机会误差小**。  
答案为：**机会误差一样小**。

针对此问题，可设置两个盒子模型：MN（新墨西哥）与TX（德州）

MN中存在1200000个票，假设此州中投民主党的合法选民占50%，即使用*随机不放回*的方式进行抽样（即简单随机抽样）时，存在约600000个1（民主党）和600000个0；  
调查公司在进行数据估算时，会抽取2500张票，并根据样本总量中的投票情况对总量进行估计，而得到的百分比等于：NM盒子中的百分数 + 机会误差

如果加入德州选民投民主党的比率也为50%，则TX盒子中存在12500000个票。使用*随机不放回*的方式进行抽样（即简单随机抽样）2500卡时，存在约6250000个1（民主党）和6250000个0；  
同样的，调查公司在进行数据估算时，会抽取2500张票，而TX盒子中的得票比率为：TX盒子中的实际百分比 + 机会误差

若针对MN合TX两个盒子进行**有放回的抽取时**，根据平方根定律，两个盒子标准误差相同(因为两个盒子的抽取次数和标准差相同，标准差使用平方根法则时仅考虑盒中面值及几率)  
即 平方根(2500) * (1-0) * 平方根(1/2 * 1/2) = 25，占总样本的25/2500=1%  
故，如果使用随机有放回的方法进行抽样时，两个盒子的标准误差及偏离期望值的比例相同，和盒子大小无关。

同时，根据之前所说，**当样本和总量之比非常小时，每次抽样后对总量内事件的比例的影响很小，故随机有放回抽取的标准误差和随机无放回的标准误差接近**  
而根据上例，当不放回的抽取了1和0的时候，抽得的结果不会大比例的影响盒中1和0卡片的组成和分布。故下次抽取得到1的比例依旧可以约等于50%。  
故此时，有放回抽取和无放回抽取的标准误差相同

根据统计学推断，***当进行了无放回抽取时，每次抽取会使得盒中变的更小，并且略微减弱变异性，故无放回抽取的标准误差要略小于有放回抽取的标准误差。  
相关公式如下：不放回抽取的标准误差 = 修正因子 * 放回抽样时的SE  
而修正因子的公式为：平方((盒中的票数-抽取的票数) / (盒子中的票数-1))  
而，当盒子中的票数相对抽取的票数很大时，修正因子接近于1且可以忽略，  
故，样本的绝对容量通过抽样的SE来决定精度，总体的大小并不重要，而当样本是总体中较大一部分(即需要进行大比例抽取)时，必须使用修正因子***。

通过非数学情景进行比喻：  
***假设从一只瓶子中，取一滴液体进行化验。若液体充分混合，则这一滴液体可以完美反应瓶子整体的成分，而瓶子的大小则无需考虑。  
瓶子中的每一分子对应盒子中的每个卡片；  
液体充分混合且液滴随机抽取，而抽取液滴中的分子数对应抽取样本中的卡片数***。

# 统计推断：百分数的准确性与置信区间

之前的大部分例子中，都在研究概率：即从已知成分的盒子中抽取一定量的元素，求抽取到的对象的机会。  
而有时，则需要根据到手的样本推断出总体的情况，即**统计推断方法-通过样本对象推断总体**，而**通过样本推断得到的总体中存在的某种特性的比例被称之为总体百分数**。  
因为在正常调查研究中*总体百分数*是调查的对象无法天然得到，故可以使用简单随机抽样样本中，特定特性样本所占的百分数（即**样本百分数**）去推断总体中的百分数

***（有放回的）随机抽取对总体的推断的隐藏逻辑：因为使用简单随机抽样的方式抽取到的样本中，数据的分布理应和总体中的数据保持一致；故，样本中的分布/平均/标准差也可以认为说是总体中的相关数据***

例如：美国大选中，调查公司可以通过简单随机抽样或多阶段分层抽样的方法，抽取并了解到美国某个地区的选择民主党人的合法投票人数，及其比例。  
而通过此随机抽样行为，可以推断出总体-即全美合法投票人的投民主党的情况/百分比。而这一切均由盒子模型和随机过程/平方根法则推断出

***当从未知的定性/0-1盒子中进行抽样时，可以使用样本中0/1的比率代替盒子中未知的比率以便估计盒子的SD/SE。当样本量足够充分大的时候，这个方法行得通  
而由于机会误差，样本百分数会偏离总体百分数，样本百分数中的SE将表示偏离的可能大小***

例：学校针对全校25000个学生进行调查，估计住在家中学生的百分比。为了进行此项调查，一共使用**简单随机抽取**的方法了400个学生样本，其中存在317个样本住在家中。求标准误差的百分比。  
根据条件可创建盒子模型【317个1，83个0】  
其中单次抽取期望值为 317/400 = 79.25%  
故盒子模型中的全部期望值为317  
根据平方根法则可知，SD为 (1-0) * 平方根(0.7925 * 0.2075) = 0.41，标准误差则为 平方根(400) * 0.41 = 8   
故，可知标准误差占样本的2%  
根据样本推断可知：总体学校中，约有79%（+-2%）的学生住在家里

## 置信区间

上例中，得到：样本数据中79%（+-2%）的样本对象住在家中。作为随机抽样可知：总体的对象中，也应有79%（+-2%）的对象住在家中。  
因为样本百分数 = 总体百分数 + 标准误差，故总体百分数一般认为在+- 1 SD/SE的范围内，即77% - 81%之中。  
当然，**由于样本误差在可能和不可能之间不存在明显界限**，故总体的百分数也有可能偏离+-1 SD/SE的范畴，但是相关几率会大大降低。

这里，***通过标准误差单位换算的回归曲线下的标准单位圈占的回归曲线的面积换算的比例，被称之为置信区间，而调查总体的置信区间的设置则是根据样本的SE/SD值向样本的期望值左右两侧的平移产生的面积比例得到的；置信水平可从正态曲线读出，但此方法仅能应用于大样本时***。  
例如，根据上例，如果使用+-2SD/SE部分的数据，则总体的百分位数置信水平约为95%的置信区间，即在此区间内有95%的几率在75%-83%的样本区间内获得总体的数据  
***置信区间上的相关比例符合正态分布中的标准单位的分布产生的面积比：  
区间样本的百分数+-1SE是总体百分数的近似68%置信区间  
区间样本的百分数+-2SE是总体百分数的近似95%置信区间  
区间样本的百分数+-3SE是总体百分数的近似99.7%置信区间  
但是没有SE的倍数能给出100%的面积，因为总存在极小的可能性出现很大的机会误差；  
且数学上这一点由正态曲线没有限定范围这一事实反映/体现，即无论所选区间多大，均存在部分面积没有被纳入***。

***置信水平被引述为大约这么一个程度，理由是标准误差已通过数据估计出；另外则是因为使用了正态近似，故不存在严格的判定规则。  
进行的最好方式是：想象总体了样本存在相同的百分比成分，然后试图判定正态近似能否适用于取自对应盒子的抽取数之和  
例如：样本的百分比接近0%或100%表明盒子的成分偏向一边；故接收正态近似之前需要大量抽取  
而如果样本的百分数接近50%，则100次左右的抽取后，正态近似应是相当满意***

例：针对一个拥有25000个合法投票者的镇子进行大选投票检查。使用简单随机抽样的方式抽取了1600份样本后，发现样本中存在917个民主党人，问25000个总体对象中，民主党人所占的百分比（近似95%置信区间）。  
根据题目设置样本的盒子模型为定性盒子模型【917个1,683个0】  
故，单次抽取期望值为917/1600=57%,而整体期望值则为917  
根据平方根法则，此盒子的标准差为：(1-0) * 平方根(0.57 * 0.43) = 0.5，故标准误差为 平方根(1600) * 0.5 = 20，占样本总量的 20/1600 = 1.25%  
根据题目可知，要求总体对象使用95%置信区间，故总体样本中，民主党的比例为 57% +- (2 * 1.25%)

针对学校在家住宿学生的统计进行95%置信区间可以得到：总体的概率为75%-83%，因为总体的概率 = +-2SE + 样本的概率，这可以被称之为：*总体的百分数在75%至83%之间的概率为95%*.  
但在频率理论中，机会表示事务发生次数的百分比，而无论进行多少次调查，学生回家居住的比例是不会改变的（即在75%-83%间，亦或者不在），即***参数不受机会变化的支配***，而实际则无法确定百分比是否落在这个区间里。  
这就是为什么统计学家认为**机会存在于抽样过程之中，而非参数中**。故使用*置信*二字作为提醒（***使用置信陈述而非概率陈述***）。

***置信区间依赖于样本，如果样本不同，则置信区间也不相同***。  
例：雇佣不同的公司研究一个装有红色和黑色球的盒子中，红球所占的比例（所占比例为80%）。每个公司使用简单随机抽取的方法抽得2500个样本进行研究，并使用公式求得“样本中红球百分比 +-2SE”从而计算出红球百分比的95%的置信区间。但是因为抽样的公司不同，导致存在的样本对象不同，故标准误差不同，故每个公司得到的置信区间，中心和长度也不尽相同。某些机构得到的数据覆盖率总体中红球的百分比（95%），而其他公司则没有（5%）

对应某些样本，区间“样本的百分数+-2 SE”*覆盖*了总体的百分数，但是对于其他样本来说，置信区间未覆盖  
故，置信区间+-2SE可被解释为：所有次数抽样样本中的大约95%，区间“样本的百分数+-2SE”能覆盖总体的百分数，另外5%的次数不能覆盖。  
+-2SE的置信区间也可被认为：95%的时候可以覆盖总体中的相关百分数数据，方法是通过针对简单随机抽样的方式抽取并计算样本中相关事件的机会，再在此机会左右取+-2SE的区间。（类似于从装满盒子的区间中随机抽取区间，其中盒子中装有的区间有95%的机会覆盖总体中事件的百分数，而存在5%的机会未覆盖）

***因为机会误差，样本的百分数将偏离总体的百分数，标准误差反馈偏离的误差大小***

***注意：有关简单随机样本的公式仅仅适用于简单随机抽样，对于其他的样本并不适用  
这是因为当前所有的定理的基础为平方根法则，即：仅仅针对每次抽样概率不变的情况。而无论适用放回/非放回的方式进行随机抽样，只要抽取的样本相对总体影响概率较小的话，就可以适用平方根法则  
而针对其他的抽样方法，即样本并非通过随机抽取的方法得到，则抽取中每次抽取样本的机会总在变化（非独立的），故平方根法则不适用，且有可能得到错误的结果***

调查公司不使用简单随机抽样的原因有很多，可能是因为成本问题，但是通过比较可知：大部分情况下，简单随机抽样得到的结果会比其他方法下得到的结果更能反应总体的情况。  
例如盖洛普公司进行的大选调查中应用了多阶段分群抽样，但是每次抽样的结果和最终的得票情况相差依旧较大。  
这是因为调查公司仅仅对可能参与投票的对象进行研究，而进行简单随机抽样时，对象则是全部合法选民。针对盖洛普公司的数据求得的标准误差也无法正常覆盖实际样本中的结果，这是因为盖洛普公司并未使用简单随机抽样。

# 估量就业率与失业率：概率与统计的应用

***失业率是政府发布的最重要的指标之一，而失业率是基于大量的现场人口调查进行的***。

## 现场人口调查设计：研究州级别的人口调查

整个州级别的失业率人口调查集中在每个州之内，目标总体的每个成员都存在相同的机会被选入样本。对于全国来说，抽样比大约为1500：1；而最小的州到最大的州，比例从200：1至2500：1不等。  
而设计的目的，是要求以接近相同的精度估计每个州/自治区中各自的失业人数；这等价51各州中，子样本容量大体相同。因此，各州的样本容量与总体的容量的比率必然存在区别。  
普查中，一般选择16个不同的基本抽样单元，以便交替轮换样本的一部分，以防止长时间多次访问样本对象而不受欢迎，导致出现偏性。

1. **首先确定抽样对象**，即将所有抽样对象（城市/县）分成不同的**抽样群组**，每个抽样群组包含一个市/县或一组相邻的县。继而**对不同的抽样群组分为多个层（基于相近的人口/经济特征；类似人口变化率，农业工人数等）**；层不跨州，且大抽样群组（纽约等）自成一层
2. 在**每个层中抽取一个抽样群组**，抽样时要求层中每个抽样群组被抽中的机会和群组中人口数量相关。而抽样均针对每个层中抽取到的抽样群组进行
3. **每个抽样群组中再划分多个基本抽样单元**，每个单元由4个住房组成。针对这些基本抽样单元进行随机抽取；并研究这些基本抽样单元中**所有年满16岁的人口**

## 调查的实施

使用上述方法，在八十年代末产生了67000个住房单元。其中11000个单元不可取（抽中空/拆毁的住房），另外3000个单元无法利用（无人在家，不配合）。  
故，最终剩下53000个住房单元接受调查。这些单元中，每个16岁之上的成员均被询问有关他们上周工作经历的问题。  
基于回答，总体来说可以分为3类：  
1、受雇的（上周从事任何有报酬的工的人/在某家庭业务中进行15小时工作/离开固定工作的休假者）  
2、失业的（上周没有受雇但可以工作，且过去四周来一直在找工作的人）  
3、劳动之外的人（既非受雇又非失业状态）

针对受雇佣的人，询问关于他们的上班时间和工作类型；  
对于失业的人，询问关于他们的最后职业，何时因何离职，及如果找工作;  
对于那些劳动之外的人，询问他们是否料理家务，或者上学或不能工作，或由于某种原因而不工作

根据定义，民用劳动力包括全部受雇或失业的平民（非军人），根据80年代的普查结果，民用劳动力总数为118.7+6.9 = 125.6百万人  
失业率为失业民用劳动率的百分数，根据上例，80年代的失业率为 6.9/125.6 = 5.5%.  
这个5.5%是所有民众子群失业率的平均数；如果希望对不同民众子群组进行研究，可以在不同维度上设计更多的详细分组（例如年龄，性别，受教育程度，种族，婚姻状况等），然后使用交叉表将数据进行展示。

当一个大的样本被交叉表列表时，在某些分类中可能仅仅保存有一些小的子样本。故，基于此的子总体的推断会变得靠不住。  
但是假设每个估计以概率95%在其真值的1%范围内，对1000个估计来说，它们中的少数几个出现比1%大约多的偏离不足为奇。  
当子样本讲到一定容量阙值时（50左右），这些状态应不再统计

## 样本加权

***加权有助于控制机会变差的影响  
例如样本中存在部分群组的事件机会较低，这样会引起样本总体的事件机会下降，最终引起对总体推断时出现偏性  
故，可以根据总体中相关群组所在的比例进行对此类群组赋予较小的权重，使得样本和总体一致  
另外，如果样本中抽出的某些群体不足时，也需要对这些群组进行加权，以矫正机会变差时引起的不平衡，并减小抽样误差***

假设统计局在所抽的115000个样本中发现了4536个失业的样本对象，而统计局的抽样原则为：1500人中抽1人。  
这很容易被想成样本中的一个人代表1500个总体中的对象，而得出总体中失业的人数约有1500 * 4536 = 680400人。  
但是实际上，统计局需要对分群组对每个样本进行加权（依据年龄，性别，种族，居住位置等）。

## 抽样中的标准误差

美国统计局进行的人口调查，实际存在较大的误差，这是因为他们采用的基本抽样单元是4个毗邻住房的整群。整群中，每个16岁以上的人都会加入样本当中，这存在了相当的偏性：  
生活在统一群组内的人互相类同（家庭背景，学历，就业状况等）。  
若使用了简单随机抽样，则类似的问题很难出现：同时抽中1个人和他的邻居的机会很小。故，每选一个新人进入随机样本中，都会提供另外的，独立于其他样本对象的信息。  
因此，统计局得到的抽样样本所含的信息小于同容量简单随机抽样样本的信息，精确性上有所降低。对于此问题，则需要使用加权的方法进行平衡。

***整群样本比同容量简单随机样本的信息少，因此针对简单随机样本有关的标准差公式不适用此情况***。、

***整群样本的标准误差可以使用半样本法由数据估算出（一种细节复杂，需要大量计算，但是逻辑简单的估算方法），即将样本刨析成两个互相独立且具有相同机会习性的两个部分进行对比，并查看他们多模相符。  
实际上，如果统计局希望了解人口调查的精准程度，可以按照完全相同的方法再进行一次独立的调查；再比对两次调查的结果，但是成本较高，不推荐使用***。

例如：假设调查的一部分民用劳动力为125.5百万，另一部分为125.7百万，差异即为机会误差，而民用劳动力的总体估计为整体的平均数（125.5+125.7）/2， = 125.6百万  
两个分组分别估计偏离他们的平均数0.1百万，故0.1百万为标准误差。

如果基于一次的剖面分析得到的标准误差并不可靠，但是通过使用不同的剖面分析方法并利用取均方根取得标准误差的方式相结合，即可得到更加可靠的结果。  
为了计算标准误差，需要知道样本数据之外的更多问题：数据如何选取。故，针对简单随机抽样方法，存在一个标准误差，而对于整群样本则存在另外一个标准误差。  
***标准误差的公式必须注意考虑用以抽取样本的概率方法的细节，对于方便样本（即不使用概率方法抽取的样本），标准误差一般没有意义***

## 数据的质量

为了控制调查质量。需要标准化整体的调查操作，并且针对参与调查的调查人员，需要进行完备的培训。上岗之后，每月也需要固定数小时的培训。  
另外，约3%的月度样本（概率抽样程序选取）需要由主管人员亲自进行调查。并对存在不符的情况和调查人员重新讨论，并矫正。

## 偏性

偏性比误差更不易察觉，***当偏性多多少少分布在整个样本时，它不能通过仅查看数据检查出，且标准误差对这类偏性可以忽略不记***  
总体来说，偏性的影响是较小的，但是确切大小也是难以估算的。

总的来说，偏性存在以下来源：  
1. 人口调查数据设计基于人口普查数据，而人口普查数据中存在一定缺口（一个难以确定的小百分数）。很难调整失业的估计人数去补足这部分缺口  
2. 不回答偏性：现场人口调查缺失的人可能略有别于他们查找到的人  
3. 定义上相对模糊的部分：定义一定是主观的，"受雇"和"失业"间的界限相对模糊，例如打零工的人会和存在专职工作的人一同分类为受雇人群，尽管他们可能被分类为失业。 

故，失业率中的偏性被认为大于标准误差

# 平均数的精度：通过标准误差计算平均单次抽得数的机会变异

计算单次抽得的平均数和标准误差，可以通过计算指定次数的抽取数的总和与指定次数下的标准误差，再求其平均值即可

例：针对盒子【1，2，3，4，5，6，7】，求25次抽取下，单次抽取的值及其标准误差  
通过题目可知：此盒中单次抽取平均值/期望值为(1+2+3+4+5+6+7)/7 = 4，故25次抽取下期望值为100  
通过计算，盒中平均差为2，故25次抽取的标准误差为 平方根(25) * 2 = 10  
故，25次抽取时，得到的结果为100 +- 10，单次抽取时的结果为 100/25 +- 10/25 = 4 +-0.4  

***当从盒子中进行有放回式的抽取时，盒子的单次抽取的平均数的期望值等于盒子中的平均值；  
抽得的平均数可以用于估算盒子里的平均数，由于机会误差，盒子里的平均数的估计值将会有一定偏离，而SE则表示这些偏离的大小  
盒子的标准误差SE等同于：  
多次抽取的和的SE / 抽取次数***

***当从盒中进行有放回的随机抽取时，抽取的平衡数的概率直方图符合正态曲线，即使盒子里的数值并不如此；  
此时，直方图必须换算成标准单位，且抽取的次数必须充足多  
这是因为：在有足够充值的抽取次数后，盒子抽取数字之和符合正态曲线，而单次抽取的平均数等于和/抽取次数  
这一除法仅仅是在尺度上进行了改变，且会因为使用标准单位计算的原因所抵消***

例2：从盒【1，2，3，4，5，6，7】中随机抽取放回的方式抽取100次，问：单次抽取的平均数/期望值为多少，单次抽取平均数/期望值大于4.2的机会为多少  
根据题目可知：单次平均期望值为(1+2+3+4+5+6+7)/7 = 4，故100次抽取下期望值为400  
通过计算可知：盒子的标准差为2，故100次抽取得到的标准误差为： 平方根(100) * 2 = 20  
故，100次抽取后，抽取数据的和为 400 (+-20)；而单次抽取的平均期望值为：400/100 = 4，而平均标准误差为 20/100 = 0.2  
故：单次抽取的平均值/期望值为 4(+-0.2)  
根据平方根法则可知：标准误差在随机过程中可被视为标准差/标准单位，而单次抽取平均值/期望值则被视为正态曲线中的平均值；  
故，可知：4.2位置所在正态曲线中1SD的位置（(4.2-4.0)/0.2）；而+-1SD位置占正态曲线的68%，而+1SD，小于-1SD位置的面积/机会为32%；  
故，大于4.2/1SD的面积/机会为 32%/2 = 16%

综合例1/例2可知：当抽取次数增加4倍时(100 * 4)，则单次抽取的误差减少2倍（0.4 / 平方根(4) = 0.2）  

***当从一个装有票子的盒子中，随机有放回的抽取时，抽取次数乘以某一因子（例如上例中的4），则抽取平均数的标准误差/SE等同于：  
抽取次数未乘以某一因子的结果 除以 因子的平方根(平方根（4） = 2)。  
故，结合平均数率推断出：抽取次数增大时，抽取卡面之和的平均误差将增加，而平均数的平均误差将减小。  
这是因为：和的标准误差将随着抽取次数增大，而按照抽取次数的平方根增长；尽管标准误差的绝对值将增加，但是因为抽取次数需要经过平方根计算的原因，抽取次数的增长相对较小；  
于是，使用抽取次数相除，使得单次抽取的标准误差下降***。

当使用不放回抽取时，计算标准误差需要乘上修正因子，当抽取次数和盒中票子总数相比相对较小时，修正因子将接近1，则可以忽略乘修正的这一步骤

注：一个盒子中随机有放回的抽取数据，**抽取数据之和的标准误差/SE**为 **平方根(抽取次数) * 盒子SD**；  
故，**在盒子中单次抽取的标准误差为**:**(平方根(抽取次数) * 盒子SD) / 抽取次数**，此公式同时可以简化为：  
**(盒子的SD) / 平方根(抽取次数)**，也可以被简写为 **σ/平方根(n)**，  
此时的σ(Sigma)为盒子的SD，n为抽取次数

## 样本的平均数：从未知盒中中抽取样本，求盒子的单次抽取期望值和标准误差

***针对简单随机抽样样本，样本的SD可以用来估算盒子的SD。当样本容量足够大，则估计将足够好***

例：针对某个城市中存在的25000户家庭进行平均收入的调查，调查机构通过简单随机抽样的方式抽取了900户家庭进行检查  
这900户家庭中平均收入为32400美元，标准差/SD为18000美元，求25000户家庭的平均收入及相关的机会误差

通过题目可知：900户家庭平均收入为32400美元，因为使用了简单随机抽样，则可认为25000户中的平均收入也为32400美元  
根据题目可知，随机抽样等同于建立了25000个样本的盒中模型，盒子中卡片上标注了每户的收入，总共从中抽取了900次  
根据样本/盒中结果可知：**900次抽取的样本**的标准差/SD为18000美元，故盒中**900抽取收入之和的**标准误差为 平方根(900) * 18000 = 540000美元  
故，盒中的**单样本期望值**为32400，而**单样本标准误差**为540000/900=600  
故，总体中25000户家庭的单户期望值应为32400 +-600

问：上例中95%的置信区间的数据范围为多少？  
针对置信区间的问题，类似于定性数据的置信区间，可以使用盒子的平均值定性的推算置信区间。  
针对上例：25000个样本的单次抽取的平均值95%的置信区间，等同于单次抽取的平均值+-2SD/SE，即： 32400 +- 1200

**此时，盒子模型中的SD和SE承担了不同的角色：  
SD指出了一个盒子模型中，抽样结果的分布，即：指出了一个家庭的收入离平均数（一个典型家庭的收入）有多远  
SE则指出样本平均数离总体平均数（一个典型的样本）有多远**

***即使数据全然不遵循正态曲线分布，但是抽得样本的平均数的概率直方图依旧符合正态曲线（当抽取数据充足时，小样本情况下依旧不符合正态曲线）  
这是因为：分布直方图仅仅显示出总体/样本横轴/x轴对应区间下的占比/分布  
而抽取的概率分布直方图指的是：在进行抽取时抽得每个单位的概率，正因为分布不同，所以分布直方图中占比高的地方被抽中的概率高，即为概率分布直方图中面积大的部分，反之亦然  
故，最终的概率分布直方图，在一定充足的抽取次数后，一定符合正态曲线***。

## 机会过程/盒子模型中的SE

从宏观上来说，**标准误差**应该被定义为**机会误差的可能大小**  
**SE表示偏离量的可能大小，它是正/负的数目**

但是针对不同的有放回随机抽取的盒子模型(定性/定量)，SE的具体意义也不仅相同：  
***针对盒子模型中抽取样本之和的SE：平方根(抽取次数) * SD  
针对盒子模型中单次抽取平均数的SE：和的SE/抽取次数(σ/平方根(n))  
针对使用定性盒子模型(0-1盒子模型)中计数的SE：0-1盒子中抽取的和的SE  
百分比的SE：计数的SE/抽取次数  
这当中，针对盒子模型抽取样本之和的SE为所有SE的基础***

## 向前或向后推理

**向前推理**，即当前的情况中，***给出了盒子模型的平均值/期望值和标准差，用以推算总体中数据的情况***  
则可以使用标准差计算出标准误差。**此时盒子平均数的置信区间可以通过使用抽得数据的平均数向左右两侧平移1或多个标准误差来得到；而置信水平可由正态曲线得出（仅限大抽取次数）**

**向后推理**，即：***给出了总体的细节和抽样的具体要求，并要求使用当前的结果自建盒子模型，自行推算盒子模型的期望值，标准差和标准误差***    
在这种情况下，需要使用盒子中抽取的具体结果对数据计算平均值/期望值及标准误差。其中置信区间可根据正态曲线拟合，并使用标准误差作为标准单位求得，即平均值偏离多少个标准误差为偏离多少个标准单位/SD。  
此时的标准误差本身仅仅是标准误差的近似值（通过正态近似拟合时，没有求得概率直方图的端点；但是当样本本身数量相对很大时，误差可以忽略。），但是标准误差的含义相同：假设用样本平均数估计盒平均数，估计产生的平均偏离值。

***注意：当前的所有结论均为通过简单随机抽取的方式进行研究得到的，也仅仅适用于简单随机抽样的情况***

# 机会模型：测量误差模型

## 估计平均数的精度：使用机会的频率理论进行

**频率理论被发展出，用于处理一类非常特殊的问题：在机会游戏中计算可能性  
故，将赌场中的理论应用在赌场之外，需要将现实情况抽象成为赌场中的理想情况  
最终抽象成为盒子模型对实际中的情况进行模拟，这些盒子模型被称为机会模型/随机模型**

**机会误差的来源:任何测量/测量时间均存在机会误差，如果重复进行测试/实验，则机会误差就会出现稍许的不同  
因此，要得到机会误差的大小，最好重复测量若干次。这些测量值的离散程度，由他们的SD进行表示，  
并给出在单次测量中的机会误差的可能大小的一个估计；这被称之为平方根法则，且仅适用于有放回的随机抽取(或样本量比总体相对较小的无放回随机抽样)***。

例：针对标准10克单位进行100次测量，测量结果均不为10克。对测量结果计算可知：测量的标准差为6微克，而测量的平均值不到10克，为10克差404.6微克  
根据上述条件可知：100次测量的标准误差为 平方根(100) * 6 = 60微克，而单次测量平均值的标准误差为 60/100 = 0.6微克  
根据上述结果可知：标准10克单位实际重量为10克以下404.6微克 +- 0.6微克

**计算中产生的6微克和0.6微克的解释如下:  
6微克为标准差/SD，表示单次测量值精确到6微克左右。  
0.6微克为标准误差/SE，即表示100次测量得到的平均数精确到0.6微克左右**。

例2：针对一个砝码进行100次测量，100次测量得到的平均数为1千克又715微克，标准差为80微克，问：  
1.*单次测量值*可能偏离确切重量8微克还是80微克  
2.*100次抽取后*测量平均数可能偏离确切重列8微克还是80微克

1.根据题目可知，所求的为单次测量值的精确程度，即抽样中的标准差，故为80微克  
2.根据题目可知，所求的为100次抽取下的精确程度，即为 (平方根(100) * 80)/100 = 8微克

为了使得整体的估计更加准确，则可以引入置信区间，此例中，95%的置信区间为平均数+-2SE，即:  
1千克之上715毫克+- 2 * 8；即1千克之上699毫克至731毫克

***因为机会过程中存在机会误差的原因，故机会存在于测量过程之中，而不是被测事物当中  
上例中，砝码的确切重量不受机会变异影响；故，影响每次测量结果的条件，为测试过程中产生的机会误差，这证明了上面的推论***

只有进充足多次数的测量时，才可以使用正态曲线来拟合机会过程的概率分布直方图，最终计算出置信区间  
而抽样次数不充足时，概率分布直方图不符合正态分布，故无法使用正态曲线拟合。这时应使用**t_分布**

## 机会模型

针对盒子模型，只有当**总体数据的变异性**和盒子中重复抽取的**样本数据的变异性**想象时，通过整体求出平均数标准误差的方法才是可行的  
故，**如果整个抽取期间，数据呈现一定趋势（例如不放回的抽取使得概率上升）或一定规律模式，则盒子模型不能应用  
这是因为：从盒子里进行抽样时出现的趋势/规律不等于整个样本的趋势/规律  
故：平方根法则仅适用于抽样行为，即取自盒子模型的抽取数**

例：针对一段时间内的国家人口普查数据（20个数据，数据本身逐步上升），求得平均数，标准差/SD和标准误差/SE，这些指标是否有意义  
作为描述统计指标，平均数和标准差存在意义，即：通过描述数据分布的情况概况了数据  
但是标准误差/SE没有实际意义：数据本身并不是通过抽取得到，即和抽取的精度/偏离平均值的偏离度无关（数据本身已提供了精确结果，且数据本身不存在抽样）。

例2：气温模型：针对某地气温，显示出极强的季节性模式：总体来说，夏天气温高，而冬天气温相对较低。即：  
数据本身狭义来说**部分随机**，即在一定时间之内（季节出现变化之前）气温相对随机；总体来说呈现线性回归。  
**这时，数据并非通过盒子模型抽取，而不接受适用平方根法则**

***可以适用平方根法则的数据(盒子模型)一定是随机抽取的数据，这些数据绘图后不呈现任何趋势（上升/回归）仅仅是稀疏的散布在图中***

## 高斯模型

***高斯模型：针对某个量/事件做重复测量，每个测量值于确切值之间相差一个机会误差。这个误差就像从盒子(误差值形成的盒子/误差盒)中进行一次随机抽取一样  
因为这一系列的测量是独立的且在相同条件下进行的，因此每次测量的机会误差值就像从误差盒中随机有放回的抽取一样。
这一模型基于以下两点：机会误差不是系统的取正值或负值，且误差盒中平均数为0***

***在高斯模型中，没测量一次/事件发生一次，就从误差盒中随机有放回的取一张票。票上的数是机会误差。将其加到确切值上将得到最后的测量值。  
误差盒的平均数为0***。

***因为误差盒的平均值为0，故误差盒中的SD可被认为是衡量每次事件/抽样机会误差的标准。  
在使用高斯模型时，可以用一列重复测量的SD来估计误差盒的SD。误差盒的SD表示一次在一次测量中机会误差的可能大小。  
当测量值足够多的时候，这个估计是可用的***。

通常，误差盒中的SD是未知的，以10克标准单位的测量为例，取其测量100次的测量值。  
根据模型，每个测量值在确切值得附近，偏离为取自误差盒中得一次抽取得到得结果：  
第一次测试确切值=确切重量+误差盒第一次抽取得数  
第二次测试确切值=确切重量+误差盒第二次抽取得数  
...
第一百次测试确切值=确切重量+误差盒第一百次抽取得数  

**此例中，因为针对误差盒进行了100次抽取，即进行了足够得抽取/抽样；  
则实际误差盒中的SD可以使用此方法有效的得出**

这当中最重要的问题是：**抽取的数据（确切重量和误差盒抽取数）无法通过实验得到（确切重量是实验的目的）**；  
因为抽取样本中的机会误差等同于总体的机会误差，且测量数据的机会误差是基于机会过程，而非事件/被测目标本身的，故：  
**针对存在大量测量记录/经验的时候，可以使用之前抽得取的样本数据的标准差/SD去推算误差盒的标准差/SD；而此时得标准差也可以代表随机过程的标准误差**

**系列的平均数比起任意一次测试更加精准，相差一个测试次数的平方根组成的因子。这假定了数据符合高斯分布**。

高斯模型中存在的假设是：**测量过程中，测量结果没有被偏性所影响**。  
在出现偏性时，每次测量/事件得到的结果将由三部分组成：确切值+偏度+机会误差  
于是，样本的平均数的SE不再/不仅仅表示样本值得平均数距确切值得距离，而是表示据**确切值+偏度**得距离。  
而，偏度往往很难被发现，同时也很难被计算。

例：在对一个10克标准器具进行100次测量后，得到了测量值得SD为6毫克。在针对另外一个10克标准器具进行了25次测量后发现，这25次测量平均数为10又605毫克克，而测量值得标准差为7毫克  
求第二个标准器具的平均标准误差

根据上述结果可知：因为是针对标准器具进行的检查，大部分偏性已经被考虑在内并被处理，故当前的测量值中仅存在确切值和机会误差  
现在已知，机会误差存在于随机过程之中而不是检测对象当中；故，可根据针对第一个10克标准器具的检测的标准差，求出误差盒的标准差，最后测算出单次的平均误差；  
而不是仅仅使用第二次检查时得到的SD作为误差盒的标准差/SD  

根据题目可知，针对第一个标准器具检测实验的标准差/SD为6，即误差盒的标准差为6。即单次检测时机会误差的大小可能为6。  
而25次平均检查的平均标准误差为：(平方根(25) * 6)/25 = 1.2微克。即，25次测试的平均数的标准误差为1.2毫克。

**统计推断可以通过对数据提出一个明确的的机会模型，而证明其合理性。没有盒子模型，就没有推断**

***被测对象确切值得置信区间，可以通过测量值的平均数向左右适当移动数个SE求得置信水平则是由正态曲线获得（盒子模型适合，且存在充足的抽样次数）  
如果模型不适用，那么获得置信区间的办法也不相同；当数据存在趋势或规律模式时，使用简单随机抽取的置信区间公式的结果将存在较大差距***。

# 遗传学中的机会模型

孟德尔通过豌豆发现基因的故事：使用绿色和黄色两种豌豆，且一株作物可以结出两种颜色豌豆的种子。

首先：独立培养绿色系和黄色系的种子（仅挑选出结绿地/黄色的种子进行下一代的培育），然后将培育出的绿色系和黄色系的种子进行杂交(使用黄色系的花粉杂交绿色系的胚珠，或者反之)。  
结果：第一代的种子全部是黄色，使用第一代种子进行杂交，得到比例为75%黄色，25%绿色的种子。由此，可以证明存在基因：  
如果控制豌豆绿色的基因被称为g,控制豌豆为黄色的基因被称为y，则第一代基因中，yg和gy均显示为黄色，而杂交后第二代的种子中，yy,yg,gy均显示黄色，而仅有gg显示绿色。  
故，y被称作显性基因，g被称作隐性基因

通过统计学角度去观察，孟德尔的实验实质上是在进行盒子模型的抽取实验：  
杂交前的盒子模型为【y,y】和【g,g】，通过随机抽取，得到第一代杂交种子【y,g】  
第一代杂交种子进行杂交时的盒子模型为【y,g】和【y,g】得到的结果为【y,y/y,g/g,y/g,g】，从中随机抽取一个作为豌豆的颜色表达基因，其中抽取到绿色即g,g的概率是1/4，即上面体到的25%

## 孟德尔的遗传模型与机会模型

抛开出现这类情况的原因，孟德尔的遗传学实验中得到的结果不应，也不会完全符合25%-75%的定律，这是因为出现机会误差的缘故（例如基因损坏/突变）。

假如，使用8023个对第二代杂交种子进行实验，因为每次实验类似在盒子模型进行抽取，为了计算这之中的标准误差有多大，可以建立定行盒子模型(仅需要颜色而非显性/隐形基因的盒子模型)【0，0，0，1】  
则单次抽取期望值/平均值1/4，而8023个种子/抽取下，抽取的期望值应位2006  
而8023次抽取的标准误差位为 平方根(8023) * (1-0) * 平方根(1、4 * 3/4) = 38.8  
而根据孟德尔的实验报告，他观察到的结果中，第三代杂交结果基本在25%结果的+-5左右，即在8023次抽取的盒子盒子模型拟合的正态曲线的 5/38.8 = 0.129个SD的位置  
这约等于正态曲线面积的12%，即：88%的情况下，结果将不同于孟德尔的报告

最终可以证明：  
孟德尔运气很好  
或  
数据本身被修正过

## 回归率/平均回归的机会模型

针对高尔顿勋爵发现的平均回归趋势，可以使用简单的机会模型表示

此模型的建立基于两个假设：  
1.身高由一个基因对所控制  
2.控制身高的基因以完全可加的方式起作用：假如模型中，存在4个表示身高的基因变量：h*,h**,h',h''，每个基因都会对身高产生一定不同的影响；当获得其中任意一个基因的时，无论其和其他身高基因结合，其依旧会对身高产生正影响（不同于孟德尔的豌豆颜色，因为显性/隐性基因的缘故，绿色基因是否有效功效要由其结合的基因一同决定；身高控制基因不区分显性隐性，只是不同的基因配合在一起得到的结果/影响不同）

当使用大写H时，则表示基因所带来的影响，例如：h*+h'贡献了 H* + H'的身高

父亲和母亲均拥有一个控制身高的基因，而孩子的身高基因，则从父母那里分别得到。  
假如父亲有一对h*,h** 基因，而母亲有一对h',h''基因，则从父亲处得到h* 的概率为1/2，而从母亲处得到h'的概率为1/2  
因此，父亲对孩子身高的贡献值为：1/2 h* + 1/2h** =1/2 H* + 1/2 H** = 1/2(H* + H**)，即身高的一半；即高尔顿回归系数；  
母亲也相同，即母亲身高的一半  
根据上述结论可以推导出：如果在确定父亲和母亲的身高水平的情况下，孩子的身高水平应等于：1/2 (父亲身高 + 母亲身高)，即父母亲身高的中间数  
考虑到男性和女性之间身高的差距，则可以对女性乘以一个身高系数(8%)，使其身高和男性相同。

但是在实际实验的过程中，会发现部分数据不符合上述模型，这是由于机会误差引起的。即：  
***平均回归模型中，儿子身高不遵循父亲身高的正态分布，是因为从父亲身高基因中抽取出现的机会误差***

# 显著性/假设检验

例：新简化税法法案的假设检验

议员提出了一条新的简化税法的议案，新法案将不会改变国家总体税收的总数。在法案落实之前，为了保证法案的确是不会影响岁入，需要先使用*微型模拟模型*对法案草稿进行检验  
依据提案，针对现有的100000个个税报税单，使用新提案中的逻辑计算出新提案下的纳税金额，并计算出总体税收  
最后求出法案颁布前/后总体税收的差值，即：颁布提案后的总税收 - 颁布前的税收

根据之前的假设，提案本身不应影响总体税收，故**法案颁布前/后总体税收的差值应为0**。

通过随机抽样的方法，从100000个结果中，随机抽取100个结果，得到的100个报税单的法案颁布前/后总体税收的差值的平均值为(-219)，标准差为725

SD和平均数之间的差距过大的原因：  
数据中存在20%左右的无需纳税的申报单，而其余80%的申报单中应纳税金额差异很大(数据分布直方图中为左偏，曲线右边存在长尾)，故SD和平均数差距较大的情况

## 假设检验

***假设检验的基本思想是概率性质的反证法。根据所考察问题的要求提出原假设和备择假设，为了检验原假设是否正确，先假定原假设是正确的情况下，构造一个小概率事件，然后根据抽取的样本去检验这个小概率事件是否发生***。

上例中，通过计算得到了数据的平均值和标准差，只是在针对数据的理解上存在偏差：  
一方认为，数据的平均值存在机会变异，实际数据应在0上；另一方为人，数据可以完整的表示当前的情况，即平均值即是实施法律后的平均值；

为了区分这两种情况，对这两种情况均赋予了相应的专有名词：  
***原假设：即待验假设，假设的期望值，观察到的差异只反映机会变量，即认为平均值仅表现了机会误差；原假设一般使用H0代表  
备择假设：又被称之为对立假设，假设的观察值，即认为观察到的差异是真实的；备择假设一般使用H1代表***

确立原假设与备择假设时应遵循以下两个原则:

1. 原假设是在一次试验中有绝对优势出现的事件，而备择假设在一次试验中不易发生(或几乎不可能发生)的事件。因此，在进行单侧检验时，最好把原假设取为预想结果的反面，即把希望证明的命题放在备择假设上。

2. 将可能犯的严重错误看作第一类错误，因为犯第一类错误的概率可以通过a的大小来控制。犯第二类错误的概率夕是无法控制的。如医生对前来问诊的病人作诊断时，可能会犯“有病看成无病”或者“无病看成有病’的错误，相比较而言，“无病看成有病“的错误更严重，故应将“问诊人有病”

***如果在一次试验中小概率事件竟然发生了，我们就怀疑原假设原假设的正确性，从而拒绝原假设如果在一次试验中小概率事件没有发生，则没有理由怀疑原假设原假设的正确性，因此接受原假设***。

**为了证明原假设的真伪，可以建立一个盒子模型，把原假设和备择假设翻译成有关模型的陈述**：  
原假设认为：盒子模型中的平均数等于0  
备择假设认为：盒子模型中的平均数不等于0

***每一个合理的显著性检验总涉及到一个盒子模型，检验的目的是为了查明一个观察到的差异值是否为真，还是一个机会变异的问题。  
一个真的差异值确实说明了盒子中的某些情况，而不是仅仅抽样一次侥幸成功或失败的反映***。

拒绝域  
能够拒绝原假设的检验统计量的所有可能取值的集合，称为拒绝域；不能够拒绝原假设的检验统计量的所有可能取值的集合称为接受域；根据给定的显著性水平确定的拒绝域的边界值，称为临界值。  
拒绝域就是由显著性水平α所围成的区域。如果利用样本观测结果计算出来的检验统计量的具体数值落在了拒绝域内，就拒绝原假设，否则就不能拒绝原假设  

拒绝域的面积与位置  
拒绝域的大小与人们事先选定的显著性水平有一定关系。在确定了显著性水平α之后，就可以根据α值的大小确定出拒绝域的具体边界值。  
在给定显著性水平后，查统计表就可以得到具体的临界值（也可以直接由Excel中的函数命令计算得到）。将检验统计量的值与临界值进行比较，就可做出拒绝或不拒绝原假设的决策。  
当样本量固定时，拒绝域的面积随着α的减小而减小。α值越小，为拒绝原假设所需要的检验统计量的临界值与原假设的参数值就越远。拒绝域的位置取决于检验是单侧检验还是双侧检验。双侧检验的拒绝域在抽样分布的两侧。而单侧检验中，如果备择假设具有符号“<”，拒绝域位于抽样分布的左侧，称为左侧检验；如果备择假设具有符号“>”，拒绝域位于抽样分布的右侧，称为右侧检验。

## 假设检验/显著性测试的步骤

做假设检验/显著性测试，首先：  
准备好数据，即对数据完成数据清洗工作  
其次：将原假设转为对应的盒子模型，并计算出检验统计量(检验统计量的公式为:(观察值-期望值)/SE，其中期望值的计算应使用盒子模型和原假设一同计算。)  
之后：找到适合的检验统计量的方法（**依赖于模型和所考虑的假设**），并使用方法度量数据和原假设下期望值的差距  
最后：计算所观察到的显著水平值P

上述步骤适用于几乎全部的假设检验模型，不同假设检验的方法的差别，仅仅是针对检验统计量结果的理解。且全部的假设检验模型均可用使用观察到的显著水平值，P值进行理解

**通常，检验的机会值，即观察到的显著水平被称之为P，表示概率；并且常常称为检验的P值**  
由于检验统计量Z依赖于数据，P值也是如此，则P被称为“观察”到的显著水平

***P值（P value）就是当原假设为真时，比所得到的样本观察结果更极端的结果出现的概率。  
P值为小的数值，是推翻原假设的证据，如果P值很小，说明原假设情况的发生的概率很小，而如果出现了，根据小概率原理，我们就有理由拒绝原假设，P值越小，我们拒绝原假设的理由越充分。总之，P值越小，表明结果越显著。但是检验的结果究竟是“显著的”、“中度显著的”还是“高度显著的”需要我们自己根据P值的大小和实际问题来解决***。

***小概率原理是指一个事件的发生概率很小，那么它在一次试验中是几乎不可能发生的，但在多次重复试验中是必然发生的。统计学上，把小概率事件在一次实验中看成是实际不可能发生的事件，一般认为等于或小于0.05或0.01的概率为小概率。***

针对观察到的显著水平P，统计学家认为的将P值进行了实际上的划分，即：P值为多少时，意味着原假设可用证明为有误  
**根据一贯的方法，统计学家将P值分为了三档：  
第一档在5%处，即如果P值小于等于1%，则结果被称为统计高度显著，即原假设被明显证明为小概率事件，故原假设可用确定被拒绝  
第二档在大于1%小于5%处，则结果被称为统计显著，说明较弱的判定结果，故原假设可用被拒绝  
第三档在大于5%处，即被成为统计不显著，说明结果更倾向于接受原假设**

假设检验中P值得逻辑有些反直觉：P值越小说明P值的拒绝域越大，即原假设发生的可能性越低；则原假设被拒绝/认定为否的概率越高

## 检验统计量和显著水平的方法：Z型/σ检验

上例中，争论的重点是100000个数的平均数而不是100个样本的数据，不过使用随机抽样的方式，可以认为100个样本代表了盒子，即100000的数据

为了验证上例中的假设**新税法提案不影响岁入**，即：新税法下的税收 - 旧税法下的税收 = 0  
则可以根据上例内容设置盒子模型：【盒中存在100000张卡片代表报税单，卡片表面写着次报税单在新旧税法下报税的差值】  
从盒中抽取100个卡片/样本，并计算这些样本/卡片上数据的合。如果样本之和为0，则说明假设验证成功。  

根据上述例中抽取的结果来看：抽得100张卡片得到的平均数为(-219),标准差为725  
则计算盒子模型中全部100次抽取的机会误差为 平方根(100) * 725 = 7250(基于平方根定律)  
故，100次单次抽取的平均误差则为72

根据抽取的概率直方图拟合正态曲线(抽取数量足够，可以拟合正态曲线)可知：假设中的新旧提案下的缴税差值，即：0，据当前抽取数据的距离为 (-219-0)/72 = -3 SD/SE  
根据正态表可知：-3SD位置的数据，占全部正态曲线的千分之1。故，可知：在抽样中，平均进行1000次抽样才可得到一个结果为0的样本

结论：  
备择假设无误，如果法案通过，则每个纳税单将平均少交219元

上例是一个***检验统计量***的标准案例：  
通过设立原假设，即认为新旧法案下缴税差异为0，并使用对应的备择假设（差异不为0）来设计盒子模型  
通过计算出的标准误差，计算出了**样本平均数的观察者和期望值之间相差了3个SE**

***检验统计量定义：检验统计量是用于假设检验计算的统计量。在原假设成立的情况下，这项统计量服从一个给定的概率分布，而这在另一种假设下则不然。从而若检验统计量的值落在上述分布的临界值之外，则可认为前述原假设未必正确。统计学中，用于检验假设量是否正确的量。常用的检验统计量有t统计量，Z统计量等***。

***上述使用的检验统计量的方法，被称之为Z/Z检验，是用来度量实际数据与假设之间的差值的  
检验统计量的公式为:(观察值-期望值)/SE，其中期望值的计算应使用盒子模型和原假设一同计算。  
Z表示观察值和期望值之间差多少个标准误差/SE  
因为抽取样本量够大，故可以使用正态曲线拟合数据(概率直方图)，而SE则可以用于求数据的概率，即P值  
期望值总是从原假设出发计算得到的。即：在原假设基础上。Z统一将统计量转化为了标准单位***

当正态近似可以用于抽得平均数得概率直方图时，只要样本合理大就可以使用Z检验(针对小样本，则使用t-检验/t-test)

针对上例：-3SE可得出结论，要取得一个样本平均数小于期望值3倍及以上的SE的概率为千分之一，这类机会被称为**观察到的显著水平**  
***观察得到的显著水平，是得到一个与观察值同样极端或更极端检验统计量的机会。  
机会是在原假设为真的基础上计算出来的。机会越小，则反对原假设的证据越强***

**Z检验得逻辑性：否定论证  
如果原假设为真，则得到一个荒谬的结论，因而必须拒绝原假设  
即：当观察值和期望值之间差多个SE时，原假设必须被拒绝**。

上例中，P值约为1/1000，即：假设原假设为真，调查人员为了验证结果，则需要1千的调查人员进行1次抽样，其中只有1个调查人员得到的检验统计量比当前得到的一样或更加极端。  
故观察到的显著水平越小，则越要拒绝原假设

***检验的P值并未给出原假设为真的机会，P值是在原假设的基础上计算而来的***  
无论抽取多少次，原假设要么为真，要么总是错的。

***上述假设检验被称之为单尾Z检验，此类检验一般用于大数据量下数据下检验统计量显著水平的方法。  
但是，往往当接收的数据不足的情况下，使用多个数据计算的标准误差并不准确。此时则可用使用t检验/t-test***

### 针对0-1盒子/定性盒子的假设检验：Z检验的相关应用

除了上例中使用Z检验对定量盒子中的数据进行检验，在使用定性/0-1盒子的情况下，也可用使用Z检验对数据进行检查

例：为了研究超感觉力/意念力(ESP)，科学家制作了一个机器进行实验，机器中存在一个随机发生器，将随机的抽取4个已有标识中的一个作为目标，但不指示出。  
参与者尝试使用意念力探知机器的选择后，通过选择4个标识对应的按钮做出选择。如果选择正确，即机器和参与者选择了同一个标识，则结果将被记录下来。

通过对15个自称存在意念力的受访者每人进行500次实验后，得到结果：7500次测试中(15 * 500)，存在2006次测试是正确的。根据常识可知，如果不使用意识力，则存在1/4的几率选到正确的结果。根据7500次抽取可知，应存在1875次正确的抽取。相对得到的2006次结果，其中多了131次(2006-1875)的正确抽取。问：此类抽取是否是因为机会误差的影响

使用Z检验时，首先假设产生的131个对象为机会误差所致。此时可以建立定性盒子模型【0，0，0，1】后，针对次盒进行7500次抽取；  
根据随机过程定律可知：此时单次抽取的期望值为1/4，则7500次抽取的期望值为1875  
根据当前盒子模型的情况可以算得：盒子中的SD为(1-0) * 平方根(0.25 * 0.75) = 0.43,故7500次抽取得到的结果为 平方根(7500) * 0.43 = 37，即7500次抽取下的平均误差为37

使用Z检验检验原假设：131/37 = 3.5 SE即拟合的正态曲线中2/1000的面积（根据正态表），对应P值为2%。，统计高度显著，即原假设可确认拒绝  
换句话说：此例中，相比期望值的1875个值，观察值的2006次正确抽取中，多出的131次正确抽取不是因为机会误差的影响。  
但是就上例来说，Z检验也只能得到这样的结论。这是因为，这多出的131个正确抽取仅能证实为不由机会误差引起，而无法证明其是因为意念力引起的。这些多出的正确抽取，可能是因为机器中的随机种子发生器中存在一定规律，或者系统随机抽取一个结果时，出现了一些声音/外形上的规律/暗示，引起了一定偏性

上述盒子模型使用的是0-1/定性盒子模型，且原假设针对的是7500次抽取后得到的结果进行。故**盒子模型中的SE并非单次抽取期望值的平均标准误差，而是7500次抽取的标准误差**  
故：***在进行数据假设检验之前，需要了解检验在观察什么：数据之和，平均数，计数或者百分位数。  
针对定量数据(求和/平均数的情况)，盒子模型中的标准差/SD一般是未知的(税法改革例子中的情况)，需要先通过现有数据(样本)拟合的求出盒子模型中的SD再进行计算。如果原假设给出了盒子的SD，则无需再进行计算；  
针对定性(计数/分类)相关的问题，需要使用0-1盒子模型，原假设常常指的是盒子中1所占的分数。可能直接通过原假设计算盒子中的SD，而不需要通过抽样结果将其估计出来***。

## t-检验/t-test

如同之前提到的，Z检验仅仅适用于大样本量的数据检验。针对小样本量的情况，因为仅有的几个样本无法完全拟合总体中的标准差/SD。  
故，针对小样本量的情况，可以使用t-检验/t-test对数据进行检查。

为了正确调试分光光度器，需要在使用次仪器之前对设备进行调试。具体的方法，就是使用仪器度量一个事先准备好的，已知度数的量标气体。此气体的度数应为70，故当仪器度数显示为70时，则仪器相对正常，否则需要重新调整设备。  
仪器的灵敏度为100PPM/100级，而一般情况下误差为10级。

假定，误差独立且遵循正态分布，某天在使用设备前，对量标气体进行了5次测试，结果为：78，83，68，72，88，问：  
通过这5个度数，可否确认设备存在未完全调整而产生的偏性(需要继续调整)，或者仅仅是因为机会误差的原因造成的结果。

根据题目可知，这次原假设应是设备收机会误差影响产生误差，即设备没有偏性。因为题目中缺少数据，且测试本身仅针对机会误差。故应该使用高斯模型检查仪器得机会误差。  
根据此模型，**每次测量一定数据时，等同于随机从盒中取出一个误差(机会误差) + 设备真值 + 偏性**。  
根据原假设可知：假设中不存在偏性，故设备测量值 = 机会误差 + 设备真值，即测量值 = 70 + 机会误差(平均期望值为70)

如果使用Z检测，则可以计算出5次测试得平均值和标准差，最后计算出标准误差/SE，再通过(观察值(5次测试平均数) - 期望值(70))/SE计算出结果  
但是因为：***测量值得SD仅仅为误差盒子中SD得一个估计，且测量数据量很小，针对SD得估计将不会精准***，即：**存在SD值测量精度低，且概率分布直方图未拟合正态曲线的问题**  

**针对测量样本量小，SD估计不准的问题**：  
如果存在大量得测量数据，可以通过测量数据产生得SD拟合误差盒子的SD。而针对抽取数量较少的情况，则可以使用较多一点的量来估计误差盒子，即在测量值SD的基础上乘上一个增量因子，这被称之为**SD+**：  
***SD+ = 平方根(测量值的个数/(测量值的个数-1)) * 测量值的SD***

**针对使用Z检测(计算P值)得到的数据不再符合正态曲线的问题**:  
一般情况下，得到标准化后的原假设和备择假设之间的差之后，如果抽取数量充足大，则可以使用正态曲线拟合数据。但是因为抽取量小，则在使用t-检验时不能直接拟合正态曲线。  
针对此问题，则可以拟合t-分布曲线/学生分布曲线，并根据已经计算完毕的t值表，计算面积/机会  
**t-分布曲线和正态分布曲线相似，只是在平均数点分布的数据并不像正态分布那么集中。  
如之前提到的，随着抽取的数据量不断提升，则得到的概率分布直方图将进一步贴近正态分布。换句话说，随着样本量的变化，t-分布的曲线也在一同变化，每个样本量将对应一个不同的t-分布曲线。  
这当中的样本量，就被称之为自由度。狭义的定义下，自由度 = 测定的个数 - 1;  
和正态表不同的，t-分布表中，不同自由度下的标准差/标准误差拟合的面积各不相同***。

针对上例中的数据，因仅仅涉及到抽取5次误差盒中的数据，故应该使用t检测验证原假设：  
计算中，误差盒子的SD可以根据抽取的5个例子进行拟合：  
抽取的5个样本的平均值为77.8，而标准差为:7.22  
因为使用的样本较小，需要使用增强SD，即SD+：平方根(5/(5-1)) * 7.22 = 8.07  
则标准误差应为 平方根(5) * 8.07 = 18.06;而平均数的SE(SD)则为18.06/5=3.61

故，最终使用Z检测得到的结果为 (77.8-70)/3.61 = 2.2 SE  
最后使用t分布表进行查看，结果约等于5%左右的面积，即：原假设为真的概率为5%，基本可以推翻原假设；即：抽样数据中存在机会误差之外的值，即偏性。

上例可以抽象为：  
使用随机有放回的方法从一个基本符合正态曲线，均值为0且SD未知的盒子中，抽取了少量票。  
每次抽取中，结果均将加上一个未知常数；原假设认为，未知常数为给定常数C，而备择假设认为，未知常数大于C；  
其中盒子的SD可以使用SD+的方式估算出，并算出SE。则检验统计量为：(抽取数据平均值-C)/SE  
观察得到的显著水平可由t-分布曲线，而不是正态曲线得到  
其中t-分布曲线的自由度使用:抽取数-1进行计算

### t-检测的使用范围

t-分布/学生曲线应应用在：  
1.数据为随机有放回的从盒子模型中所抽得的数  
2.盒子模型中的SD未知  
3.观察个数相对较小，且盒子的SD不能通过已知数据精确的估算出  
4.盒子的值未知，但是分布直方图和正态曲线不能相差太远

针对大量测量值(大于25次测量，最好大于120次测量)，通常可以拟合正态曲线。  
如果盒子的SD已知，且盒子中数据分布符合正态曲线，则可以使用正态曲线进行拟合，无论样本量为多少。

# 双因子/因素假设检验：两个因素差的平均数

之前提到的t-检验和Z检验均为单因素检验，即：**针对一个单一事件进行的假设验证**

而实际工作当中，往往会出现需要比较两个**独立**事件的情况，例如：一段时间内的两次考试的成绩。  
这种时候，就必须使用双因素假设检验进行

## 两个事件的差的期望值与标准误差

**针对两个独立事件，求其期望值的差的情况，两个独立事件的期望值可以相减，而两个独立事件的标准误差可以适用于平方根法则，即为：平方根(SE1^2 + SE2^2)  
其中SE1和SE2分别为事件1和事件2的标准误差**

注：此方法仅能应用于独立事件当中

例: 存在盒A，盒B两个盒子模型，2个盒内情况未知。其中盒A中平均值为110，且SD为60。而盒B中平均值为90，SD为40.  
针对两个盒子进行了不同次数的随机有放回的抽取，盒A进行了400次，而盒B中进行了100次。求：两个样本平均数之间的差的期望值和标准误差

首先，根据盒子模型可知：  
盒A中盒子的期望值为平均数110，盒A 400次抽取的标准误差为 平方根(400) * 60 = 1200，故盒A平均值的标准误差为：1200/400 = 3  
盒B中，盒子的期望值为平均数的90，盒B 100次抽取的平均误差为 平方根(100) * 40 = 400故盒B平均值的标准误差为：400/100 = 4

题目中的目的是：求两个事件平均数的差的期望值，及其标准误差，且根据题目可知：两个盒子均使用使用有放回的方式进行的随机抽取，即两个盒子/事件均为完全独立事件；  
故，两个事件之间差的期望值为两个事件的平均数的差，即：110-90 = 20。针对平均误差，则可以使用上述方法计算独立事件的标准误差：平方根(3^2 + 4^2) = 平方根(25) = 5  
故，两个事件期望值差的期望值为 20 +-5

例1：从盒C【1，2】中随机放回的抽取100此，再从盒D【3，4】中随机放回的抽取100次，问：从盒C中抽取到1的次数和从盒D中抽取到4的次数的差的期望值于标准误差。

根据题目内容可知：两个抽取事件之间互相独立且，两个抽取事件本身抽取也是独立的。故，可以使用平方根法则。  
另，根据题目中要求从盒中抽取指定对象，即可以将原盒转化为0-1/定性盒子进行抽取。即：从盒C【0，1】，盒D【0，1】分别抽取100次，求差的期望值及平均误差

针对两个相同成分的盒子，平均数/期望值是相同的：盒子平均数为(0+1)/2 = 0.5，故100次抽取后的期望值为100 * 0.5 = 50  
两个盒子的SD应为：(1-0) * 平方根(1/2 * 1/2) = 1/2，故两个盒子100次抽取下的标准误差均为 平方根(100) * 1/2 = 5  
根据上述定理计算：两个盒子的差的期望值为：50-50 = 0；而标准误差的期望值为 平方根(5^2 + 5^2) = 7  
故：上例中，两个盒子差的期望值为 0 +-7

例2：随机有放回的从盒【1，2，3，4，5】中抽取100次，问：抽得1的期望值和抽得的期望值的差是否可以使用平方根法则求得。

答无法使用上述方法求得：因为抽取1和抽取5的之前并不互相独立(例如：抽得1的前置条件/机会为抽得结果不为5)，故平方根法则不适用

## 比较两个事件的平均数：双样本/因子Z检测

***双样本的Z检测中，检验统计量应由一下项目共同计算得出：  
1.两个样本的容量  
2.两个样本的平均数  
3.两个样本的SD  
即:(观测值-期望值)/平方根(样本1SD^2+样本2SD^2)
此检验假设这是两个独立的简单随机样本***

例：针对一个学校，在1973年和1982年针对数学科目的考试进行了两次研究，73年的考试中，得分的平均数为55.0，标准差为17.2；而82年的考试中的得分的平均数为51.8，标准差为16.9；问：形成此问题的原因是因为及机会变异还是因为实际成绩的下降。

不同于之前的检验统计量方法(单因子/样本Z检测或t检测)，检验统计量中，作为分母的SE需要考虑到两个样本，而这两个样本均会受到机会误差的影响；  
因此上例中，故：在进行检测统计量的时候，可以参照平方根法则进行

为了对原假设(形成次问题的是机会变异，即：两个盒子的平均数相同，即两个样本的平均数的差的期望值为0)和备择假设(第二次测试结果的平均值缺少低于第一次测试结果的平均值)进行验证，需要设置一个盒子模型。为了简化模型，则假设两次测试均针对学校中17岁学生中进行1000次简单随机抽取的样本进行  
在基于上述假设，则应该建立2个盒子模型：1973年盒子模型和1982年盒子模型，每个盒子中卡片代表一个17岁的学生，而卡片上标识学生的考试成绩；盒中卡片数未知，但是抽取数是已知的：1000次

两个样本的检验统计量值-Z值等同于(观察值-期望值)/SE；其中：观察值为(51.8-55.0)=-3.2，而期望值为0；则分子部分为-3.2  
针对检验统计量使用的分母部分，即模型的SE，因为例中数据实际服从平方根法则（两个样本抽样时互相独立，且使用有放回随机抽取），故此例中，差的SE可以使用平方根法则，从两个盒子的标准误差中求出。

根据题目中的信息：盒A中1000次抽取的SE为：平方根(1000) * 17.2 = 544，则平均数的SE为 544/1000=0.544;  
而盒B中1000次抽取的SE为：平方根(1000) * 16.9 = 534，则平均数的SE为 534/1000=0.534;  
故，两个盒子差的标准误差为 平方根(0.544^2+0.534^2)=0.76  

根据Z检测求检验统计量，结果为：-3.2/0.76 = -4.2 SE。即：82年和73年之间的差低于期望值-4.2个SE。  
因为例中样本量相当大，故可以使用Z检测的方式检测  
故原假设(两个盒子平均数相同)将被拒绝，而保留备择假设。即：平均数上的差是客观存在的

双样本Z检测也可以用于检测两个百分数盒的差:

例3：一个规模较大的大学，分别进行了1次针对男学生和女学生的简单随机抽样。样本容量分别为200，300。抽样结果为：107个样本男生经常使用PC(53.5%)，而女生端为132(44.0%)。问：出现和性别相关的差异的原因，是机会误差还是确有不同。

此例中，原假设为：出现差异的原因是因为机会误差，即：男/女使用PC的百分比相同，男女百分比差异为0；而备择假设则认为：男女百分比存在差异，差不为0。  
针对假设，可以将整个学校的男/女学生**分别**作为盒子模型的建模对象，针对男学生使用PC的情况，可以将全部男生作为卡片放置到盒中，其中使用PC的学生的卡片上标为1，其余为0；女生同理。
故，测试就类似于从男性盒子中抽取200次，从女性盒子重抽取300次。

因为无论男/女盒子中，均由0-1组成，故：可以使用SD计算法，即：  
男盒：(1-0) * 平方根(0.535 * 0.465) = 0.499；200次抽取下盒子的SE为:平方根(200) * 0.499=7，SE所占的百分比为7/200=3.5%  
女盒：(1-0) * 平方根(0.440 * 0.560) = 0.496；300次抽取下盒子的SE为:平方根(300) * 0.496=9，SE所占的百分比为9/300=2.9%  
故，两个盒子的差的SE为 平方根(3.5%^2 + 2.9%^2)=4.5%(SE)  

针对上述条件：备择假设为53.5%-44.0%=9.5%，而原假设认为差为0，SE为4.5，则使用Z检测下的检验统计量为：  
(9.5%-0)/4.5% = 2.1，根据正态曲线可知：可能性<5%，故原假设将被拒绝，即:男女使用PC的百分比存在差异

## 实验中的双样本K检测比较

在实验中，同样也可以使用双样本K检测的方式去验证实验中提出的假设

注意：**观察**和**实验**是不同的，在观察中，分组由对象自主进行；而实验中，分组则由第三方统筹进行。  
故，在使用K检验进行数据统计时，情况将和一般的盒子模型有所不同：  
**通过条件筛选出的对象，将被认为分配给实验组或者对照组，这时实验组和对照组的对象实际并不互相独立，即：如果被选为实验组则不会被选为对照组。但是这种情况下，实际依然可以适用K检测**

***有一盒票，票上针对实验组和对照组标定了不同的数据，而两个数据仅有一个能被观察到（当票被分到指定组时）。  
当随机不放回的从中选取一些票以观察实验的反应，将留下的票作为第二样本对照组进行观察；此时，两个组间平均数的标准误差的计算可以保守估计为：  
1.随机放回基础上计算的两个组的各自的标准误差/SE  
2.像样本是相互独立那样将两个标准误差一同使用平方根法则计算差的标准误差***

例：针对为维生素C是否可以防治感冒的实验。实验共有200名实验对象，将随机的将实验对象*等分*为实验组(提供维生素C)和对照组(提供等量安慰剂)；  
实验结果可知：实验组中，得感冒的次数的平均值为2.3次，标准差为3.1次；而对照组中，得感冒得次数得平均数为2.6次，而标准差为2.9次。问：维生素C是否可以防治感冒。即：使用维生素C的组的平均值是否真正低于对照组，而不是因为机会变量引起。

上述例题中，原假设应定为：维生素C对感冒无效，而实验组和对照组的平均值应相同。而备择假设则为:两组之间的平均数不同。  
实验组的标准误差应为: 平方根(100) * 3.1 = 31，而抽得平均数得标准误差为 31/100 = 0.31；  
对照组得标准误差应为:平方根(100) * 2.6 = 26，而抽得平均数得标准误差为 23/100 = 0.26；  
故，根据上述结果可知：检验统计量得分子为 (2.3-2.6) - 0(原假设)  = -0.3；而分母SE则应为两个事件的SE，根据平方根法则应为: 平方根(0.31^2+0.26^2) = 0.42。  
故，此时的检验统计量计算应为: -0.3/0.42 = -0.7；原假设为真的机会较高；原因可能是存在大量容易患感冒的样本对象被分至对照组。

使用检验统计量之前，均会要求样本是**独立且随机有放回的**从盒子中取出。上例中的实际情况并不遵循这一要求。因为上例中，实验组和对照组实质上是通过随机无放回的被抽取的。因此，抽取是不放回的，而样本间实际上是相依的(针对一个易患感冒的对象，若被选为实验组则不会被选为对照组，而这会影响两个平均数)。但是，即便出现了此问题，依旧可以直接计算出SE，这和盒子模型的选取有关。  
盒子模型中的两个组，使用的是随机分配的形式构成，每个被分组的样本可以被视盒子中的票，而票上实质存在两个数，一个表示针对实验组，即针对维生素C的反应，而另外一个表示针对对照组的安慰剂的反应。  
这两个数字，只有一个可以观察到(因为实验组和对照组二者取其一)

从这些票中，随机不放回的抽取一些票，观察其对应实验组的数据，则这些票应被标识为实验组；之后随机不放回的抽取一些票，如果观察的是安慰剂相关的反应，则应被记为对照组。  
上例中，全部的200个样本，不是被抽取为实验组就是被抽取为对照组；故，第二个样本就可以被视为第一个样本抽取后盒子中剩余的票。

题中原假设认为：两种处理的平均反应相同，为了验证原假设，需要比较两组的平均值：实验组平均值-对照组平均值及其对应为多少个SE单位。可以存在的问题：  
**1.抽取是不放回的，但是两个SE应基于互相独立的样本进行计算，即又放回随机抽取  
2.两个组的平均数是相依的，但是计算SE时并未考虑此事项**

针对此问题:  
**若，抽取次数针对盒子中的票数是小的，则放回和无放回之前不存在差别，且平均数之间的相依性相对较小**  
这将相当于存在两个不同的盒子：**实验组盒子**与**对照组盒子**

而针对上例，则因为：**抽取次数相对较大，则错误本身是实质性的。例如上例中，半数对象均被分置实验组中。此时的修正银子将明显小于1。  
但是，因为SE实际因为不放回抽取的原因被计算偏大，而又因为平均数相依的原因被计算偏小，二者将互相抵消。  
即:当数据源于随机化实验时，无论抽取次数是大是小，则结果依据适用于检验统计量**。

### 定性实验中的双样本K检测

例：*合理性*一词，在经济学上被认为是依据某些正规的规则形成的，决策者应针对事实做出反应而不是针对提出事实的方式做出反应；而心理学则认为，合理性和提出事实的方式存在强相关。  
故，设计了实验检查同一信息以不同方式提出时，决策者是否会收到信息提供方式的影响

实验中，针对167名医生，信息以两种方式提出：  
形式A:每100个做外科手术的人中，10人将在手术中死亡，32人将在1年内死亡，66人将在5年内死亡；而每100名接收放疗的患者中，无人在治疗过程中死亡，1年内将有23人死亡，5年内将有78人死亡。  
形式B:每100个做外科手术的人中，90人将在手术中生还，68人将存活1年及以上，34人将存活5年或以上；而每100名接收放疗的患者中，所有人将在治疗中存货，1年内将有77人将存活1年及以上，22人将存活5年或以上  
上述两个形式，表达的数据是相同的；实验中，随机选择80人进行形式A的描述，另外87人则给予形式B的描述(随机无放回式抽取，以防两个形式信息造成的混淆)。  
这当中，接收形式A信息的80个样本中，其中40人选择手术(41/80)；而接受形式B描述的87个样本中，73人选择手术(73/87)。问：产生上述差异的原因，是否是因为提供信息形式不同造成的.  

此例中，原假设为：表述信息形式的不同不会影响对合理性的判断，即：两个形式数据下的平均数相同；而备择假设则为：表述信息形式不同会影响对合理性的判断。  
此例中，因为进行的是定性分析，则数据均在0-1盒子中。盒子中存在代表着167个样本对象的卡片，卡片上存在两个0/1组成的数据结果，表明样本对象对形式A和形式B的结果，而对此卡片结果的观察和分组保持一致。  
实验时，首先随机抽取80个卡片并观察其形式A下的结果，再对剩余的67个卡片观察其形式B下的结果。  
因为图中均为0-1盒子，故盒中SD为 (1-0) * 平方根(1/2 * 1/2) = 1/2

根据上述题目可推算出: 形式A组中的SE为 平方根(80) * 1/2 = 4.5；而形式A中平均值的标准误差/SE为 4.5/80 = 5.6%  
形式B组中SE为 平方根(80) * 1/2 = 4.6；而形式B中平均值的标准误差/SE为 4.6/87 = 3.9%  

此例使用检验统计量时，根据题目可知：原假设假定两个形式的平均值的差为0，而实际/备择假设结果则为(41/80-73/83) = 34%，而分母可使用平方根法则进行计算: 平方根(5.6%^2 + 3.9%^2) = 6.8%  
故，此时检验统计量计算为:(34%-0)/6.8%=5 SE;即原假设几乎完全不成立

# 卡方检验(x^2检验)

针对**模型对实际情况拟合的程度，可以使用卡方检验进行**

针对仅存在两个类的0-1盒中，可以使用K检验进行假设检验。但是如果一次事件中存在多个类的问题，就无法使用K检验，例如:  
检查骰子是否公平，即：是否每一面均有1/6的机会被投中；此时，每用骰子投1此将存在6种完全独立的情况：即分别出现1，2，3，4，5，6点，6种情况



# t分布曲线和正态分布，z分布，卡方分布和方差分析的f分布曲线的区别

（1）t分布

在概率论和统计学中，t-分布（t-distribution）用于根据小样本来估计呈正态分布且方差未知的总体的均值。如果总体方差已知（例如在样本数量足够多时），则应该用正态分布来估计总体均值。

（2）正态分布

若随机变量X服从一个数学期望为μ、方差为σ^2的正态分布，记为N(μ，σ^2)。其概率密度函数为正态分布的期望值μ决定了其位置，其标准差σ决定了分布的幅度。当μ = 0,σ = 1时的正态分布是标准正态分布。

（3）z分布

全称费歇耳（Fisher)Z分布，亦称费歇耳方差比分布

（4）卡方分布

若n个相互独立的随机变量ξ₁，ξ₂，...,ξn ，均服从标准正态分布（也称独立同分布于标准正态分布），则这n个服从标准正态分布的随机变量的平方和构成一新的随机变量，其分布规律称为卡方分布（chi-square distribution）

（5）F分布

1924年英国统计学家R.A.Fisher提出，并以其姓氏的第一个字母命名的。它是一种非对称分布，有两个自由度，且位置不可互换。

二、特征不同

（1）以0为中心，左右对称的单峰分布；t分布是一簇曲线，其形态变化与n（确切地说与自由度df）大小有关。自由度df越小，t分布曲线越低平；自由度df越大，t分布曲线越接近标准正态分布（u分布）曲线

（2）正态曲线呈钟型，两头低，中间高，左右对称因其曲线呈钟形，因此人们又经常称之为钟形曲线。

（3）分布在第一象限内，卡方值都是正值，呈正偏态（右偏态），随着参数  的增大，  分布趋近于正态分布；卡方分布密度曲线下的面积都是1。

（4）分布的均值与方差可以看出，随着自由度  的增大，χ2分布向正无穷方向延伸（因为均值  越来越大），分布曲线也越来越低阔（因为方差  越来越大）。

（5）不同的自由度决定不同的卡方分布，自由度越小，分布越偏斜。

三、用途不同

（1）学生t-分布可简称为t分布。其推导由威廉·戈塞于1908年首先发表，当时他还在都柏林的健力士酿酒厂工作。之后t检验以及相关理论经由罗纳德·费雪的工作发扬光大，而正是他将此分布称为学生分布。

（2） 分布在数理统计中具有重要意义。  分布是由阿贝(Abbe)于1863年首先提出的，后来由海尔墨特(Hermert)和现代统计学的奠基人之一的卡·皮尔逊(C K．Pearson)分别于1875年和1900年推导出来，是统计学中的一个非常有用的著名分布。

（3）正态分布概念是由德国的数学家和天文学家Moivre于1733年首次提出的，但由于德国数学家Gauss率先将其应用于天文学研究，故正态分布又叫高斯分布。

（4）高斯这项工作对后世的影响极大，他使正态分布同时有了“高斯分布”的名称，后世之所以多将最小二乘法的发明权归之于他，也是出于这一工作。

（5）F分布有着广泛的应用，如在方差分析、回归方程的显著性检验中都有着重要的地位。

‍

扩展资料：

t分布数据：

1、首先要提一句u分布，正态分布（normal distribution）是许多统计方法的理论基础。正态分布的两个参数μ和σ决定了正态分布的位置和形态。

2、为了应用方便，常将一般的正态变量X通过u变换[(X-μ)/σ]转化成标准正态变量u，以使原来各种形态的正态分布都转换为μ=0，σ=1的标准正态分布（standard normaldistribution）,亦称u分布。

3、根据中心极限定理，通过抽样模拟试验表明，在正态分布总体中以固定 n 抽取若干个样本时，样本均数的分布仍服从正态分布，即N（μ，σ）。所以，对样本均数的分布进行u变换，也可变换为标准正态分布N (0,1)。

4、由于在实际工作中，往往σ(总体方差)是未知的，常用s（样本方差）作为σ的估计值，为了与u变换区别，称为t变换，统计量t 值的分布称为t分布。假设X服从标准正态分布N（0,1），Y服从（n）分布，那么Z=X/sqrt(Y/n)的分布称为自由度为n的t分布,记为 Z～t(n)